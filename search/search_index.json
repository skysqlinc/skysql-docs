{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction to SkySQL","text":"<p>MariaDB stands as one of the world's leading open-source relational databases, renowned for its maturity and widespread adoption. Born as a fork of MySQL, MariaDB maintains high compatibility with its predecessor while offering enhanced features and performance.</p> <p>SkySQL is an AI-driven, fully managed Database-as-a-Service (DBaaS), designed to deploy MariaDB and MySQL-compatible workloads across diverse environments including multiple data centers, regions, and cloud providers. It now offers both traditional provisioned and serverless deployment options, catering to a wide range of use cases and workload patterns while preventing over-provisioning.  With the addition of the no-code SkyAI Agent builder, developers can easily provide natural language interfaces to their end users to ask questions of the data without SQL expertise.</p> <p>Originally developed by MariaDB, SkySQL aimed to be the most comprehensive cloud platform for MariaDB. Its robust feature set is the result of years of insights gathered from hundreds of customers running mission-critical workloads. In late 2023, the core team behind SkySQL formed an independent company, named  SkySQL, to further advance the platform.</p> <p>SkySQL provides MariaDB and MySQL-compatible workloads with enterprise-grade and production-ready features:</p> <pre><code>. Serverless deployment option for instant autoscaling\n. Integrated AI Agents to converse with the database\n. Automated complex database configurations\n. Cloud-native capabilities including auto-scaling\n. Global replication\n. Automated backups\n. Advanced security with end-to-end encryption and private connectivity\n. Compliance and governance\n. And numerous other powerful features\n</code></pre> <p></p>"},{"location":"#key-features-of-skysql","title":"Key Features of SkySQL","text":""},{"location":"#advanced-scalability","title":"Advanced Scalability","text":"<ul> <li>Serverless Scaling: Provides near instantaneous scaling from zero to defined upper limit and back down to zero, adapting dynamically to workloads without manual intervention.</li> <li>Intelligent Load Balancing: Maintains consistency via smart proxy-based load balancing and read-write splitting.</li> <li>Flexible Consistency: Offers both causal and strong global consistency models.</li> <li>Custom Query Routing: Allows fine-tuned performance optimization through customizable routing rules.</li> </ul>"},{"location":"#integrated-ai-agents","title":"Integrated AI Agents","text":"<ul> <li>Semi Autonomous Agent Builder: Create domain specific AI agents to ask questions of your data with human in the loop validation via UI interface</li> <li>App Integration: Embed conversational interfaces into your apps with the associated agent REST API endpoints</li> <li>Built-in Developer and DBA Copilot Agents: Improves productivity with general SkySQL questions, query performance tuning, and troubleshooting guidance.</li> </ul>"},{"location":"#global-multi-cloud-presence","title":"Global Multi-Cloud Presence","text":"<ul> <li>Available in 40+ regions across AWS, GCP, and Azure, offering unparalleled flexibility and reach.</li> </ul>"},{"location":"#robust-high-availability-ha","title":"Robust High Availability (HA)","text":"<ul> <li>Resilient Infrastructure: Multi-layered protection across disks, compute, zones/regions, network, and load balancing.</li> <li>Intelligent Proxy: Ensures seamless failover and monitors replication lag, maintaining service continuity.</li> <li>Rapid Failover: Employs real-time health checks for swift, automated recovery.</li> </ul>"},{"location":"#disaster-recovery","title":"Disaster Recovery","text":"<ul> <li>Multi-Region Replication: Spans across regions and cloud providers for maximum resilience.</li> <li>Flexible External Replication: Supports custom external replica setups for enhanced redundancy and disaster recovery.</li> </ul>"},{"location":"#state-of-the-art-data-protection","title":"State-of-the-Art Data Protection","text":"<ul> <li>Comprehensive Backup Solutions: Goes beyond nightly backups with incremental, snapshot, and binlog backup options to both SkySQL and customer-managed storage.</li> <li>Near-Zero RPO: Achieves minimal data loss with continuous binlog streaming.</li> </ul>"},{"location":"#dynamic-auto-scaling","title":"Dynamic Auto-scaling","text":"<ul> <li>Predictive Scaling: Anticipates and adjusts storage needs based on usage patterns.</li> <li>Cost-Efficient Scaling: Proactively scales resources up and down to match demand and optimize costs.</li> </ul>"},{"location":"#fractional-dba-service","title":"Fractional DBA Service","text":"<ul> <li>SkyDBA Service: Provides access to skilled DBAs for proactive database optimization.</li> <li>Continuous Performance Monitoring: Ensures peak efficiency through ongoing monitoring and rapid issue resolution.</li> </ul>"},{"location":"#versatile-interoperability","title":"Versatile Interoperability","text":"<ul> <li>Multi-Protocol Support: Supports both JSON and SQL operations from a single data source.</li> <li>Native MongoDB/MariaDB/MySQL Support: Seamlessly integrates with existing applications via native MongoDB and MariaDB/MySQL protocol support.</li> </ul> <p>For more detailed information, you can refer to the original blog on the SkySQL website.</p>"},{"location":"Changelog/","title":"Changelog","text":""},{"location":"Changelog/#2024-releases","title":"2024 Releases","text":""},{"location":"Changelog/#october-23-release","title":"October 23 Release","text":"<ul> <li>Introduced Serverless services in Technical Preview. An industry-first, Serverless allows developers to launch MariaDB in cloud in seconds and ensures smooth scaling of resources without disruptions. Serverless brings forever free developer database.</li> <li>Fixed an issue related to stopping and scaling services on GCP due to change in Google Cloud's APIs.</li> </ul>"},{"location":"FAQs/","title":"FAQs","text":""},{"location":"FAQs/#overview","title":"Overview","text":""},{"location":"FAQs/#what-is-skysql","title":"What is SkySQL?","text":"<p>SkySQL is a modern database as a service (DBaaS) solution for production MySQL and MariaDB workloads. It simplifies database management with automated configuration, autonomous scaling, global replication, enterprise-grade security, real-time observability, automated backups and more. SkySQL delivers ultimate flexibility, reliability, performance and effortless management for your databases allowing you to focus on your application features. SkySQL provides both provisioned servers and serverless deployment options to handle a variety of use cases from mission-critical, always-on production to experimental, spiky workloads.</p>"},{"location":"FAQs/#what-is-the-history-of-skysql","title":"What is the history of SkySQL?","text":"<p>SkySQL is a database-as-a-service (DBaaS) that was originally developed and managed by MariaDB Corporation. The cloud division (SkySQL) was later spun out of MariaDB into a independent company -  SkySQL Inc.  The team that developed SkySQL transitioned over to the new company.</p>"},{"location":"FAQs/#where-is-skysql-available-what-instance-and-storage-options-are-available","title":"Where is SkySQL available? What instance and storage options are available?","text":"<p>SkySQL is available across 40+ global regions on Amazon AWS, Google Cloud and Microsoft Azure. Database services on SkySQL support a range of instance sizes. Storage starts at 10GB and can scale up to 9000GB. SkySQL's autonomous scaling takes the guesswork out of provisioning. You can start small and scale automatically as your needs evolve. </p>"},{"location":"FAQs/#how-do-i-get-started","title":"How do I get started?","text":"<p>You can sign up for a free account at\u00a0https://app.skysql.com. There is no credit card required to start and you get $100 in free credit. Once registered, you can get started right away by\u00a0launching a service,\u00a0connecting, and\u00a0loading data.</p>"},{"location":"FAQs/#how-quickly-can-i-launch-a-new-database","title":"How quickly can I launch a new database?","text":"<p>Launching a new database service with SkySQL is quick and easy. Serverless database services start in miliseconds. Provisioned Database services start in 2-4 min. </p>"},{"location":"FAQs/#is-skysql-ready-for-production-use","title":"Is SkySQL ready for production use?","text":"<p>Yes. SkySQL delivers enterprise-grade cloud database service for your mission-critical applications. Multi-node databases feature a comprehensive\u00a0SLA, High Availability (HA) features, and operations features.\u00a0Enterprise support\u00a0options extend support to 24x7, with the additional option of\u00a0SkyDBA\u00a0for proactive assistance from a team of expert DBAs.</p>"},{"location":"FAQs/#what-is-the-history-of-skysql_1","title":"What is the history of SkySQL?","text":"<p>SkySQL was originally developed and launched in early 2020 by MariaDB Corporation. In December 2023, MariaDB completed the spinoff of its SkySQL business to SkySQL Inc., as a new independent entity founded by the former MariaDB team that built and supported the SkySQL product. </p>"},{"location":"FAQs/#skysql-features","title":"SkySQL Features","text":""},{"location":"FAQs/#what-services-are-available-on-skysql","title":"What services are available on SkySQL?","text":"<p>SkySQL is primarily designed for online applications and offers two topologies -</p> <ul> <li>Replicated: Useful for mission-critical, production workloads requiring read scaling. Replicated services feature 1 primary and up to 4 replicas and uses MariaDB MaxScale for load balancing and automatic zero-interruption failover.</li> <li>Single Node: Useful for low-cost development and test transactional workloads. Single Node services cannot be scaled to Replicated topologies.</li> </ul>"},{"location":"FAQs/#what-options-are-available-for-scaling-and-right-sizing-skysql","title":"What options are available for scaling and right-sizing SkySQL?","text":"<p>You can choose\u00a0topologies to match your workload requirements, cloud regions to match your latency and operating requirements, instance sizes,\u00a0and\u00a0support plan.</p> <p>Our platform features: - Availability in a range of database\u00a0instance sizes and storage sizes - Availability from multiple\u00a0AWS (Amazon Web Services), GCP (Google Cloud Platform), and Azure (Cloud Computing Services) regions. - Load Balancing features included with\u00a0Replicated Transactions topologies\u00a0allow for read-scaling through read-write splitting. - Custom instance sizes (for\u00a0Power Tier\u00a0customers) - Range of\u00a0support options</p>"},{"location":"FAQs/#what-reliability-features-are-available-on-skysql","title":"What reliability features are available on SkySQL?","text":"<ul> <li>SkySQL is operated by a global team of Site Reliability Engineers (SRE), and expert DBAs. Platform problems are escalated to our team 24x7.</li> <li>Service Level Agreement, including an elevated SLA for\u00a0Power Tier customers</li> <li>Kubernetes self-healing - Databases run in containers in kubernetes clusters and auto-heal.</li> <li>Load balancing for multi-node configurations using MariaDB MaxScale</li> <li>High Availability (HA) for multi-node configurations</li> <li>MaxScale Redundancy option</li> <li>Inbound and outbound replication - you can replicate to your self managed MariaDB anywhere.</li> </ul>"},{"location":"FAQs/#what-operations-features-are-available-on-skysql","title":"What operations features are available on SkySQL?","text":"<ul> <li>Support from SkySQL Inc, including Enterprise and Platinum tiers optionally with SkyDBA for reactive and proactive assistance</li> <li>Vendor managed infrastructure and platform</li> <li>SkySQL Portal and SkySQL DBaaS API for instance management</li> <li>Compatibility with most programming languages and clients that work with MariaDB or MySQL, for off-the-shelf integration to your stack</li> <li>Scheduled upgrades to database software</li> <li>Automated nightly backups</li> <li>Configuration management</li> <li>On-demand backups and Snapshots</li> <li>Monitoring</li> <li>Ability to deploy additional services to support application migrations and testing on the same configuration used in production</li> <li>On-demand tear-down of unneeded services</li> </ul>"},{"location":"FAQs/#what-governance-risk-compliance-and-information-security-features-are-available-on-skysql","title":"What governance, risk, compliance, and information security features are available on SkySQL?","text":"<ul> <li>Firewall protection, including dedicated IP allowlists to access databases and to access monitoring features</li> <li>Data-at-rest encryption</li> <li>Data-in-transit encryption by default</li> <li>VPC peering, AWS PrivateLink, GCP Private Service Connect and Azure Private Link options</li> <li>Standard or enterprise authentication for management portal</li> <li>Business Associate Addendum (BAA) for HIPAA</li> <li>Data Processing Addendum (DPA) for GDPR</li> </ul>"},{"location":"FAQs/#pricing","title":"Pricing","text":""},{"location":"FAQs/#how-much-does-skysql-cost","title":"How much does SkySQL cost?","text":"<p>You can get started on SkySQL at no cost for experimenting and early development using the forever-free serverless option. Provisioned database services on SkySQL are billed based on the topology, cloud region, instance and storage sizes. For example, you can run a single 2 vCPU, 4 GB RAM instance with 100GB storage on AWS us-east-1 region 24/7 for for little over $100 a month. </p> <p>When you\u00a0launch a database service, SkySQL provides a handy estimate of how much your service selections will cost. Multi-node database services incur charge for running our intelligent proxy. Data Transfer charges associated with your service vary based on the usage and are not included in the estimates. We passthrough data transfer charges levied by cloud providers with no additional markup. </p> <p>If you\u00a0stop a service, you will continue to be charged for storage, since your data is not deleted. Instance and egress charges will stop until the instance is started again.</p> <p>Your database service cost includes Standard support and nightly backups. See the Pricing page for additional details on pricing.</p>"},{"location":"FAQs/#do-i-need-to-purchase-a-separte-mariadb-license-or-subscription-to-use-skysql","title":"Do I need to purchase a separte MariaDB license or subscription to use SkySQL?","text":"<p>No additional licenses are necessary to use SkySQL.</p>"},{"location":"FAQs/#what-is-optional-in-skysql-pricing","title":"What is optional in SkySQL pricing?","text":"<p>Add-ons are available to optimize your SkySQL experience:</p> <ul> <li>SkySQL Power Tier\u00a0is a premium service offering for SkySQL customers who have the most critical requirements for uptime, availability, performance, and support.</li> <li>While all Foundation Tier services include Standard Support, Power Tier customers are offered the \u00a0Enterprise support plan.</li> <li>An optional add-on,\u00a0SkyDBA, further extends the premium support experience and the capabilities of your in-house DBAs with the backing from a global team of expert MariaDB DBAs, available 24/7 for the most severe (P1) issues. SkySQL's SkyDBAs manage your  SkySQL databases both proactively and reactively so you can focus on your core business.</li> </ul>"},{"location":"FAQs/#is-discounted-pricing-available-for-a-longer-term-commitment","title":"Is discounted pricing available for a longer-term commitment?","text":"<p>Yes. Discounts are typically offered for one-year and three-year commitments. Please\u00a0contact us\u00a0for more information.</p>"},{"location":"FAQs/#billing-and-payment","title":"Billing and Payment","text":""},{"location":"FAQs/#how-can-i-see-my-current-charges","title":"How can I see my current charges?","text":"<p>Current month's\u00a0estimated charges\u00a0can be viewed on the Billing page. Billing history for the prior months are available on the Billing History page.</p>"},{"location":"FAQs/#when-will-i-be-billed","title":"When will I be billed?","text":"<p>Customers are billed monthly and an invoice for your SkySQL usage will be sent via email. Accounts using credit card will automatically be charged.</p>"},{"location":"FAQs/#what-forms-of-payment-does-skysql-accept","title":"What forms of payment does SkySQL accept?","text":"<p>SkySQL accepts payment by\u00a0all major credit card and through remittance accounts. Contact us\u00a0to have your account set up for payment by wire transfer or ACH.</p> <p>Note</p> <p>SkySQL does not store any of your credit card information. We use Stripe to manage all credit card transactions. Stripe is a widely used payment processing platform that enables businesses to accept credit card payments securely</p>"},{"location":"FAQs/#can-i-procure-skysql-through-cloud-marketplaces","title":"Can I procure SkySQL through Cloud Marketplaces?","text":"<p>Yes. SkySQL is available for procurement on Amazon AWS, Google Cloud and Microsoft Azure marketplaces. You can either purchase direct or we can generate a private offer to customize a subscription.</p> <ul> <li>Amazon AWS Listing</li> <li>Google Cloud Listing</li> <li>[Microsoft Azure Listing] (https://azuremarketplace.microsoft.com/en-us/marketplace/apps/skysqlinc.skysql-fully-managed-cloud-database?tab=Overview)</li> </ul>"},{"location":"FAQs/#will-i-be-charged-vat-or-taxes","title":"Will I be charged VAT or taxes?","text":"<p>SkySQL will bill for VAT and/or taxes in applicable jurisdictions. Customers are responsible for paying all applicable taxes and fees. See the\u00a0SkySQL Terms of Use\u00a0for additional information.</p>"},{"location":"FAQs/#who-do-i-contact-with-billing-questions","title":"Who do I contact with billing questions?","text":"<p>Contact\u00a0billing@skysql.com\u00a0with billing questions.</p>"},{"location":"FAQs/#backup-restore-and-deletion","title":"Backup, Restore and Deletion","text":""},{"location":"FAQs/#how-do-i-backup-my-data-on-skysql","title":"How do I backup my data on SkySQL?","text":"<p>SkySQL performs full backup of your database services each night. You can also use SkySQL's Backup Service to schedule backups and perform restores. The Backup Service supports Snapshot, Full, Incremental and Logical Dump backups. You can perform restore on the same database or another database in the same or different region using the Backup Service.</p>"},{"location":"FAQs/#are-automated-backups-sent-offsite-will-my-data-be-sent-to-another-country","title":"Are automated backups sent offsite? Will my data be sent to another country?","text":"<p>No. All data is managed within the same region by default where your database is running for data sovereignty.</p>"},{"location":"FAQs/#do-backup-operations-impact-application-performance","title":"Do backup operations impact application performance?","text":"<p>No. MariaDB Backup (mariabackup) is used for Replicated Transactions and Single Node Transactions service backups. MariaDB Backup breaks up backups into non-blocking stages so writes and schema changes can occur during backups.</p>"},{"location":"FAQs/#how-long-are-backups-retained","title":"How long are backups retained?","text":"<p>SkySQL's nightly backups as well as self-service backups are retained for 7 days.</p>"},{"location":"FAQs/#does-skysql-support-point-in-time-recovery-pitr","title":"Does SkySQL support Point-in-Time Recovery (PITR)?","text":"<p>By default, full and complete backup restoration is available. To enable point-in-time recovery, services must be configured in advance for additional binary log retention.\u00a0Point-in-time recovery (PITR)\u00a0configuration is available to\u00a0Power Tier\u00a0customers.</p>"},{"location":"FAQs/#how-long-do-you-keep-my-data-when-i-delete-a-service","title":"How long do you keep my data when I delete a service?","text":"<p>All data residing on a service's storage is deleted at time of service deletion. Backups for deleted services are purged after 7 days.</p>"},{"location":"FAQs/#security","title":"Security","text":""},{"location":"FAQs/#will-all-my-data-be-encrypted","title":"Will all my data be encrypted?","text":"<p>Yes. By default, SkySQL encrypts all data-in-transit using standard SSL/TSL. While not recommended, you can disable SSL/TLS connections while launching a database service. SkySQL leverages HashiCorp Vault for certificate and key management. Certificates and keys are not customer-configurable at this time.</p> <p>All data-at-rest is encrypted using standard cloud encryption options. - Amazon AWSAmazon EBS encryption. - Google Cloud\u00a0encryption by default. - Microsoft Azure\u00a0default encryption.</p>"},{"location":"FAQs/#are-client-certificates-supported","title":"Are client certificates supported?","text":"<p>No. SkySQL supports server-side certificates. Database users are authenticated by standard password authentication.</p>"},{"location":"FAQs/#support","title":"Support","text":""},{"location":"FAQs/#how-do-i-contact-support","title":"How do I contact support?","text":"<p>You can contact Support using the Support Portal or by emailing support@skysql.com.</p>"},{"location":"FAQs/#what-support-options-are-available-for-skysql","title":"What support options are available for SkySQL?","text":"<p>All customers with a valid payment profile receive Standard Support which includes 24x5, 2-hours response for P1 incidents. Standard Support is available at no extra charge. Enterprise Support provides 24x7, 30-min response for P1 incidents and is suitable for mission-critical workloads. SkyDBA is our premiere fractional DBA service that gives you direct access to our highly skilled DBA team who can provide technical expertise, guidance, and troubleshooting assistance when needed. See\u00a0the Support page for full details on our support options.</p>"},{"location":"FAQs/#is-24x7x365-support-available-for-mission-critical-applications","title":"Is 24x7x365 support available for mission-critical applications?","text":"<p>Yes.\u00a0Enterprise Support levels are available for customers requiring 24x7x365 support (24 hours per day, 7 days per week, 365 (or 366) days per year).</p>"},{"location":"FAQs/#what-professional-services-are-available-for-skysql","title":"What professional services are available for SkySQL?","text":"<p>SkySQL offers a full range of professional services, including:</p> <ul> <li>SkyDBA\u00a0for proactive and reactive support</li> <li>Migration\u00a0assistance</li> <li>Assistance with your SkySQL proof-of-concept (contact us for more information</li> </ul>"},{"location":"FractionalDBA/","title":"Fractional DBA Service - SkyDBA","text":"<p>SkyDBA is a \"Fractional\" DBA Service, a cost-effective solution for businesses that need database administration but do not require a full-time database administrator. This service provides access to a team of experienced database administrators on a part-time basis. Whether it's for routine maintenance, troubleshooting, or strategic advice, SkyDBA's Fractional DBA Service ensures that expert assistance is just a message away. This approach not only saves the expense of a full-time employee but also provides a higher level of service due to the collective knowledge and experience of the SkyDBA team.</p> <p>Note</p> <p>SkyDBA is an optional service that you can purchase. You can use this service regardless of the Tier (Foundation or Power) used to deploy DB services. For more information, please contact SkySQL support </p> <p>Here is what you can expect from this \u201cadd-on\u201d service. </p>"},{"location":"FractionalDBA/#migration-methodology-advice","title":"Migration Methodology &amp; Advice","text":"<p>Expert advice available on migration methodology and procedures.</p>"},{"location":"FractionalDBA/#query-optimization-and-performance-tuning","title":"Query Optimization and Performance Tuning","text":"<p>SkyDBAs offers tailored query analysis and professional tuning upon request. Our team provides expert assistance in implementing low-impact table alterations when necessary.</p>"},{"location":"FractionalDBA/#quarterly-business-review","title":"Quarterly Business Review","text":"<p>With a SkyDBA subscription, your customer success manager can schedule quarterly business reviews with someone from the SkyDBA team to review items such as:</p> <ul> <li>Historical usage focusing on peak</li> <li>Future Growth/Capacity Planning</li> <li>Recovery Time (RTO)/Recovery Point (RPO) Objectives</li> <li>Escalation Points</li> <li>Business Continuity</li> </ul>"},{"location":"FractionalDBA/#quarterly-security-audits","title":"Quarterly Security Audits","text":"<p>Work with the SkyDBA team to ensure that your environment is safe and secure. This includes auditing of users and grants.</p>"},{"location":"FractionalDBA/#proactive-monitoring-and-incident-response","title":"Proactive Monitoring and Incident Response","text":"<p>SkyDBAs monitors instances for potential business impact events. Upon detection, events are internally flagged. We investigate and collaborate with your team as needed for swift resolution.</p>"},{"location":"FractionalDBA/#extended-troubleshootinganalysis-core-dumps-system-logs-etc","title":"Extended Troubleshooting/Analysis (Core Dumps, system logs, etc.)","text":"<p>With a SkyDBA Subscription, our database experts can assist with tasks such as analyzing core dumps, system logs and other similar technical issues that require expert database server knowledge.</p>"},{"location":"FractionalDBA/#tailored-backuprestore-strategies","title":"Tailored Backup/Restore Strategies","text":"<p>Partner with SkyDBAs to create tailored backup strategies to meet your organization's Recovery Time Objective (RTO) and Recovery Point Objective (RPO) goals.</p>"},{"location":"FractionalDBA/#data-recovery-assistance-and-validation","title":"Data Recovery Assistance and Validation","text":"<p>SkyDBAs can assist in data recovery from backups or other sources, providing expertise for analysis. Additionally, as requested, SkyDBA can conduct annual Disaster Recovery exercises upon request to ensure preparedness. It's important to note that running a recovery to a secondary service may require additional compute resources.</p>"},{"location":"Observability/","title":"Observability","text":"<p>This page provides a high-level overview of the Observability functionality in SkySQL.</p> <p>In order to interact with our Observability APIs, an API KEY must be generated. Throughout this document, we will refer to it as <code>{{SKYSQL_API_KEY}}</code>.</p> <p>Additionally, you will need the SkySQL Database ID, available by clicking on any of your existing services from the SkySQL Console, and navigating to the Details page. We will Refer to the Database ID as <code>{{SKYSQL_DATABASE_ID}}</code> throughout this document.</p> <p>For the impatient reader, we jump right to the Integrations section, then for ones who are building custom instrumentation, we provide a detailed list of APIs and their relevant documentation.</p>"},{"location":"Observability/#integrations","title":"Integrations","text":""},{"location":"Observability/#datadog","title":"Datadog","text":"<p>Using the Datadog integration, you can instrument Observability metrics from SkySQL into your Datadog account.  This integration allows you to monitor and visualize SkySQL metrics alongside other services in your Datadog dashboard.</p>"},{"location":"Observability/#requirements","title":"Requirements.","text":"<p>You will need your Datadog API key to set up the integration.  We will refer to it as <code>{{DD_API_KEY}}</code> throughout this document.</p>"},{"location":"Observability/#agent-setup","title":"Agent Setup.","text":"<p>You will need to configure the Datadog Agent to pull metrics from us.  Here is an example of how you can setup the DataDog Agent:</p> <ol> <li>Create a local directory for configuration to be mapped to the Docker Container: <pre><code>mkdir -p /home/datadog-agent/openmetrics\n</code></pre></li> <li>Create a <code>conf.yaml</code> file in your <code>openmetrics</code> directory with: <pre><code>init_config:\n\ninstances:\n  - openmetrics_endpoint: https://api.skysql.com/observability/v2/metrics\n    namespace: {{SKYSQL_DATABASE_ID}}\n    extra_headers:\n      X-API-KEY: {{SKYSQL_API_KEY}}\n    metrics:\n      - '.*'\n</code></pre></li> <li> <p>Send the metrics to the correct DataDog Site. You should refer to DataDog Site documentation to determine the correct <code>SITE PARAMETER</code> for your account. This resource provides a comprehensive list of Datadog sites and their corresponding <code>SITE PARAMETER</code> values, ensuring that your data is sent to the correct regional Datadog instance. We will refer to it as <code>{{DD_SITE_PARAMETER}}</code> throughout this document.</p> </li> <li> <p>Run the Datadog Agent Docker Container with the following command: <pre><code>docker run -v /home/datadog-agent/openmetrics:/etc/datadog-agent/conf.d/openmetrics.d:ro \\\n  -e DD_API_KEY={{DD_API_KEY}} -e DD_HOSTNAME=\"my-agent\" -e DD_SITE=\"{{DD_SITE_PARAMETER}}\" \\ \n  -e DD_LOG_LEVEL=\"info\" gcr.io/datadoghq/agent:7\n</code></pre></p> </li> <li>You should see the metrics soon to be available in DataDog Metrics Explorer </li> </ol>"},{"location":"Observability/#testing-skysql-apis","title":"Testing SkySQL APIs","text":"<p>If you can always check if the Observability API is working successfully by calling it directly: <pre><code>curl --location 'https://api.skysql.com/observability/v2/metrics' \\\n--header 'X-API-KEY: {{SKYSQL_API_KEY}}'\n</code></pre> Detailed documentation on how to interact with our APIs follows:</p>"},{"location":"Observability/#apis","title":"APIs","text":"<p>To build instrumentation around our Observability APIs, we expose the following endpoints:</p>"},{"location":"Observability/#logs","title":"Logs","text":"<p>SkySQL exposes a set of log-related endpoints under <code>observability/v2/logs</code>, allowing you to: - Retrieve logs within a specified date range - Download log archives - Query log types and servers - Manage log retention settings</p> <p>Refer to the Observability section of the SkySQL API docs for the full list of parameters and responses.</p>"},{"location":"Observability/#metrics","title":"Metrics","text":"<p>You can retrieve metrics (in Prometheus-compatible format) from SkySQL using the <code>observability/v2/metrics</code> endpoint. To learn more about query parameters and usage, see:</p> <p>Example: <pre><code>curl --location 'https://api.skysql.com/observability/v2/metrics' \\\n--header 'X-API-KEY: {{SKYSQL_API_KEY}}'\n</code></pre></p> <p>Refer to the Observability section of the SkySQL API docs for the full list of parameters and responses.</p>"},{"location":"Observability/#api-documentation","title":"API Documentation","text":"<p>For the complete, detailed API reference (including request/response formats, error codes, etc.), please see the official SkySQL API docs here:</p> <ul> <li>SkySQL Observability (Logs + Metrics) Endpoints.</li> <li>Prometheus HTTP API.</li> </ul>"},{"location":"Observability/#appendix","title":"Appendix","text":""},{"location":"Observability/#table-a-key-observability-metric-series","title":"Table A. Key Observability Metric Series","text":"<p>We export the folowing metrics as part of the metrics endpoint:</p> Metric mariadb_galera_evs_repl_latency_avg_seconds mariadb_galera_evs_repl_latency_max_seconds mariadb_galera_evs_repl_latency_min_seconds mariadb_galera_status_info mariadb_global_status_aborted_clients mariadb_global_status_aborted_connects mariadb_global_status_buffer_pool_pages mariadb_global_status_bytes_received mariadb_global_status_bytes_sent mariadb_global_status_commands_total mariadb_global_status_created_tmp_disk_tables mariadb_global_status_created_tmp_files mariadb_global_status_created_tmp_tables mariadb_global_status_handlers_total mariadb_global_status_innodb_data_read mariadb_global_status_innodb_data_written mariadb_global_status_innodb_num_open_files mariadb_global_status_innodb_page_size mariadb_global_status_open_files mariadb_global_status_open_table_definitions mariadb_global_status_open_tables mariadb_global_status_opened_files mariadb_global_status_opened_table_definitions mariadb_global_status_opened_tables mariadb_global_status_queries mariadb_global_status_questions mariadb_global_status_rows_read mariadb_global_status_rows_sent mariadb_global_status_select_full_join mariadb_global_status_select_full_range_join mariadb_global_status_select_range mariadb_global_status_select_range_check mariadb_global_status_select_scan mariadb_global_status_slave_running mariadb_global_status_slow_queries mariadb_global_status_sort_merge_passes mariadb_global_status_sort_range mariadb_global_status_sort_rows mariadb_global_status_sort_scan mariadb_global_status_table_locks_immediate mariadb_global_status_table_locks_waited mariadb_global_status_table_open_cache_hits mariadb_global_status_table_open_cache_misses mariadb_global_status_table_open_cache_overflows mariadb_global_status_threads_cached mariadb_global_status_threads_connected mariadb_global_status_threads_created mariadb_global_status_threads_running mariadb_global_status_uptime mariadb_global_status_wsrep_cert_deps_distance mariadb_global_status_wsrep_cluster_conf_id mariadb_global_status_wsrep_cluster_size mariadb_global_status_wsrep_cluster_status mariadb_global_status_wsrep_connected mariadb_global_status_wsrep_flow_control_paused mariadb_global_status_wsrep_last_committed mariadb_global_status_wsrep_local_recv_queue mariadb_global_status_wsrep_local_recv_queue_avg mariadb_global_status_wsrep_local_recv_queue_max mariadb_global_status_wsrep_local_recv_queue_min mariadb_global_status_wsrep_local_send_queue mariadb_global_status_wsrep_local_send_queue_avg mariadb_global_status_wsrep_local_send_queue_max mariadb_global_status_wsrep_local_send_queue_min mariadb_global_status_wsrep_local_state mariadb_global_status_wsrep_ready mariadb_global_status_wsrep_replicated mariadb_global_status_wsrep_replicated_bytes mariadb_global_variables_gtid_current_pos mariadb_global_variables_innodb_buffer_pool_size mariadb_global_variables_innodb_log_buffer_size mariadb_global_variables_key_buffer_size mariadb_global_variables_max_connections mariadb_global_variables_open_files_limit mariadb_global_variables_query_cache_size mariadb_global_variables_read_only mariadb_global_variables_table_open_cache mariadb_info_schema_engine_table_count_total mariadb_info_schema_table_size mariadb_security_users_without_passwords mariadb_slave_status_exec_master_log_pos mariadb_slave_status_last_io_errno mariadb_slave_status_last_sql_errno mariadb_slave_status_read_master_log_pos mariadb_slave_status_relay_log_pos mariadb_slave_status_seconds_behind_master mariadb_slave_status_slave_io_running mariadb_slave_status_slave_sql_running mariadb_up mariadb_xpand_activity_core0 mariadb_xpand_activity_til mariadb_xpand_capacity_disk_system_avail_bytes mariadb_xpand_capacity_disk_system_max_bytes mariadb_xpand_capacity_disk_system_usage_ratio mariadb_xpand_capacity_disk_total_usage_percent mariadb_xpand_cluster_nodes_in_quorum mariadb_xpand_cluster_total_nodes mariadb_xpand_cluster_uptime_seconds mariadb_xpand_containers_rows mariadb_xpand_cpu_load mariadb_xpand_io_disk_latency_seconds mariadb_xpand_io_network_bytes mariadb_xpand_io_network_latency_seconds mariadb_xpand_memory_bm_bytes mariadb_xpand_memory_reserved_bytes mariadb_xpand_memory_total_bytes mariadb_xpand_memory_working_bytes mariadb_xpand_qps mariadb_xpand_rebalancer_jobs_queued mariadb_xpand_rebalancer_rebalancer_rebalance mariadb_xpand_rebalancer_rebalancer_reprotects mariadb_xpand_rebalancer_rebalancer_reranks mariadb_xpand_rebalancer_rebalancer_softfail_reprotects mariadb_xpand_rebalancer_rebalancer_splits mariadb_xpand_rebalancer_underprotected_slices mariadb_xpand_response_time_seconds mariadb_xpand_sessions mariadb_xpand_sessions_time_in_state mariadb_xpand_sessions_trx_age mariadb_xpand_stats_Com_alter_cluster mariadb_xpand_stats_Com_delete mariadb_xpand_stats_Com_delete_seconds mariadb_xpand_stats_Com_insert mariadb_xpand_stats_Com_insert_seconds mariadb_xpand_stats_Com_select mariadb_xpand_stats_Com_select_seconds mariadb_xpand_stats_Com_set_option mariadb_xpand_stats_Com_show_slave_status mariadb_xpand_stats_Com_show_status mariadb_xpand_stats_Com_show_variables mariadb_xpand_stats_Com_update mariadb_xpand_stats_Com_update_seconds mariadb_xpand_stats_connections mariadb_xpand_tps mariadb_xpand_wals_avg_sync_time_seconds maxscale_modules maxscale_server_active_operations maxscale_server_adaptive_avg_select_time maxscale_server_connection_pool_empty maxscale_server_connections maxscale_server_max_connections maxscale_server_max_pool_size maxscale_server_persistent_connections maxscale_server_reused_connections maxscale_server_routed_packets maxscale_server_total_connections maxscale_service_connections maxscale_threads_count maxscale_threads_current_descriptors maxscale_threads_errors maxscale_threads_event_queue_length maxscale_threads_hangups maxscale_threads_max_queue_time maxscale_threads_reads maxscale_threads_stack_size maxscale_threads_total_descriptors maxscale_threads_writes maxscale_up maxscale_uptime_seconds process_resident_memory_bytes"},{"location":"Support/","title":"Support","text":"<p>SkySQL is operated by a team of site reliability engineers (SREs), support engineers and MariaDB-certified database administrators (SkyDBAs).</p>"},{"location":"Support/#what-support-is-available","title":"What Support is Available?","text":"<p>Foundation level support is included with every SkySQL Subscription. Support cases at this standard support level can only be created with the P3 or P4 response SLA.</p> <p>Power level support expands the Standard level offering with Problem Resolution Support, Engineering Support and 24x7 support for S1 issues. With provided logs and information. Support will work with Customer through the needed steps for resolution via communication within the Customer Support Portal.</p> Support Feature Foundation Power Availability Foundation Tier Power Tier Named Technical Support Contacts 3 10 Problem Resolution Support Yes Yes Engineering Support Yes Yes Active Monitoring Yes Yes Consultative Support No Yes SkyDBA Add-on Available No Yes Real-Time Chat No Yes, with SkyDBA Add-on Option SLA Response Time * P3, 4 hours (24x5)* P4, 8 hours (24x5) * P1, 30 minutes (24x7) * P2, 2 hours (24x5) * P3, 4 hours (24x5) * P4, 8 hours (24x5) <p>A definitive description of SkySQL support can be found in the SkySQL Support Policy.</p>"},{"location":"Support/#how-to-request-support","title":"How to Request Support","text":"<p>Support cases are managed through the Support Portal, which is accessible to all registered users.</p> <p>Users unable to reach the Support Portal can also use Support Email.</p>"},{"location":"Uptime%20SLA/","title":"Uptime SLA","text":"<p>SkySQL customers should assess the availability requirements of their application and choose an appropriate service tier to meet their objectives. SkySQL customers are on the Foundation Tier unless they have specifically purchased and paid for Power Tier service.</p>"},{"location":"Uptime%20SLA/#performance-standard","title":"Performance Standard","text":"Tier Performance Standard SkySQL Foundation Tier Multi-node configurations will deliver a 99.95% service availability on a per-billing-month basis. For example, with this availability target in a 30 day calendar month the maximum service downtime is 21 minutes and 54 seconds. SkySQL Power Tier Multi-node configurations will deliver a 99.995% service availability on a per-billing-month basis. For example, with this availability target in a 30 day calendar month the maximum service downtime is 2 minutes and 11 seconds."},{"location":"Uptime%20SLA/#service-downtime","title":"Service Downtime","text":"<p>Service Downtime\u00a0is measured at each SkySQL database endpoint as the total number of full minutes, outside of scheduled downtime for maintenance and upgrades, where continuous attempts to establish a connection within the minute fail as reflected in minute-by-minute logs.</p>"},{"location":"Uptime%20SLA/#monthly-uptime-percentage","title":"Monthly Uptime Percentage","text":"<p>Monthly Uptime Percentage\u00a0is calculated on a per-billing-month basis as the total number of minutes in a month, minus the number of minutes of measured\u00a0Service Downtime\u00a0within the month, divided by the number of minutes in that month. When a service is deployed for only part of a month, it is assumed to be 100% available for the portion of the month that it is not deployed.</p>"},{"location":"Uptime%20SLA/#service-credit","title":"Service Credit","text":"<p>Service Credit\u00a0is the percentage of the total fees paid by you for a given SkySQL service during the month in which the downtime occurred to be credited if SkySQL approves your claim. The percentage used in calculating Service Credit is dependent on whether the customer is on Foundation Tier or Power Tier, and is dependent on the calculated\u00a0Monthly Uptime Percentage.</p> Tier Monthly Uptime Percentage Percentage Applied Foundation Tier Less than 99.95%, but greater than or equal to 99.0% 10% Foundation Tier Less than 99.0% 25% Power Tier Less than 99.995%, but greater than or equal to 99.0% 10% Power Tier Less than 99.0% 25% <p>SkySQL will grant and process claims, provided the customer has satisfied its\u00a0Customer Obligations\u00a0and that none of the\u00a0Exclusions\u00a0listed apply to the claim.\u00a0Service Credits\u00a0will be issued only upon request within 60 days of the end of the billing period of the month of impact to service availability, and upon confirmation of outage.\u00a0Service Credits\u00a0will be issued in the form of a monetary credit applied to future use of the service that experienced the\u00a0Service Downtime.\u00a0Service Credits\u00a0will not be applied to fees for any other SkySQL instance.</p> <p>The aggregate maximum number of\u00a0Service Credits\u00a0to be issued by SkySQL to customers for any and all\u00a0Service Downtime\u00a0that occurs in a single billing month will not exceed 50% of the amount due from the customer for the covered service for the applicable month.</p>"},{"location":"Uptime%20SLA/#customer-obligations","title":"Customer Obligations","text":"<p>A customer will forfeit their right to receive a\u00a0Service Credit\u00a0unless they:</p> <ul> <li>Log a support ticket with SkySQL Support within 60 minutes of first becoming aware of an event that impacts service availability.</li> <li>Submit a claim and all required information by the end of the month immediately following the month when the\u00a0Service Downtime\u00a0occurred.</li> <li>Submit necessary information for SkySQL to validate the claim, including:<ul> <li>a description of the events resulting in the\u00a0Service Downtime, and related request logs</li> <li>the date, time, and duration of the\u00a0Service Downtime</li> <li>the number and location(s) of affected users</li> <li>descriptions of customer attempts to fix the\u00a0Service Downtime\u00a0as it occurred</li> </ul> </li> <li>Provide reasonable assistance to SkySQL in investigating the cause of the\u00a0Service Downtime\u00a0and investigating your claim.</li> </ul>"},{"location":"Uptime%20SLA/#exclusions","title":"Exclusions","text":"<ul> <li> <p>Out-of-scope configurations</p> <p>The\u00a0Performance Standard\u00a0does not apply to single instance SkySQL service configuration or services in Technical Preview. Customers requiring High Availability should deploy instead in production-ready multi-node service configuration.</p> </li> <li> <p>Underlying infrastructure</p> <p>Impact to service availability caused by availability or performance of cloud services used to operate SkySQL is excluded. This includes any such outages in Amazon Web Services (AWS) and Amazon Elastic Kubernetes Service (EKS), and Google Cloud Platform (GCP) and Google Kubernetes Engine (GKE).</p> </li> <li> <p>Network interruption</p> <p>Impact to service availability caused by blocking of network traffic by ISPs, network providers, governments, or third parties is excluded.</p> </li> <li> <p>External factors</p> <p>Impact to your use of service based on factors outside SkySQL are excluded. This includes periods of downtime for your applications.</p> </li> <li> <p>Uncorroborated impacts</p> <p>Only impacts to service availability detected at\u00a0point of measurement\u00a0are subject when determining the uptime percentage. Service availability impacts measured through any other means, such as application instrumentation, are excluded except as also measured as\u00a0Service Downtime\u00a0by SkySQL.</p> </li> <li> <p>Portal access</p> <p>Impact to your ability to access or use the SkySQL portal, an interface provided to manage services, is excluded. This includes any component and content linked from the SkySQL portal, including Documentation, the Customer Support portal, Monitoring, and Workload Analysis. These components operate independently from database services and do not impact database availability.</p> </li> <li> <p>Resource usage</p> <p>Impact to service availability caused by usage of system resources, such as problems caused by excessive workload consumption of CPU, disk I/O, disk capacity, memory, and other system resources, are excluded.</p> </li> <li> <p>Clients and connectors</p> <p>Impact to service availability caused by the use of unsupported third-party clients and connectors is excluded.</p> </li> <li> <p>Non-paying customers</p> <p>The\u00a0Performance Standard\u00a0applies only to paying SkySQL customers who are paid-in-full. All other SkySQL customers, including those not paid-in-full and those customers participating in a free or credited service trial, are excluded.</p> </li> <li> <p>Customer-directed maintenance</p> <p>When a customer directs that SkySQL conduct a maintenance operation on a service, any resulting impact to service availability is excluded.</p> </li> <li> <p>Customer-approved maintenance</p> <p>When a customer approves SkySQL-recommended maintenance on a service, any resulting impact to service availability is excluded.</p> </li> <li> <p>Customer-initiated changes</p> <p>When a customer initiates changes to their SkySQL services, e.g., via access to the database or via the SkySQL portal, any resulting impact to service availability is excluded.</p> </li> <li> <p>Initial provisioning</p> <p>Availability of services during initial provisioning, e.g., before a service becomes online, healthy, and available, is excluded.</p> </li> </ul>"},{"location":"Autonomously%20scale%20Compute%2C%20Storage/","title":"Autonomously scale Compute, Storage","text":"<p>Autonomous features enable automatic scaling in response to changes in workload.</p> <p>Auto-scale of nodes enables scaling based on load:</p> <ul> <li>In/Out auto-scaling performs horizontal scaling, decreasing (In) or increasing (Out) the node count.</li> <li>Up/Down auto-scaling performs vertical scaling, increasing (Up) or decreasing (Down) the instance size.</li> </ul> <p>Auto-scale of storage enables expansion of capacity based on usage.</p> <p>Autonomous features can be enabled at time of\u00a0service launch. Autonomous features can be enabled or disabled after launch.</p> <p></p>"},{"location":"Autonomously%20scale%20Compute%2C%20Storage/#enable-auto-scaling-of-nodes","title":"Enable Auto-Scaling of Nodes","text":"<p>Auto-scaling of nodes can be enabled either at time of service launch or after service launch.</p> <p>During\u00a0service launch:</p> <ul> <li>Check the \"Enable auto-scale nodes\" checkbox and set the desired scaling parameters.</li> </ul> <p>After service launch,\u00a0manage Autonomous settings, and enable the desired auto-scaling features.</p>"},{"location":"Autonomously%20scale%20Compute%2C%20Storage/#enable-auto-scaling-of-storage","title":"Enable Auto-Scaling of Storage","text":"<p>Auto-scaling of storage can be enabled either at time of service launch or after service launch.</p> <p>During\u00a0Service Launch:</p> <ul> <li>Check the \"Enable auto-scale storage\" checkbox and set the desired maximum transactional data storage.</li> </ul> <p>After service launch,\u00a0manage Autonomous settings, and enable the desired auto-scaling features.</p>"},{"location":"Autonomously%20scale%20Compute%2C%20Storage/#manage-autonomous-settings","title":"Manage Autonomous Settings","text":"<p>To manage Autonomous settings:</p> <ul> <li>From the\u00a0Portal, click the \"MANAGE\" button for the desired service,     then choose \"Autonomous\" from the menu.</li> <li>Update settings as desired.</li> <li>Click \"Apply Changes\" when complete.</li> </ul>"},{"location":"Autonomously%20scale%20Compute%2C%20Storage/#scaling-rules","title":"Scaling Rules","text":"<p>Automatic scaling occurs based on rules.</p> Policy Condition Action Auto-Scale Disk <ul><li>Disk utilization &gt; 90% sustained for 5 minutes.</li><li>The disk is expected to run out of capacity in the next 24 hours (predicted based on the last 6 hours of service usage).</li></ul> Upgrade storage to the next available size in 100GB increments.You cannot downgrade storage, the upgrade is irreversible. Auto-Scale Nodes Out <ul><li>CPU utilization &gt; 75% over all replicas sustained for 30 minutes.</li><li>Number of concurrent sessions &gt; 90% over all replicas sustained for 1 hour.</li><li>Number of concurrent sessions is expected to hit the maximum within 4 hours (predicted based on the last 2 hours of service usage).</li></ul> Add new replica or node.Additional nodes will be of the same size and configuration as existing nodes. Auto-Scale Nodes In <ul><li>CPU utilization &lt; 50% over all replicas sustained for 1 hour.</li><li>Number of concurrent sessions &lt; 50% over all replicas sustained for 1 hour.</li></ul> Remove replica or node.Node count will not decrease below the initial count set at launch. Auto-Scale Nodes Up <ul><li>Number of concurrent sessions is expected to hit the maximum within 4 hours (predicted based on the last 2 hours of service usage).</li></ul> Upgrade all nodes to the next available size. Auto-Scale Nodes Down <ul><li>CPU utilization &lt; 50% over all replicas sustained for 1 hour.</li><li>Number of concurrent sessions &lt; 50% over all replicas sustained for 1 hour.</li></ul> Downgrade nodes.Node size will not decrease below the initial node size set at launch. <p>Autonomous actions are not instantaneous.</p> <p>Cooldown periods may apply. A cooldown period is the time period after a scaling operation is completed and before another scaling operation can occur. The cooldown period for storage scaling is 6 hours.</p>"},{"location":"Backup%20and%20Restore/","title":"Back up and instance","text":""},{"location":"Backup%20and%20Restore/#skysql-snapshot-backups","title":"SkySQL Snapshot Backups <li> SkySQL database snapshots create a point-in-time copy of the database persistent volume. Compared to full backups, snapshots provide a faster method for restoring your database with the same data.  </li> <li> Snapshots are incremental in nature. After the initial full snapshot of a database persistent volumes, subsequent snapshots only capture and store the changes made since the last snapshot. This approach saves a lot of storage space and reduces the time it takes to create a snapshot database backup and the related cloud storage cost.  </li> <li> Users have the flexibility to trigger a snapshot as per their scheduling requirements - either on-demand or according to a pre-defined schedule.  </li> <li> The SkySQL snapshots benefit from MariaDB's [backup stage flush](https://mariadb.com/kb/en/backup-stage/#:~:text=active%20DDL%20commands.-,BACKUP%20STAGE%20FLUSH,as%20closed%20for%20the%20backup.) to create a consistent backup of the database - database lock temporarily suspends write operations and replication for just a few seconds. In a Primary/Replica topology, snapshot backups are prioritized and performed on the replica node. This is to ensure that the primary server can continue to operate in read/write mode, as the backup process is carried out on the replica node. After the backup process on the replica is completed, replication resumes automatically. </li>","text":"Overview"},{"location":"Backup%20and%20Restore/#snapshot-backup-examples","title":"Snapshot Backup Examples","text":"<p>SkySQL supports database snapshot backups either on-demand or according to a pre-established schedule.  Below are examples of how to schedule a snapshot backup using the SkySQL API.</p> <ul> <li>Examples</li> </ul> <p>Important: Database snapshots are deleted immediately upon service deletion. </p>  References  <ul> <li>Amazon EBS snapshots</li> <li>Google Cloud Kubernetes Engine - Snapshot Persistent Volume</li> <li>Kubernetes - Volume Snapshots</li> <li>MariaDB - How Mariabackup Works/create-a-consistent-backup-point</li> </ul>"},{"location":"Backup%20and%20Restore/#full-physical-backups","title":"Full (physical) Backups <li> Full backups create a complete backup of the database server into a new backup folder. It uses [mariabackup](https://mariadb.com/kb/en/full-backup-and-restore-with-mariabackup/) under the hood. Physical backups are performed by copying the individual data files or directories. </li> <li> The physical backup uses backup stages to create a consistent backup of the database without requiring a global read lock for the entire duration of the backup, while allowing the database to continue processing transactions. Instead, the server read lock is only needed briefly during the [BACKUP STAGE FLUSH](https://mariadb.com/kb/en/backup-stage/#:~:text=active%20DDL%20commands.-,BACKUP%20STAGE%20FLUSH,as%20closed%20for%20the%20backup.) stage, which flushes the tables to ensure that all of them are in a consistent state at the exact same point in time, independent of storage engine. The database lock temporarily suspends write operations and replication; the duration of the lock is typically just a few seconds. In a Primary/Replica topology, backups are prioritized and performed on the replica node. This approach ensures that the primary server can continue to operate in read/write mode, as the backup process is carried out on the replica node. After the backup process on the replica is completed, replication resumes automatically. </li>","text":"Overview"},{"location":"Backup%20and%20Restore/#full-physical-backup-examples","title":"Full (physical) Backup Examples","text":"<p>SkySQL supports database physical backups either on-demand or according to a pre-established schedule. Below are examples of how to schedule a physical backup using the SkySQL API.</p> <ul> <li>Examples</li> </ul>  References  <ul> <li>mariabackup</li> </ul>"},{"location":"Backup%20and%20Restore/#incremental-backups","title":"Incremental Backups Incremental backups update a previous backup with any changes to the data that have occurred since the initial backup was taken.  InnoDB pages contain log sequence numbers, or LSN's. Whenever you modify a row on any InnoDB table in the database, the storage engine increments this number. When performing an incremental backup, Mariabackup checks the most recent LSN for the backup against the LSN's contained in the database. It then updates any of the backup files that have fallen behind.","text":"Overview"},{"location":"Backup%20and%20Restore/#incremental-backup-examples","title":"Incremental Backup Examples","text":"<p>SkySQL supports database incremental backups either on-demand or according to a pre-established schedule.  Below are examples of how to schedule an incremental backup using the SkySQL API.</p> <ul> <li>Examples</li> </ul>"},{"location":"Backup%20and%20Restore/#logical-mariadb-dump-backups","title":"Logical (Mariadb-dump) Backups Logical backups consist of the SQL statements necessary to restore the data, such as CREATE DATABASE, CREATE TABLE, and INSERT. This is done using mariadb-dump ([mariadb-dump](https://mariadb.com/kb/en/mariadb-dump/)) and is the most flexible way to perform a backup and restore, and a good choice when the data size is relatively small.","text":"Overview"},{"location":"Backup%20and%20Restore/#logical-backup-examples","title":"Logical Backup Examples","text":"<p>SkySQL supports database logical backups either on-demand or according to a pre-established schedule. Below are examples of how to schedule a logical backup using the SkySQL API.</p> <ul> <li>Examples</li> </ul>  References   [mariadb-dump](https://mariadb.com/kb/en/mariadb-dump/)"},{"location":"Backup%20and%20Restore/#binarylog-backups","title":"BinaryLog Backups Binlogs record database changes (data modifications, table structure changes) in a sequential, binary format. You can preserve binlogs for setting up replication or to recover to a certain point-in-time.","text":"Overview"},{"location":"Backup%20and%20Restore/#binarylog-backup-examples","title":"BinaryLog Backup Examples","text":"<ul> <li>Examples</li> </ul>"},{"location":"Backup%20and%20Restore/#additional-backup-options-with-examples","title":"Additional Backup Options (with Examples)","text":"<ul> <li>  Replication as Backup : In situations where the service cannot be locked or stopped, or is under heavy load, performing backups directly on a primary server may not be the preferred option. Using a replica database instance for backups allows the replica to be shut down or locked, enabling backup operations without impacting the primary server.      The approach is commonly implemented in the following manner:     - The primary server replicates data to a replica.     - Backups are then initiated from the replica, ensuring no disruption to the primary server.      Details on how to set up replication with your SkySQL instance can be found [here](../Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/). </li> <li>  Automatic Nightly Backups : Automated nightly backups include a full backup of every database in the service to ensure that your SkySQL Database service is backed up regularly. Nightly backups are running for every SkySQL database by default. </li> <li>  Bring Your Own Bucket (BYOB) : You can backup or restore data to/from your own bucket in either GCP or AWS. Sample GCP and AWS scripts can be found [here](../Backup%20and%20Restore/Bring%20Your%20Own%20Bucket%20Examples/). </li> <li>  Point-in-time Recovery : You can restore from a full or a logical backup and then use a binlog backup to restore to a point-in-time. </li> <li>  Secure Backup/Restores : Control backup/restore privileges by granting roles to users in SkySQL. </li> <li>  Other Backup API Examples : Various API scripts providing examples of listing backups, checking backup statuses, and working with backup schedules can be found [here](../Backup%20and%20Restore/Other%20backup%20API%20examples/). </li> </ul>"},{"location":"Backup%20and%20Restore/#restores","title":"Restores","text":""},{"location":"Backup%20and%20Restore/#warning","title":"Warning","text":"<p>Restoring from a backup will, by default, erase all data in your target DB service. If you are uncertain, it is advisable to first create a backup of the DB service before initiating the restore process. Consider restoring to a new database instance as a preferred approach. For restores other than logical dumps, the database being restored will be temporarily stopped during the restoration.</p> <p>Users can instruct the restore of their SkySQL Database from their own SkySQL storage or from an external storage they own. The restore API provides options for listing, adding, and deleting a scheduled restore operation.</p>"},{"location":"Backup%20and%20Restore/#list-restore-schedules","title":"List Restore Schedules","text":"<p>SkySQL Users can fetch their already existing database restore schedules using the backup API. Check the provided API examples for details.</p>"},{"location":"Backup%20and%20Restore/#restore-list-examples","title":"Restore List Examples","text":"<ul> <li>Examples</li> </ul>"},{"location":"Backup%20and%20Restore/#create-a-restore","title":"Create a Restore","text":"<p>SkySQL Users can restore their databases using their own SkySQL managed backup storage or using an external storage they own. Check the provided service API examples for details.</p>"},{"location":"Backup%20and%20Restore/#database-restore-examples","title":"Database Restore Examples","text":"<ul> <li>Examples</li> </ul>"},{"location":"Backup%20and%20Restore/#delete-restore-schedule","title":"Delete Restore Schedule","text":"<p>SkySQL Users can delete their already defined database restore schedules with the provided service API.</p>"},{"location":"Backup%20and%20Restore/#delete-restore-examples","title":"Delete Restore Examples","text":"<ul> <li>Examples</li> </ul>"},{"location":"Backup%20and%20Restore/#gtid-considerations-for-logical-dumps","title":"GTID Considerations for Logical Dumps","text":"<p>When restoring from a logical dump in MariaDB:</p> <ul> <li>The GTID state is not preserved by default in logical dumps</li> <li>If you're using replication, you'll need to:<ol> <li>Either reset the GTID state after restore</li> <li>Or use <code>mysqldump --dump-slave</code> to include GTID information in the backup</li> </ol> </li> <li>Consider using physical backups (mariabackup) instead, as they preserve GTID state</li> </ul>"},{"location":"Backup%20and%20Restore/#limitations","title":"Limitations","text":"<ul> <li>Currently, SkySQL services deployed in Azure can only be backed up and restored using SkySQL Snapshots.</li> <li>SkySQL Managed backups can only be restored within the same cloud provider. If you need to restore to a SkySQL service hosted on a different cloud provider, you must export your backup to S3 or GCS storage and follow the steps described here.</li> </ul>"},{"location":"Backup%20and%20Restore/Binarylog%20Backup%20Examples/","title":"Binarylog Backup Examples","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol>"},{"location":"Backup%20and%20Restore/Binarylog%20Backup%20Examples/#binary-log-backup","title":"Binary log Backup","text":""},{"location":"Backup%20and%20Restore/Binarylog%20Backup%20Examples/#one-time-binary-log","title":"One-time Binary log <p>To set up an one-time binary log backup:</p> <pre><code>```bash\ncurl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n    \"backup_type\": \"binarylog\",\n    \"schedule\": \"once\",\n    \"service_id\": \"$SERVICE_ID\"\n}'\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> <li>SERVICE_ID : SkySQL serivce identifier, format dbtxxxxxx. You can fetch the service ID from the Fully qualified domain name(FQDN) of your service. E.g: in dbpgf17106534.sysp0000.db2.skysql.com, 'dbpgf17106534' is the service ID.You will find the FQDN in the Connect window </li> </ul>","text":""},{"location":"Backup%20and%20Restore/Binarylog%20Backup%20Examples/#schedule-binary-log-backup","title":"Schedule Binary log backup","text":"<p>To set up an cron incremental backup:</p> <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n    \"backup_type\": \"binarylog\",\n    \"schedule\": \"0 3 * * *\",\n    \"service_id\": \"$SERVICE_ID\"\n}'\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> <li>SCHEDULE : Cron schedule, see Cron</li> <li>SERVICE_ID : SkySQL serivce identifier, format dbtxxxxxx</li> </ul>"},{"location":"Backup%20and%20Restore/Binarylog%20Backup%20Examples/#backup-status-can-be-fetch-using-httpsapiskysqlcomskybackupv1backups-see-the-backup-status-section-for-an-example","title":"Backup status can be fetch using 'https://api.skysql.com/skybackup/v1/backups'. See the 'Backup Status' section for an example.","text":""},{"location":"Backup%20and%20Restore/Bring%20Your%20Own%20Bucket%20Examples/","title":"Bring Your Own Bucket Examples","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol>"},{"location":"Backup%20and%20Restore/Bring%20Your%20Own%20Bucket%20Examples/#scheduling-backups-to-your-own-bucket-external-storage","title":"Scheduling Backups to your own bucket (external storage)","text":"<p>To set up an external storage backup, you need to make the following API call:</p> <ul> <li> <p>For GCP you need to create an service account key. Please follow the steps from this documentation. Once you have created the service account key you will need to base64 encode it. You can encode it directly from a command line itself. For example the execution of command <code>echo -n 'service-account-key' | base64</code> will produce something like <code>c2VydmljZS1hY2NvdW50LWtleQ==</code></p> <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n    \"backup_type\": \"full\",\n    \"schedule\": \"0 2 * * *\",\n    \"service_id\": \"dbtgf28044362\",\n    \"external_storage\": {\n        \"bucket\": {\n            \"path\": \"s3://my_backup_bucket\",\n            \"credentials\": \"c2VydmljZS1hY2NvdW50LWtleQ==\"\n        }\n    }\n}'\n</code></pre> <p>The service account key will be in the following format:</p> <pre><code>{\n    \"type\": \"service_account\",\n    \"project_id\": \"XXXXXXX\",\n    \"private_key_id\": \"XXXXXXX\",\n    \"private_key\": \"-----BEGIN PRIVATE KEY-----XXXXX-----END PRIVATE KEY-----\",\n    \"client_email\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXX.iam.gserviceaccount.com\",\n    \"client_id\": \"XXXXXXX\",\n    \"auth_uri\": \"&lt;https://accounts.google.com/o/oauth2/auth&gt;\",\n    \"token_uri\": \"&lt;https://oauth2.googleapis.com/token&gt;\",\n    \"auth_provider_x509_cert_url\": \"&lt;https://www.googleapis.com/oauth2/v1/certs&gt;\",\n    \"client_x509_cert_url\": \"&lt;https://www.googleapis.com/robot/v1/metadata/x509/XXXXXXXXXXXXXX.iam.gserviceaccount.com&gt;\",\n    \"universe_domain\": \"googleapis.com\"\n}\n</code></pre> </li> <li> <p>For AWS, you must provide your own credentials. These include the AWS access key associated with an IAM account and the bucket region. For more information about AWS credentials, please refer to the documentation. The required credentials are aws_access_key_id , aws_secret_access_key and region. For example your credentials should look like:</p> <pre><code>[default]\naws_access_key_id = AKIAIOSFODNN7EXAMPLE\naws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nregion = us-west-2\n</code></pre> <p>You should encode your credentials base64 before passing it to the API. You can encode it directly from a command line itself. For example the execution of command <code>echo '[default]\\naws_access_key_id = AKIAIOSFODNN7EXAMPLE\\naws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\\nregion = us-west-2' | base64</code> will produce the following <code>W2RlZmF1bHRdCmF3c19hY2Nlc3Nfa2V5X2lkID0gQUtJQUlPU0ZPRE5ON0VYQU1QTEUKYXdzX3NlY3JldF9hY2Nlc3Nfa2V5ID0gd0phbHJYVXRuRkVNSS9LN01ERU5HL2JQeFJmaUNZRVhBTVBMRUtFWQpyZWdpb24gPSB1cy13ZXN0LTIK</code>. Using encoded credentials you will be able to pass it to the API server. To initiate a new backup to your external storage you need to execute an API call to the backup service:</p> <p><code>```bash curl --location '&lt;https://api.skysql.com/skybackup/v1/backups/schedules&gt;' \\ --header 'Content-Type: application/json' \\ --header 'Accept: application/json' \\ --header 'X-API-Key: ${API_KEY}' \\ --data '{     \"backup_type\": \"full\",     \"schedule\": \"0 2 ** *\",     \"service_id\": \"dbpgf28044362\",     \"external_storage\": {         \"bucket\": {             \"path\": \"s3://my_backup_bucket\",             \"credentials\": \"W2RlZmF1bHRdCmF3c19hY2Nlc3Nfa2V5X2lkID0gQUtJQUlPU0ZPRE5ON0VYQU1QTEUKYXdzX3NlY3JldF9hY2Nlc3Nfa2V5ID0gd0phbHJYVXRuRkVNSS9LN01ERU5HL2JQeFJmaUNZRVhBTVBMRUtFWQpyZWdpb24gPSB1cy13ZXN0LTIK\"         }     } }'</code></p> </li> </ul>"},{"location":"Backup%20and%20Restore/Incremental%20Backup%20Examples/","title":"Incremental Backup Examples","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol>"},{"location":"Backup%20and%20Restore/Incremental%20Backup%20Examples/#incremental-backup","title":"Incremental Backup","text":"<p>Incremental backups can be taken once you have full backup. Read here for more details. </p>"},{"location":"Backup%20and%20Restore/Incremental%20Backup%20Examples/#one-time-incremental","title":"One-time Incremental <p>To set up an one-time incremental backup, you need to make the following API call:</p> <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n    \"backup_type\": \"incremental\",\n    \"schedule\": \"once\",\n    \"service_id\": \"$SERVICE_ID\"\n}'\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> <li>SERVICE_ID : SkySQL service identifier, format dbtxxxxxx. You can fetch the service ID from the Fully qualified domain name(FQDN) of your service. E.g: in dbpgf17106534.sysp0000.db2.skysql.com, 'dbpgf17106534' is the service ID.You will find the FQDN in the Connect window </li> </ul>","text":""},{"location":"Backup%20and%20Restore/Incremental%20Backup%20Examples/#cron-incremental","title":"Cron Incremental <p>To set up an cron incremental backup, you need to make the following API call:</p> <p><pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n    \"backup_type\": \"incremental\",\n    \"schedule\": \"0 3 * * *\",\n    \"service_id\": \"$SERVICE_ID\"\n}'\n</code></pre> - API_KEY : SKYSQL API KEY, see SkySQL API Keys - SCHEDULE : Cron schedule, see Cron - SERVICE_ID : SkySQL service identifier, format dbtxxxxxx</p>","text":""},{"location":"Backup%20and%20Restore/Incremental%20Backup%20Examples/#backup-status-can-be-fetched-using-httpsapiskysqlcomskybackupv1backups-see-the-backup-status-section-for-an-example","title":"Backup status can be fetched using 'https://api.skysql.com/skybackup/v1/backups'. See the 'Backup Status' section for an example.","text":""},{"location":"Backup%20and%20Restore/Logical%20Backup%20Examples/","title":"Logical Backup Examples","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol>"},{"location":"Backup%20and%20Restore/Logical%20Backup%20Examples/#logicaldump-backup","title":"Logical(dump) Backup","text":"<pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n    \"backup_type\": \"dump\",\n    \"schedule\": \"once\",\n    \"service_id\": \"dbtgf28044362\"\n}'\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> <li>SERVICE_ID : SkySQL service identifier, format dbtxxxxxx. You can fetch the service ID from the Fully qualified domain name(FQDN) of your service. E.g: in dbpgf17106534.sysp0000.db2.skysql.com, 'dbpgf17106534' is the service ID.You will find the FQDN in the Connect window </li> </ul>"},{"location":"Backup%20and%20Restore/Logical%20Backup%20Examples/#logicaldump-backup_1","title":"Logical(dump) Backup <p>To set up an cron Logical(dump) backup, you need to make the following API call:</p> <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n    \"backup_type\": \"dump\",\n    \"schedule\": \"0 3 * * *\",\n    \"service_id\": \"dbtgf28044362\"\n}'\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> <li>SCHEDULE : Cron schedule, see Cron</li> <li>SERVICE_ID : SkySQL service identifier, format dbtxxxxxx</li> </ul>","text":""},{"location":"Backup%20and%20Restore/Logical%20Backup%20Examples/#backup-status-can-be-fetched-using-httpsapiskysqlcomskybackupv1backups-see-the-backup-status-section-for-an-example","title":"Backup status can be fetched using 'https://api.skysql.com/skybackup/v1/backups'. See the 'Backup Status' section for an example.","text":""},{"location":"Backup%20and%20Restore/MariaDB%20Backup/","title":"MariaDB Backup","text":"<p>Regular and reliable backups are essential to successful recovery of mission critical applications. MariaDB Server backup and restore operations are performed using MariaDB Backup, an open source backup tool.</p> <p>MariaDB Backup is compatible with MariaDB Server 10.2, 10.3, 10.4, 10.5, and 10.6.</p> <ul> <li>Storage Engines and Backup Types</li> <li>Hot Online Backups</li> <li>Understanding Recovery</li> <li>Creating the Backup User</li> <li>Full Backup and Restore</li> <li>Incremental Backup and Restore</li> <li>Partial Backup and Restore</li> <li>Point-in-Time Recoveries</li> </ul>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#storage-engines-and-backup-types","title":"Storage Engines and Backup Types","text":"<p>MariaDB Backup creates a file-level backup of data from the MariaDB Server data directory. This backup includes temporal data, and the encrypted and unencrypted tablespaces of supported storage engines (e.g., InnoDB, MyRocks, Aria).</p> <p>MariaDB Server implements:</p> <ul> <li>Full backups, which contain all data in the database.</li> <li>Incremental backups, which contain modifications since the last backup.</li> <li>Partial backups, which contain a subset of the tables in the database.</li> </ul> <p>Backup support is specific to storage engines. All supported storage engines enable full backup. The InnoDB storage engine additionally supports incremental backup.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#non-blocking-backups","title":"Non-blocking Backups","text":"<p>A feature of MariaDB Backup and MariaDB Server, non-blocking backups minimize workload impact during backups. When MariaDB Backup connects to MariaDB Server, staging operations are initiated to protect data during read.</p> <p>Non-blocking backup functionality differs from historical backup functionality in the following ways:</p> <ul> <li>MariaDB Backup includes optimizations to backup staging, including DDL statement tracking, which reduces lock-time during backups.</li> <li>MariaDB Backup in MariaDB Community Server 10.4 and later will block writes, log tables, and statistics.</li> <li>Older MariaDB Community Server releases used <code>FLUSH TABLES WITH READ LOCK</code>, which closed open tables and only allowed tables to be reopened with a read lock during the duration of backups.</li> </ul>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#understanding-recovery","title":"Understanding Recovery","text":"<p>MariaDB Backup creates complete or incremental backups of MariaDB Server data, and is also used to restore data from backups produced using MariaDB Backup.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#preparing-backups-for-recovery","title":"Preparing Backups for Recovery","text":"<p>Full backups produced using MariaDB Server are not initially point-in-time consistent, and an attempt to restore from a raw full backup will cause InnoDB to crash to protect the data.</p> <p>Incremental backups produced using MariaDB Backup contain only the changes since the last backup and cannot be used standalone to perform a restore.</p> <p>To restore from a backup, you first need to prepare the backup for point-in-time consistency using the <code>--prepare</code> command:</p> <ul> <li>Running the <code>--prepare</code> command on a full backup synchronizes the tablespaces, ensuring that they are point-in-time consistent and ready for use in recovery.</li> <li>Running the <code>--prepare</code> command on an incremental backup synchronizes the tablespaces and also applies the updated data into the previous full backup, making it a complete backup ready for use in recovery.</li> <li>Running the <code>--prepare</code> command on data that is to be used for a partial restore (when restoring only one or more selected tables) requires that you also use the <code>--export</code> option to create the necessary <code>.cfg</code> files to use in recovery.</li> </ul>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#restore-requires-empty-data-directory","title":"Restore Requires Empty Data Directory","text":"<p>When MariaDB Backup restores from a backup, it copies or moves the backup files into the MariaDB Server data directory, as defined by the <code>datadir</code> system variable.</p> <p>For MariaDB Backup to safely restore data from full and incremental backups, the data directory must be empty. One way to achieve this is to move the data directory aside to a unique directory name:</p> <ol> <li>Make sure that the Server is stopped.</li> <li>Move the data directory to a unique name (for example, <code>/var/lib/mysql-2020-01-01</code>) OR remove the old data directory (depending on how much space you have available).</li> <li>Create a new (empty) data directory (for example, <code>mkdir /var/lib/mysql</code>).</li> <li>Run MariaDB Backup to restore the databases into that directory.</li> <li>Change the ownership of all the restored files to the correct system user (for example, <code>chown -R mysql:mysql /var/lib/mysql</code>).</li> <li>Start MariaDB Server, which now uses the restored data directory.</li> <li>When ready, and if you have not already done so, delete the old data directory to free disk space.</li> </ol>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#creating-the-backup-user","title":"Creating the Backup User","text":"<p>When MariaDB Backup performs a backup operation, it not only copies files from the data directory but also connects to the running MariaDB Server.</p> <p>This connection to MariaDB Server is used to manage locks and backup staging that prevent the Server from writing to a file while being read for a backup.</p> <p>MariaDB Backup establishes this connection based on the user credentials specified with the <code>--user</code> and <code>--password</code> options when performing a backup.</p> <p>It is recommended that a dedicated user be created and authorized to perform backups.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#105-and-later","title":"10.5 and Later","text":"<p>MariaDB Backup 10.5 and later requires this user to have the <code>RELOAD</code>, <code>PROCESS</code>, <code>LOCK TABLES</code>, and <code>BINLOG MONITOR</code> privileges. (The BINLOG MONITOR privilege replaced the <code>REPLICATION CLIENT</code> privilege in MariaDB Server 10.5.):</p> <p>**<code>CREATE** **USER** 'mariabackup'@'localhost'IDENTIFIED **BY** 'mbu_passwd'**;GRANT** RELOAD**,** PROCESS**,** **LOCK** TABLES**,** BINLOG MONITOR**ON** ***.*****TO** 'mariabackup'@'localhost'**;**</code></p> <p>In the above example, MariaDB Backup would run on the local system that runs MariaDB Server. Where backups may be run against a remote server, the user authentication and authorization should be adjusted.</p> <p>While MariaDB Backup requires a user for backup operations, no user is required for restore operations since restores occur while MariaDB Server is not running.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#104-and-earlier","title":"10.4 and Earlier","text":"<p>MariaDB Backup 10.4 and earlier requires this user to have the <code>RELOAD</code>, <code>PROCESS</code>, <code>LOCK TABLES</code>, and <code>REPLICATION CLIENT</code> privileges. (The BINLOG MONITOR privilege replaced the <code>REPLICATION CLIENT</code> privilege in MariaDB Server 10.5.):</p> <p>**<code>CREATE** **USER** 'mariabackup'@'localhost'IDENTIFIED **BY** 'mbu_passwd'**;GRANT** RELOAD**,** PROCESS**,** **LOCK** TABLES**,** REPLICATION CLIENT**ON** ***.*****TO** 'mariabackup'@'localhost'**;**</code></p> <p>In the above example, MariaDB Backup would run on the local system that runs MariaDB Server. Where backups may be run against a remote server, the user authentication and authorization should be adjusted.</p> <p>While MariaDB Backup requires a user for backup operations, no user is required for restore operations since restores occur while MariaDB Server is not running.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#full-backup-and-restore","title":"Full Backup and Restore","text":"<p>Full backups performed with MariaDB Backup contain all table data present in the database.</p> <p>When performing a full backup, MariaDB Backup makes a file-level copy of the MariaDB Server data directory. This backup omits log data such as the binary logs (binlog), error logs, general query logs, and slow query logs.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#performing-full-backups","title":"Performing Full Backups","text":"<p>When you perform a full backup, MariaDB Backup writes the backup to the <code>--target-dir</code> path. The directory must be empty or non-existent and the operating system user account must have permission to write to that directory. A database user account is required to perform the backup.</p> <p>The version of <code>mariabackup</code> or <code>mariadb-backup</code> should be the same version as the MariaDB Server version. When the version does not match the server version, errors can sometimes occur, or the backup can sometimes be unusable.</p> <p>To create a backup, execute <code>mariabackup</code> or <code>mariadb-backup</code> with the <code>--backup</code> option, and provide the database user account credentials using the <code>--user</code> and <code>--password</code> options:</p> <p><code>$ sudo mariabackup --backup \\      --target-dir=/data/backups/full \\      --user=mariabackup \\      --password=mbu_passwd</code></p> <p>Subsequent to the above example, the backup is now available in the designated <code>--target-dir</code> path.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#preparing-a-full-backup-for-recovery","title":"Preparing a Full Backup for Recovery","text":"<p>A raw full backup is not point-in-time consistent and must be prepared before it can be used for a restore. The backup can be prepared any time after the backup is created and before the backup is restored. However, MariaDB recommends preparing a backup immediately after taking the backup to ensure that the backup is consistent.</p> <p>The backup should be prepared with the same version of MariaDB Backup that was used to create the backup.</p> <p>To prepare the backup, execute <code>mariabackup</code> or <code>mariadb-backup</code> with the <code>--prepare</code> option:</p> <p><code>$ sudo mariabackup --prepare \\   --use-memory=34359738368 \\   --target-dir=/data/backups/full</code></p> <p>For best performance, the <code>--use-memory</code> option should be set to the server's <code>[innodb_buffer_pool_size](https://mariadb.com/docs/server/ref/mdb/system-variables/innodb_buffer_pool_size/)</code> value.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#restoring-from-full-backups","title":"Restoring from Full Backups","text":"<p>Once a full backup has been prepared to be point-in-time consistent, MariaDB Backup is used to copy backup data to the MariaDB Server data directory.</p> <p>To restore from a full backup:</p> <ol> <li>Stop the MariaDB Server</li> <li>Empty the data directory</li> <li> <p>Restore from the \"full\" directory using the <code>--copy-back</code> option:</p> <p><code>$ sudo mariabackup --copy-back --target-dir=/data/backups/full</code></p> </li> </ol> <p>MariaDB Backup writes to the data directory as the current user, which can be changed using <code>sudo</code>. To confirm that restored files are properly owned by the user that runs MariaDB Server, run a command like this (adapted for the correct user/group):</p> <p><code>$ sudo chown -R mysql:mysql /var/lib/mysql</code></p> <p>Once this is done, start MariaDB Server:</p> <p><code>$ sudo systemctl start mariadb</code></p> <p>When the Server starts, it works from the restored data directory.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#incremental-backup-and-restore","title":"Incremental Backup and Restore","text":"<p>Full backups of large data-sets can be time-consuming and resource-intensive. MariaDB Backup supports the use of incremental backups to minimize this impact.</p> <p>While full backups are resource-intensive at time of backup, the resource burden around incremental backups occurs when preparing for restore. First, the full backup is prepared for restore, then each incremental backup is applied.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#performing-incremental-backups","title":"Performing Incremental Backups","text":"<p>When you perform an incremental backup, MariaDB Backup compares a previous full or incremental backup to what it finds on MariaDB Server. It then creates a new backup containing the incremental changes.</p> <p>Incremental backup is supported for InnoDB tables. Tables using other storage engines receive full backups even during incremental backup operations.</p> <p>To increment a full backup, use the <code>--incremental-basedir</code> option to indicate the path to the full backup and the <code>--target-dir</code> option to indicate where you want to write the incremental backup:</p> <p><code>$ sudo mariabackup --backup \\      --incremental-basedir=/data/backups/full \\      --target-dir=/data/backups/inc1 \\      --user=mariabackup \\      --password=mbu_passwd</code></p> <p>In this example, MariaDB Backup reads the <code>/data/backups/full</code> directory, and MariaDB Server then creates an incremental backup in the <code>/data/backups/inc1</code> directory.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#preparing-an-incremental-backup","title":"Preparing an Incremental Backup","text":"<p>An incremental backup must be applied to a prepared full backup before it can be used in a restore operation. If you have multiple full backups to choose from, pick the nearest full backup prior to the incremental backup that you want to restore. You may also want to back up your full-backup directory, as it will be modified by the updates in the incremental data.</p> <p>If your full backup directory is not yet prepared, run this to make it consistent:</p> <p><code>$ sudo mariabackup --prepare --target-dir=/data/backups/full</code></p> <p>Then, using the prepared full backup, apply the first incremental backup's data to the full backup in an incremental preparation step:</p> <p><code>$ sudo mariabackup --prepare \\      --target-dir=/data/backups/full \\      --incremental-dir=/data/backups/inc1</code></p> <p>Once the incremental backup has been applied to the full backup, the full backup directory contains the changes from the incremental backup (that is, the <code>inc1/</code> directory). Feel free to remove <code>inc1/</code> to save disk space.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#restoring-from-incremental-backups","title":"Restoring from Incremental Backups","text":"<p>Once you have prepared the full backup directory with all the incremental changes you need (as described above), stop the MariaDB Server, empty its data directory, and restore from the original full backup directory using the <code>--copy-back</code> option:</p> <p><code>$ sudo mariabackup --copy-back --target-dir=/data/backups/full</code></p> <p>MariaDB Backup writes files into the data directory using either the current user or root (in the case of a sudo operation), which may be different from the system user that runs the database. Run the following to recursively update the ownership of the restored files and directories:</p> <p><code>$ sudo chown -R mysql:mysql /var/lib/mysql</code></p> <p>Then, start MariaDB Server. When the Server starts, it works from the restored data directory.</p> <p>The details of the restore procedure depend on the characteristics of the table:</p> <ul> <li>Partial Restore Non-partitioned Tables</li> <li>Partial Restore Partitioned Tables</li> <li>Partial Restore of Tables with Full-Text Indexes</li> </ul> <p>As partial restores are performed while the server is running, not stopped, care should be taken to prevent production workloads during restore activity.</p> <p>Note</p> <p>You can also use data from a full backup in a partial restore operation if you have prepared the data using the <code>--export</code> option as described above.</p>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#partial-restore-non-partitioned-tables","title":"Partial Restore Non-partitioned Tables","text":"<p>To restore a non-partitioned table from a backup, first create a new table on MariaDB Server to receive the restored data. It should match the specifications of the table you're restoring.</p> <p>Be extra careful if the backup data is from a server with a different version than the restore server, as some differences (such as a differing <code>ROW_FORMAT</code>) can cause an unexpected result.</p> <ol> <li> <p>Create an empty table for the data being restored:</p> <p>**<code>CREATE** **TABLE** test**.**address_book **(**   id INT **PRIMARY** **KEY** AUTO_INCREMENT**,**   name VARCHAR**(**255**),**   email VARCHAR**(**255**));**</code></p> </li> <li> <p>Modify the table to discard the tablespace:</p> <p>**<code>ALTER** **TABLE** test**.**address_book DISCARD TABLESPACE**;**</code></p> </li> <li> <p>You can copy (or move) the files for the table from the backup to the data directory:</p> <p><code>$ sudo cp /data/backups/part_inc1/test/address_book.* /var/lib/mysql/test</code></p> </li> <li> <p>Use a wildcard to include both the <code>.ibd</code> and <code>.cfg</code> files. Then, change the owner to the system user running MariaDB Server:</p> <p><code>$ sudo chown mysql:mysql /var/lib/mysql/test/address_book.*</code></p> </li> <li> <p>Lastly, import the new tablespace:</p> <p>**<code>ALTER** **TABLE** test**.**address_book IMPORT TABLESPACE**;**</code></p> <p>MariaDB Server looks in the data directory for the tablespace you copied in, then imports it for use. If the table is encrypted, it also looks for the encryption key with the relevant key ID that the table data specifies.</p> </li> <li> <p>Repeat this step for every table you wish to restore.</p> </li> </ol>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#partial-restore-partitioned-tables","title":"Partial Restore Partitioned Tables","text":"<p>Restoring a partitioned table from a backup requires a few extra steps compared to restoring a non-partitioned table.</p> <p>To restore a partitioned table from a backup, first create a new table on MariaDB Server to receive the restored data. It should match the specifications of the table you're restoring, including the partition specification.</p> <p>Be extra careful if the backup data is from a server with a different version than the restore server, as some differences (such as a differing <code>ROW_FORMAT</code>) can cause an unexpected result.</p> <ol> <li> <p>Create an empty table for the data being restored:</p> <p>**<code>CREATE** **TABLE** test**.**students **(**   id INT **NOT** **NULL** AUTO_INCREMENT**,**   name VARCHAR**(**255**),**   email VARCHAR**(**255**),**   graduating_year **YEAR,**   **PRIMARY** **KEY** **(**id**,** graduating_year**))** ENGINE = InnoDBPARTITION **BY** RANGE **(**graduating_year**)** **(**   PARTITION p0 **VALUES** **LESS** **THAN** **(**2019**),**   PARTITION p1 **VALUES** **LESS** **THAN** **MAXVALUE);**</code></p> </li> <li> <p>Then create a second empty table matching the column specification, but without partitions. This will be your working table:</p> <p>**<code>CREATE** **TABLE** test**.**students_work **ASSELECT** * **FROM** test**.**students **WHERE** **NULL;**</code></p> </li> <li> <p>For each partition you want to restore, discard the working table's tablespace:</p> <p>**<code>ALTER** **TABLE** test**.**students_work DISCARD TABLESPACE**;**</code></p> </li> <li> <p>Then, copy the table files from the backup, using the new name:</p> <p><code>$ sudo cp /data/backups/part_inc1/test/students.ibd /var/lib/mysql/test/students_work.ibd $ sudo cp /data/backups/part_inc1/test/students.cfg /var/lib/mysql/test/students_work.cfg</code></p> </li> <li> <p>Change the owner to that of the user running MariaDB Server:</p> <p><code>$ sudo chown mysql:mysql /var/lib/mysql/test/students_work.*</code></p> </li> <li> <p>Import the copied tablespace:</p> <p>**<code>ALTER** **TABLE** test**.**students_work IMPORT TABLESPACE**;**</code></p> </li> <li> <p>Lastly, exchange the partition, copying the tablespace from the working table into the partition file for the target table:</p> <p>**<code>ALTER** **TABLE** test**.**students EXCHANGE PARTITION p0 **WITH** **TABLE** test**.**students_work**;**</code></p> </li> <li> <p>Repeat the above process for each partition until you have them all exchanged into the target table. Then delete the working table, as it's no longer necessary:</p> <p>**<code>DROP** **TABLE** test**.**students_work**;**</code></p> <p>This restores a partitioned table.</p> </li> </ol>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#partial-restore-of-tables-with-full-text-indexes","title":"Partial Restore of Tables with Full-Text Indexes","text":"<p>When restoring a table with a full-text search (FTS) index, InnoDB may throw a schema mismatch error.</p> <p>In this case, to restore the table, it is recommended to:</p> <ul> <li>Remove the corresponding <code>.cfg</code> file.</li> <li>Restore data to a table without any secondary indexes including FTS.</li> <li>Add the necessary secondary indexes to the restored table.</li> </ul> <p>For example, to restore table <code>t1</code> with FTS index from database <code>db1</code>:</p> <ol> <li> <p>In the MariaDB shell, drop the table you are going to restore:</p> <p>**<code>DROP** **TABLE** **IF** **EXISTS** db1**.**t1**;**</code></p> </li> <li> <p>Create an empty table for the data being restored:</p> <p>**<code>CREATE** **TABLE** db1**.**t1**(**f1 CHAR**(**10**))** ENGINE=INNODB**;**</code></p> </li> <li> <p>Modify the table to discard the tablespace:</p> <p>**<code>ALTER** **TABLE** db1**.**t1 DISCARD TABLESPACE**;**</code></p> </li> <li> <p>In the operating system shell, copy the table files from the backup to the data directory of the corresponding database:</p> <p><code>$ sudo cp /data/backups/part/db1/t1.* /var/lib/mysql/db1</code></p> </li> <li> <p>Remove the <code>.cfg</code> file from the data directory:</p> <p><code>$ sudo rm /var/lib/mysql/db1/t1.cfg</code></p> </li> <li> <p>Change the owner of the newly copied files to the system user running MariaDB Server:</p> <p><code>$ sudo chown mysql:mysql /var/lib/mysql/db1/t1.*</code></p> </li> <li> <p>In the MariaDB shell, import the copied tablespace:</p> <p>**<code>ALTER** **TABLE** db1**.**t1 IMPORT TABLESPACE**;**</code></p> </li> <li> <p>Verify that the data has been successfully restored:</p> <p>**<code>SELECT** * **FROM** db1**.**t1**;**</code></p> <p><code>+--------+ | f1     | +--------+ | ABC123 | +--------+</code></p> </li> <li> <p>Add the necessary secondary indexes:</p> <p>**<code>ALTER** **TABLE** db1**.**t1 **FORCE,** **ADD** FULLTEXT **INDEX** f_idx**(**f1**);**</code></p> </li> <li> <p>The table is now fully restored:</p> <p>**<code>SHOW** **CREATE** **TABLE** db1**.**t1**\\G**</code></p> <ul> <li> <pre><code>*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `f1` char(10) DEFAULT NULL,\n  FULLTEXT KEY `f_idx` (`f1`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci\n</code></pre> </li> </ul> </li> </ol>"},{"location":"Backup%20and%20Restore/MariaDB%20Backup/#point-in-time-recoveries","title":"Point-in-Time Recoveries","text":"<p>Recovering from a backup restores the data directory at a specific point-in-time, but it does not restore the binary log. In a point-in-time recovery, you begin by restoring the data directory from a full or incremental backup, then use the <code>mysqlbinlog</code> utility to recover the binary log data to a specific point in time.</p> <ol> <li> <p>First, prepare the backup as you normally would for a full or incremental backup:</p> <p><code>$ sudo mariabackup --prepare --target-dir=/data/backups/full</code></p> </li> <li> <p>When MariaDB Backup runs on a MariaDB Server where binary logs are enabled, it stores binary log information in the <code>xtrabackup_binlog_info</code> file. Consult this file to find the name of the binary log position to use. In the following example, the log position is <code>321</code>.</p> <p>`$ sudo cat /data/backups/full/xtraback_binlog_info</p> <p>mariadb-node4.00001     321`</p> </li> <li> <p>Update the configuration file to use a new data directory.</p> <p>**<code>[mysqld]**datadir=/var/lib/mysql_new</code></p> </li> <li> <p>Using MariaDB Backup, restore from the backup to the new data directory:</p> <p><code>$ sudo mariabackup --copy-back --target-dir=/data/backups/full</code></p> </li> <li> <p>Then change the owner to the MariaDB Server system user:</p> <p><code>$ sudo chown -R mysql:mysql /var/lib/mysql_new</code></p> </li> <li> <p>Start MariaDB Server:</p> <p><code>$ sudo systemctl start mariadb</code></p> </li> <li> <p>Using the binary log file in the old data directory, the start position in the <code>xtrabackup_binlog_info</code> file, the date and time you want to restore to, and the <code>mysqlbinlog</code> utility to create an SQL file with the binary log changes:</p> <p><code>$ mysqlbinlog --start-position=321 \\      --stop-datetime=\"2019-06-28 12:00:00\" \\      /var/lib/mysql/mariadb-node4.00001 \\      &gt; mariadb-binlog.sql</code></p> </li> <li> <p>Lastly, run the binary log SQL to restore the databases:</p> <p><code>$ mysql -u root -p &lt; mariadb-binlog.sql</code></p> </li> </ol>"},{"location":"Backup%20and%20Restore/Other%20backup%20API%20examples/","title":"Other backup API examples","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol>"},{"location":"Backup%20and%20Restore/Other%20backup%20API%20examples/#working-with-backup-schedules","title":"Working with Backup Schedules","text":""},{"location":"Backup%20and%20Restore/Other%20backup%20API%20examples/#get-backup-schedules-inside-the-organization","title":"Get backup schedules inside the Organization : <pre><code>curl --location '&lt;https://api.skysql.com/skybackup/v1/backups/schedules&gt;' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}'\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> </ul>","text":""},{"location":"Backup%20and%20Restore/Other%20backup%20API%20examples/#get-all-backup-schedules-per-service","title":"Get all Backup Schedules per service","text":"<p>To get backup schedules for specific service :</p> <p><pre><code>curl --location '&lt;https://api.skysql.com/skybackup/v1/backups/schedules?service_id=dbtgf28044362&gt;' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}'\n</code></pre> - API_KEY : SKYSQL API KEY, see SkySQL API Keys</p>"},{"location":"Backup%20and%20Restore/Other%20backup%20API%20examples/#get-backup-schedule-by-id","title":"Get Backup Schedule by ID","text":"<p>To get specific backup schedule by id :</p> <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules/200' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}'\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> </ul>"},{"location":"Backup%20and%20Restore/Other%20backup%20API%20examples/#update-backup-schedule","title":"Update Backup Schedule","text":"<p>In the following example, we update the backup schedule to 9 AM UTC. Remember, you cannot change the schedules for one-time backups. To update specific backup schedule you need to make the following API call:</p> <p><pre><code>curl --location --request PATCH '&lt;https://api.skysql.com/skybackup/v1/backups/schedules/215&gt;' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n  \"schedule\": \"0 9 ** *\"\n}'\n</code></pre> - API_KEY : SKYSQL API KEY, see SkySQL API Keys - SCHEDULE : Cron schedule, see Cron</p>"},{"location":"Backup%20and%20Restore/Other%20backup%20API%20examples/#delete-backup-schedule","title":"Delete Backup Schedule","text":"<p>To delete a backup schedule you need to provide the backup schedule id. Example of the api call below:</p> <pre><code>curl --location --request DELETE 'https://api.skysql.com/skybackup/v1/backups/schedules/215' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}'\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> </ul>"},{"location":"Backup%20and%20Restore/Other%20backup%20API%20examples/#backup-status","title":"Backup Status","text":"<p>The following API illustrates how to get the available backups and status of backup jobs .</p>"},{"location":"Backup%20and%20Restore/Other%20backup%20API%20examples/#list-all-backups-inside-the-organization","title":"List all backups inside the organization <p>Here is an example to fetch all the available Backups in your org:</p> <p><pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}'\n</code></pre> - API_KEY : SKYSQL API KEY, see SkySQL API Keys</p>","text":""},{"location":"Backup%20and%20Restore/Other%20backup%20API%20examples/#list-all-backups-by-service","title":"List all backups by service <p>To list all backups available for your service :</p> <p><pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups?service_id=dbtgf28216706' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}'\n</code></pre> - API_KEY : SKYSQL API KEY, see SkySQL API Keys</p> <p>The typical response of either of two calls should look like:</p> <pre><code>{\n    \"backups\": [\n        {\n            \"id\": \"eda3b72460c8c0d9d61a7f01b6a22e32:dbtgf28216706:tx-filip-mdb-ms-0\",\n            \"service_id\": \"dbtgf28216706\",\n            \"type\": \"full\",\n            \"method\": \"skybucket\",\n            \"server_pod\": \"tx-filip-mdb-ms-0\",\n            \"backup_size\": 5327326,\n            \"reference_full_backup\": \"\",\n            \"point_in_time\": \"2024-03-26 17:18:21\",\n            \"start_time\": \"2024-03-26T17:18:57Z\",\n            \"end_time\": \"2024-03-26T17:19:01Z\",\n            \"status\": \"Succeeded\"\n        }\n    ],\n    \"backups_count\": 1,\n    \"pages_count\": 1\n}\n</code></pre>  <p>The ** Backup id is the most important part of this data as you need to provide it in the restore api call** to schedule restore execution.</p>","text":""},{"location":"Backup%20and%20Restore/Physical%20Backup%20Examples/","title":"Physical Backup Examples","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol>"},{"location":"Backup%20and%20Restore/Physical%20Backup%20Examples/#fullphysical-backup-scheduling","title":"Full(physical) Backup Scheduling","text":""},{"location":"Backup%20and%20Restore/Physical%20Backup%20Examples/#one-time-fullphysical-backup-example","title":"One-time Full(physical) Backup Example","text":"<pre><code>    curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n    --header 'Content-Type: application/json' \\\n    --header 'X-API-Key: $API_KEY' \\\n    --data '{\n    \"backup_type\": \"full\",\n    \"schedule\": \"once\",\n    \"service_id\": \"$SERVICE_ID\"\n    }'\"\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> <li>SERVICE_ID : SkySQL service identifier, format dbtxxxxxx. You can fetch the service ID from the Fully qualified domain name(FQDN) of your service. E.g: in dbpgf17106534.sysp0000.db2.skysql.com, 'dbpgf17106534' is the service ID.You will find the FQDN in the Connect window </li> </ul>"},{"location":"Backup%20and%20Restore/Physical%20Backup%20Examples/#cron-fullphysical-example","title":"Cron Full(physical) Example","text":"<pre><code>    curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n    --header 'Content-Type: application/json' \\\n    --header 'X-API-Key: $API_KEY' \\\n    --data '{\n    \"backup_type\": \"full\",\n    \"schedule\": \"0 3 * * *\",\n    \"service_id\": \"$SERVICE_ID\"\n    }'\"\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> <li>SCHEDULE : Cron schedule, see Cron</li> <li>SERVICE_ID : SkySQL service identifier, format dbtxxxxxx</li> </ul>"},{"location":"Backup%20and%20Restore/Physical%20Backup%20Examples/#backup-status-can-be-fetched-using-httpsapiskysqlcomskybackupv1backups-see-the-backup-status-section-for-an-example","title":"Backup status can be fetched using 'https://api.skysql.com/skybackup/v1/backups'. See the 'Backup Status' section for an example.","text":""},{"location":"Backup%20and%20Restore/Point-in-Time%20Restore/","title":"Point-in-Time Restore","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY  <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:  <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol>"},{"location":"Backup%20and%20Restore/Point-in-Time%20Restore/#important-note","title":"Important Note <p>For Point-in-Time Restore to work, you must have a pre-configured backup schedule that ensures:</p> <ul> <li>Your backup schedule creates snapshot backups with a time gap shorter than your <code>expire_logs_days</code> database configuration setting (required for binary log availability)</li> <li>Your selected restore point must be between two consecutive snapshot backups from this schedule</li> <li>By default, SkySQL sets <code>expire_logs_days</code> to 4 days, but you can configure this value to match your backup schedule requirements</li> </ul>","text":""},{"location":"Backup%20and%20Restore/Point-in-Time%20Restore/#usage-examples","title":"Usage Examples","text":""},{"location":"Backup%20and%20Restore/Point-in-Time%20Restore/#api-example","title":"API Example <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/restores' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header \"X-API-Key: ${API_KEY}\" \\\n--data '{\n  \"service_id\": \"&lt;SERVICE_ID&gt;\",\n  \"id\":\"&lt;BACKUP_SOURCE_SERVICE_ID&gt;\",\n  \"point_in_time\":\"&lt;RESTORE_POINT_IN_TIME, UTC, FORMAT: YYYY-MM-DD HH:MM:SS&gt;\"\n}'\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> <li>SERVICE_ID : SkySQL service identifier, format dbtxxxxxx. This is your restore target service</li> <li>BACKUP_SOURCE_SERVICE_ID: SkySQL service identifier, format dbtxxxxxx. This is your backup source service id</li> <li>You can fetch the SkySQL service identifier from the Fully Qualified Domain Name (FQDN) of your service. For example: in dbpgf17106534.sysp0000.db2.skysql.com, 'dbpgf17106534' is the service ID. You will find the FQDN in the Connect window</li> </ul>","text":""},{"location":"Backup%20and%20Restore/Point-in-Time%20Restore/#skysql-portal-example","title":"SkySQL Portal Example <p>To perform a Point-in-Time Restore through the SkySQL Portal:</p> <ol> <li>Navigate to Backups\u2192Restores</li> <li>Click the \"Point-in-Time Restore\" Button</li> <li>In the restore form, provide:     <ol> <li>Database restore target service</li> <li>Backup source service</li> <li>Selected restoration point in time</li> </ol> </li> <li>Click the \"Restore\" button to start the restore process</li> </ol>","text":""},{"location":"Backup%20and%20Restore/Point-in-Time%20Restore/#limitations","title":"Limitations","text":"<ul> <li>Cross-cloud restore is not supported. Your restore target service must be in the same cloud provider as your backup source service.</li> <li>Only SkySQL native snapshots can be used as restore source. External backups are not supported for Point-in-Time Restore.</li> <li>Point-in-Time Restore requires MariaDB 10.8 or later, which introduced the binary log search functionality needed for this feature.</li> <li>Support for Serverless databases as Point-in-Time Restore sources is coming soon.</li> </ul>"},{"location":"Backup%20and%20Restore/Restore%20Delete%20Examples/","title":"Restore Delete Examples","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol> <p>In order to delete an already scheduled Restore, users  need to make the following API call:</p> <pre><code>curl --location --request DELETE 'https://api.skysql.com/skybackup/v1/restores/&lt;ID&gt;' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}'\n</code></pre> <ul> <li>ID : the SkySQL Restore ID. To get the restore id, you can use the following API call:</li> </ul> <pre><code>curl --location 'https://api-test.skysql.com/skybackup/v1/backups?service_id=d&lt;SERVICE_ID&gt;' \\\n  --header 'Accept: application/json' \\\n  --header \"X-API-Key: skysql.1zzz.mh2oe85a.5aXjdyqgef7facjgAQ6DcLlVfx8imkkybIan.87c113e7\"\n</code></pre> <ul> <li>SERVICE_ID : SkySQL service identifier, format dbtxxxxxx.    You can fetch your service ID from the Fully qualified domain name(FQDN) of your service.   E.g: in dbpgf17106534.sysp0000.db2.skysql.com, 'dbpgf17106534' is the service ID. You will find the FQDN in the Connect window </li> </ul>"},{"location":"Backup%20and%20Restore/Restore%20Examples/","title":"Restore Examples","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol>"},{"location":"Backup%20and%20Restore/Restore%20Examples/#restore-from-your-bucket-external-storage","title":"Restore From your Bucket (External Storage)","text":"<p>You can restore your data from external storage. Your external storage bucket data should be created via one of the following tools: <code>mariabackup, mysqldump</code>. Credentials to external storage access could be fetched from:</p> <ul> <li> <p>For GCP you need to create a service account key. Please follow the steps from this documentation. Once you have created the service account key you will need to encode it with base64. You can encode it directly from the command line itself. For example the execution of command <code>echo -n 'service-account-key' | base64</code> will produce the following <code>c2VydmljZS1hY2NvdW50LWtleQ==</code></p> <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header \"X-API-Key: ${API_KEY}\" \\\n--data '{\n    \"backup_type\": \"full\",\n    \"schedule\": \"0 2 * * *\",\n    \"service_id\": \"dbtgf28044362\",\n    \"external_storage\": {\n        \"bucket\": {\n            \"path\": \"s3://my_backup_bucket\",\n            \"credentials\": \"c2VydmljZS1hY2NvdW50LWtleQ==\"\n        }\n    }\n}'\n</code></pre> <p>The service account key will be in the following format:</p> <pre><code>{\n    \"type\": \"service_account\",\n    \"project_id\": \"XXXXXXX\",\n    \"private_key_id\": \"XXXXXXX\",\n    \"private_key\": \"-----BEGIN PRIVATE KEY-----XXXXX-----END PRIVATE KEY-----\",\n    \"client_email\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXX.iam.gserviceaccount.com\",\n    \"client_id\": \"XXXXXXX\",\n    \"auth_uri\": \"&lt;https://accounts.google.com/o/oauth2/auth&gt;\",\n    \"token_uri\": \"&lt;https://oauth2.googleapis.com/token&gt;\",\n    \"auth_provider_x509_cert_url\": \"&lt;https://www.googleapis.com/oauth2/v1/certs&gt;\",\n    \"client_x509_cert_url\": \"&lt;https://www.googleapis.com/robot/v1/metadata/x509/XXXXXXXXXXXXXX.iam.gserviceaccount.com&gt;\",\n    \"universe_domain\": \"googleapis.com\"\n}\n</code></pre> </li> <li> <p>For AWS, you must provide your own credentials. These include the AWS access key associated with an IAM account and the bucket region. For more information about AWS credentials, please refer to the documentation. The required credentials are aws_access_key_id , aws_secret_access_key and region. For example your credentials should look like:</p> <pre><code>[default]\naws_access_key_id = AKIAIOSFODNN7EXAMPLE\naws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nregion = us-west-2\n</code></pre> <p>You should encode your credentials base64 before passing it to the API. You can encode it directly from a command line itself. For example the execution of command <code>echo '[default]\\naws_access_key_id = AKIAIOSFODNN7EXAMPLE\\naws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\\nregion = us-west-2' | base64</code> will produce the following <code>W2RlZmF1bHRdCmF3c19hY2Nlc3Nfa2V5X2lkID0gQUtJQUlPU0ZPRE5ON0VYQU1QTEUKYXdzX3NlY3JldF9hY2Nlc3Nfa2V5ID0gd0phbHJYVXRuRkVNSS9LN01ERU5HL2JQeFJmaUNZRVhBTVBMRUtFWQpyZWdpb24gPSB1cy13ZXN0LTIK</code>.</p> </li> </ul> <p>The following request demonstrates how to restore your data from an external storage:</p> <pre><code>{\n  \"service_id\": \"dbtgf28044362\",\n  \"key\": \"/backup.tar.gz\",\n  \"external_source\": {\n    \"bucket\": \"gs://my_backup_bucket\",\n    \"method\": \"mariabackup\",\n    \"credentials\" \"W2RlZmF1bHRdCmF3c19hY2Nlc3Nfa2V5X2lkID0gQUtJQUlPU0ZPRE5ON0VYQU1QTEUKYXdzX3NlY3JldF9hY2Nlc3Nfa2V5ID0gd0phbHJYVXRuRkVNSS9LN01ERU5HL2JQeFJmaUNZRVhBTVBMRUtFWQpyZWdpb24gPSB1cy13ZXN0LTIK\"\n  }\n}\n</code></pre> <p>In case your backup data is encrypted you need to pass encryption key as well:</p> <pre><code>{\n  \"service_id\": \"dbtgf28044362\",\n  \"key\": \"/backup.tar.gz\",\n  \"external_source\": {\n    \"bucket\": \"gs://my_backup_bucket\",\n    \"method\": \"mariabackup\",\n    \"credentials\": \"W2RlZmF1bHRdCmF3c19hY2Nlc3Nfa2V5X2lkID0gQUtJQUlPU0ZPRE5ON0VYQU1QTEUKYXdzX3NlY3JldF9hY2Nlc3Nfa2V5ID0gd0phbHJYVXRuRkVNSS9LN01ERU5HL2JQeFJmaUNZRVhBTVBMRUtFWQpyZWdpb24gPSB1cy13ZXN0LTIK\",\n    \"encryption_key\": \"my_encryption_key\"\n  }\n}\n</code></pre>"},{"location":"Backup%20and%20Restore/Restore%20From%20Your%20Own%20Bucket/","title":"Restore From Your Own Bucket","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol>"},{"location":"Backup%20and%20Restore/Restore%20From%20Your%20Own%20Bucket/#restore-from-your-bucket-external-storage","title":"Restore From your Bucket (External Storage)","text":"<p>You can restore your data from external cloud storage.  SkySQL supports restoration from both Google Cloud Storage (GCS) and Amazon S3 cloud storage buckets.  Your backup data should be created using either <code>mariabackup</code> or <code>mysqldump</code>.</p> <p>Below is a sample restore call:</p> <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/restores' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n    \"service_id\": \"&lt;SERVICE_ID&gt;\",\n    \"id\": \"&lt;ID&gt;\",\n    \"external_source\": {\n      \"bucket\": \"&lt;GCS_URI&gt; \u043er &lt;S3_URI&gt; \",\n      \"method\": \"&lt;BACKUP_METHOD&gt;\",\n      \"credentials\": \"&lt;GCP_SERVICE_ACCOUNT_BASE64&gt; or AWS_ACCOUNT_ACCESS_KEY_BASE64\"\n    }\n  }'\n</code></pre> <ul> <li>SERVICE_ID : SkySQL serivce identifier, format dbtxxxxxx.    You can fetch your service ID from the Fully qualified domain name(FQDN) of your service.   E.g: in dbpgf17106534.sysp0000.db2.skysql.com, 'dbpgf17106534' is the service ID. You will find the FQDN in the Connect window </li> <li>ID : the backup data file reference, available in your GCS or S3 bucket.</li> </ul> <p>Note</p> <p>Gzip compressed file  expected.</p> <p>Example: <pre><code>gzip &lt;backup file&gt; -c &gt; &lt;backup file&gt;.gz\n</code></pre></p> <ul> <li>GCS_URI/S3_URI : the GCS/S3 bucket URI where the backup file is stored. </li> </ul> <p>Format gs://BUCKET_NAME/ or s3://BUCKET_NAME/</p> <p>Note</p> <p>Make sure the BUCKET_NAME contains a trailing slash. </p> <ul> <li>BACKUP_METHOD : the backup method used to create the backup file.    Available options: <code>mariabackup</code> , <code>mysqldump</code> </li> <li>GCP_SERVICE_ACCOUNT_BASE64/AWS_ACCOUNT_ACCESS_KEY_BASE64 : Your base64 encoded GCP service account or AWS account access key. </li> </ul> <p>Information on how to create a GCP service account here   Storage Admin role is required for the service account attemping the restore.</p> <p>Sample GCP service account key and command to encode it: </p> <pre><code>echo -n '\n{\n    \"type\": \"service_account\",\n    \"project_id\": \"XXXXXXX\",\n    \"private_key_id\": \"XXXXXXX\",\n    \"private_key\": \"-----BEGIN PRIVATE KEY-----XXXXX-----END PRIVATE KEY-----\",\n    \"client_email\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXX.iam.gserviceaccount.com\",\n    \"client_id\": \"XXXXXXX\",\n    \"auth_uri\": \"&lt;https://accounts.google.com/o/oauth2/auth&gt;\",\n    \"token_uri\": \"&lt;https://oauth2.googleapis.com/token&gt;\",\n    \"auth_provider_x509_cert_url\": \"&lt;https://www.googleapis.com/oauth2/v1/certs&gt;\",\n    \"client_x509_cert_url\": \"&lt;https://www.googleapis.com/robot/v1/metadata/x509/XXXXXXXXXXXXXX.iam.gserviceaccount.com&gt;\",\n    \"universe_domain\": \"googleapis.com\"\n} ' | base64\n</code></pre> <p>Sample AWS account access key and command to encode it: </p> <pre><code>echo -n '\n{\n    [default]\n    aws_access_key_id = XXXXXXXXXXXXXEXAMPLE\n    aws_secret_access_key = XXXXXXXXXXXXX/XXXXXXXXXXXXX/XXXXXXXXXXXXXEXAMPLEKEY\n    region = XXXXXXXXXXXXX\n} ' | base64\n</code></pre>"},{"location":"Backup%20and%20Restore/Restore%20Listing%20Examples/","title":"Restore Listing Examples","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol>   In order to get all Restores scheduled in the past you need to make api call:  <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/restores' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}'\n</code></pre>  ## Get Restore by ID  <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/restores/&lt;ID&gt;' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}'\n</code></pre> - ID : the SkySQL Restore ID. aTo get the restore id, check the above sample call listing all   Typical response of those two apis should look like:  In case restore is in progress:  <pre><code>[\n    {\n        \"id\": 12,\n        \"service_id\": \"dbtgf28216706\",\n        \"bucket\": \"gs://sky-syst0000-backup-us-84e9d84ecf265a/orgpxw1x\",\n        \"key\": \"eda3b72460c8c0d9d61a7f01b6a22e32:dbtgf28216706:tx-filip-mdb-ms-0\",\n        \"type\": \"physical\",\n        \"status\": \"Running\",\n        \"message\": \"server is not-ready\"\n    }\n]\n</code></pre>  In case restore completed:  <pre><code>[\n    {\n        \"id\": 13,\n        \"service_id\": \"dbtgf28216706\",\n        \"bucket\": \"gs://sky-syst0000-backup-us-84e9d84ecf265a/orgpxw1x\",\n        \"key\": \"dda9b72460c9c0d9d61a7f01b6a33e39:dbtgf28216706:tx-filip-mdb-ms-0\",\n        \"type\": \"physical\",\n        \"status\": \"Succeeded\",\n        \"message\": \"Restore has succeeded!\"\n    }\n]\n</code></pre>"},{"location":"Backup%20and%20Restore/Restore%20from%20SkySQL%20Managed%20Storage/","title":"Restore from SkySQL Managed Storage","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol> <p>You can restore your database from the backup located in the default SkySQL managed backup storage. Below is a sample restore call.</p>"},{"location":"Backup%20and%20Restore/Restore%20from%20SkySQL%20Managed%20Storage/#restore-from-skysql-managed-storage","title":"Restore From SkySQL Managed Storage","text":"<pre><code>curl --location 'https://api.skysql.com/skybackup/v1/restores' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header \"X-API-Key: ${API_KEY}\" \\\n--data '{\n  \"key\": \"xxx:dbtgf28044362:xxx\",\n  \"service_id\": \"&lt;SERVICE_ID&gt;\"\n}'\n</code></pre> <ul> <li> <p>SERVICE_ID : SkySQL service identifier, format dbtxxxxxx.    You can fetch your service ID from the Fully qualified domain name(FQDN) of your service.   E.g: in dbpgf17106534.sysp0000.db2.skysql.com, 'dbpgf17106534' is the service ID. You will find the FQDN in the Connect window </p> </li> <li> <p>KEY : the SkySQL backup key. To get the backup key, you can use the following API call:</p> </li> </ul> <p><pre><code>curl --location 'https://api-test.skysql.com/skybackup/v1/backups?service_id=d&lt;SERVICE_ID&gt;' \\\n  --header 'Accept: application/json' \\\n  --header \"X-API-Key: skysql.1zzz.mh2oe85a.5aXjdyqgef7facjgAQ6DcLlVfx8imkkybIan.87c113e7\"\n</code></pre> Key Format: \\w*SERVICE_ID\\w* , where \\w*: Matches zero or more alphanumeric characters.</p>"},{"location":"Backup%20and%20Restore/Snapshot%20Backup%20Examples/","title":"Snapshot Backup Examples","text":"Authentication  <ol> <li> Go to the SkySQL API Key management page  and generate an API key </li> <li> Export the value from the token field to an environment variable $API_KEY    <pre><code>export API_KEY='... key data ...'\n</code></pre> </li> <li> Use it on subsequent request, e.g:          <pre><code>curl --request GET 'https://api.skysql.com/skybackup/v1/backups/schedules' --header \"X-API-Key: ${API_KEY}\"\n</code></pre> </li> </ol>"},{"location":"Backup%20and%20Restore/Snapshot%20Backup%20Examples/#snapshot-backup-scheduling","title":"Snapshot Backup Scheduling","text":""},{"location":"Backup%20and%20Restore/Snapshot%20Backup%20Examples/#one-time-snapshot-example","title":"One-time Snapshot Example","text":"<pre><code>    curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n    --header 'Content-Type: application/json' \\\n    --header 'X-API-Key: $API_KEY' \\\n    --data '{\n        \"backup_type\": \"snapshot\",\n        \"schedule\": \"once\",\n        \"service_id\": \"$SERVICE_ID\"\n    }'\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> <li>SERVICE_ID : SkySQL service identifier, format dbtxxxxxx. You can fetch the service ID from the Fully qualified domain name(FQDN) of your service. E.g: in dbpgf17106534.sysp0000.db2.skysql.com, 'dbpgf17106534' is the service ID.You will find the FQDN in the Connect window </li> </ul>"},{"location":"Backup%20and%20Restore/Snapshot%20Backup%20Examples/#cron-snapshot-example","title":"Cron Snapshot Example","text":"<pre><code>    curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n    --header 'Content-Type: application/json' \\\n    --header 'X-API-Key: $API_KEY' \\\n    --data '{\n        \"backup_type\": \"snapshot\",\n        \"schedule\": \"0 3 * * *\",\n        \"service_id\": \"$SERVICE_ID\"\n    }'\n</code></pre> <ul> <li>API_KEY : SKYSQL API KEY, see SkySQL API Keys</li> <li>SCHEDULE : Cron schedule, see Cron</li> <li>SERVICE_ID : SkySQL service identifier, format dbxxxxxx</li> </ul>"},{"location":"Backup%20and%20Restore/Snapshot%20Backup%20Examples/#backup-status-can-be-fetched-using-httpsapiskysqlcomskybackupv1backups-see-the-backup-status-section-for-an-example","title":"Backup status can be fetched using 'https://api.skysql.com/skybackup/v1/backups'. See the 'Backup Status' section for an example.","text":""},{"location":"Connecting%20to%20SkySQL%20DBs/","title":"Connecting to Sky DBs","text":"<p>This page describes how to connect to a SkySQL database using a MariaDB-compatible client.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/#important-whitelist-your-ip-address-first","title":"Important - Whitelist your IP address first","text":"<p>Note</p> <p>\ud83d\udca1 Access to all services are protected by a firewall, by default. You need to IP whitelist your client\u2019s (your desktop, laptop or server) IP. Just select \u2018Manage \u2014&gt; Security Access\u2019 and then click \u2018Add my current IP\u2019 to add the IP of your current workstation (laptop, desktop).</p> <p>Note</p> <p>\ud83d\udca1 If you are not sure or unable to obtain the IP address, you can use 0.0.0.0/0 to effectively disable the firewall. Goes without saying \u2014 don\u2019t do this for your production DBs.</p> <p>For more details go to the\u00a0Firewall\u00a0settings page. </p>"},{"location":"Connecting%20to%20SkySQL%20DBs/#connecting-using-the-mariadb-client-cli","title":"Connecting using the MariaDB Client CLI","text":"<p>Once your DB service is launched, click on the \u2018Connect\u2019 option for your service on the dashboard. This pops up all the required attributes to connect from any SQL client. </p> <p>Connection parameters include:</p> <ul> <li>Default username</li> <li>Default password</li> <li>Hostname (Fully Qualified Domain Name)</li> <li>TCP port (3306 or 3307)</li> <li>ssl-verify-server-cert (if SSL is ON)</li> </ul> <p>Note</p> <p>\ud83d\udca1 Unlike previous SkySQL versions, the current version no longer requires clients to supply the Server SSL Certificate for SSL connections. Customers who migrated from MariaDB corporation to SkySQL Inc can continue to use provided certificates (when using the previous SkySQL method for connecting). But, we strongly recommend moving to the connection properties as shown in the Connect window for your service.</p> <p>Note</p> <p>\ud83d\udca1 There is a default config change in the 11.4.2 MariaDB client that requires SSL. This needs to be disabled by setting <code>--ssl-verify-server-cert=0</code>.</p> <p></p>"},{"location":"Connecting%20to%20SkySQL%20DBs/#install-and-connect-using-the-mariadb-client","title":"Install and Connect using the MariaDB client","text":"<p>After installing the MariaDB client according to your operating system, simply copy/paste the MariaDB CLI command as displayed in the Connect window. </p>"},{"location":"Connecting%20to%20SkySQL%20DBs/#connecting-from-your-application","title":"Connecting from your Application","text":"<p>Applications can connect to SkySQL using any of the below MariaDB supported connectors. There are several other connectors from the community too. </p> <ul> <li>C</li> <li>C++</li> <li>Java</li> <li>Java R2DBC</li> <li>Node.js (JavaScript)</li> <li>ODBC API</li> <li>Python</li> <li>MongoDB Client</li> </ul> <p>Note</p> <p>\ud83d\udca1 For  Server With Replica(s), you can also use any MongoDB client and use the\u00a0NoSQL Interface"},{"location":"Connecting%20to%20SkySQL%20DBs/#connecting-from-sql-tools","title":"Connecting from SQL tools","text":"<p>Clients listed here have been tested to properly connect with SkySQL and execute queries.</p> <p>Most of the SQL clients and editors natively support MariaDB. Most often you can also just select 'MySQL' and connect to your SkySQL DB service. </p> <ul> <li>Connecting using Java clients like Squirrel SQL <ul> <li>All you need to do is to make sure the \"useSsl\" property is set to 'true' if SSL is ON. </li> </ul> </li> <li>MariaDB CLI</li> <li>Sequel Ace - Connect to MariaDB from MacOS<ul> <li>In the connection window, you should select 'Require SSL' if your SkySQL database has SSL turned ON (the default). </li> </ul> </li> </ul>"},{"location":"Connecting%20to%20SkySQL%20DBs/#graphical-user-interfaces-guis","title":"Graphical User Interfaces (GUIs)","text":"<p>The following GUI clients have been tested to properly connect with SkySQL and execute queries. Most SQL clients and editors natively support MariaDB. You can often select 'MySQL' as the connection type to connect to your SkySQL DB service.</p> <ul> <li>Connect using DBeaver SkyDBA Recommended</li> <li>Connect using DBGate</li> <li>Connect using HeidiSQL</li> <li>Connect using TablePlus</li> </ul>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Java%20App/","title":"Connect from Java App","text":"<p>MariaDB Connector/J enables Java applications to connect to SkySQL using a native MariaDB connector.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Java%20App/#install-mariadb-connectorj-via-jar","title":"Install MariaDB Connector/J via JAR","text":"<p>To download the JAR file manually:</p> <ol> <li>Go to the\u00a0MariaDB Connector/J download page</li> <li>Within the \"Product\" dropdown, choose the \"Java 8+ connector\".</li> <li>In the \"Version\" dropdown, choose the desired version.</li> <li>Click the \"Download\" button to download the JAR file.</li> <li>When the JAR file finishes downloading, place it into the relevant directory on your system.</li> <li>Similarly, install dependency JAR files, if any are used.</li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Java%20App/#install-mariadb-connectorj-via-maven","title":"Install MariaDB Connector/J via Maven","text":"<p>Maven can install MariaDB Connector/J as a dependency of your application during build. Set the\u00a0<code>&lt;version&gt;</code>\u00a0element to correspond to the version of MariaDB Connector/J that you would like to install.</p> <p>To use Maven to install MariaDB Connector/J, add the dependency to your\u00a0<code>pom.xml</code>\u00a0file:</p> <pre><code>&lt;dependency&gt;\n   &lt;groupId&gt;org.mariadb.jdbc&lt;/groupId&gt;\n   &lt;artifactId&gt;mariadb-java-client&lt;/artifactId&gt;\n   &lt;version&gt;3.4.1&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <p>For additional information on available releases, see the \"Release Notes for MariaDB Connector/J\".</p> <p>Depending on the features you plan to use, you may need to add some additional dependencies to\u00a0<code>pom.xml</code>.</p> <p>If you downloaded the connector JAR, place it on your CLASSPATH</p> <pre><code>export CLASSPATH=\"/path/to/application:/path/to/mariadb-java-client-3.4.1.jar\"\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Java%20App/#connectorj-30","title":"Connector/J 3.0","text":"<p>In MariaDB Connector/J 3.0, TLS is enabled for connections to SkySQL using the\u00a0<code>sslMode</code>\u00a0parameter.</p> <pre><code>import java.sql.*;\nimport java.util.Properties;\n\npublic class App {\n    public static void main(String[] argv) {\n        Properties connConfig = new Properties();\n        connConfig.setProperty(\"user\", \"db_user\");\n        connConfig.setProperty(\"password\", \"db_user_password\");\n        **connConfig.setProperty(\"sslMode\", \"verify-full\");**\n\n        try (Connection conn = DriverManager.getConnection(\"jdbc:mariadb://HOST:PORT\", connConfig)) {\n            try (Statement stmt = conn.createStatement()) {\n                try (ResultSet contact_list = stmt.executeQuery(\"SELECT first_name, last_name, email FROM test.contacts\")) {\n                    while (contact_list.next()) {\n                        System.out.println(String.format(\"%s %s &lt;%s&gt;\",\n                            contact_list.getString(\"first_name\"),\n                            contact_list.getString(\"last_name\"),\n                            contact_list.getString(\"email\")));\n                    }\n                }\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Java%20App/#connectorj-27","title":"Connector/J 2.7","text":"<p>In MariaDB Connector/J 2.7 and before, TLS is enabled for connections to SkySQL using the\u00a0<code>useSsl</code>\u00a0parameter.</p> <pre><code>import java.sql.*;\nimport java.util.Properties;\n\npublic class App {\n    public static void main(String[] argv) {\n        Properties connConfig = new Properties();\n        connConfig.setProperty(\"user\", \"db_user\");\n        connConfig.setProperty(\"password\", \"db_user_password\");\n        **connConfig.setProperty(\"useSsl\", \"true\");**\n\n        try (Connection conn = DriverManager.getConnection(\"jdbc:mariadb://HOST:PORT\", connConfig)) {\n            try (Statement stmt = conn.createStatement()) {\n                try (ResultSet contact_list = stmt.executeQuery(\"SELECT first_name, last_name, email FROM test.contacts\")) {\n                    while (contact_list.next()) {\n                        System.out.println(String.format(\"%s %s &lt;%s&gt;\",\n                            contact_list.getString(\"first_name\"),\n                            contact_list.getString(\"last_name\"),\n                            contact_list.getString(\"email\")));\n                    }\n                }\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20MongoDB%20clients/","title":"Connect from MongoDB clients","text":"<p>The NoSQL protocol module allows a MariaDB server or cluster to execute transactions for applications using MongoDB client libraries, transparently converting MongoDB API calls into the equivalent SQL. The MariaDB responses are then converted into the format expected by the MongoDB\u00ae client library and application.</p> <p>For detailed information on supported commands, see \"NoSQL Protocol Module\" in MariaDB MaxScale documentation.</p>  \ud83d\udca1 IMPORTANT - this feature is supported by the MariaDB advanced proxy - Maxscale.  And, maxscale is only started when using the SkySQL Replicated topology. i.e. will not work when using a Standalone MariaDB server."},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20MongoDB%20clients/#enable-support-for-nosql","title":"Enable Support for NoSQL","text":"<ol> <li>When\u00a0launching Mariadb Server With Replica(s), after defining the service name, expand the \"Additional options\" section.</li> <li>Check the \"Enable support for NoSQL\" checkbox.</li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20MongoDB%20clients/#available-clients","title":"Available Clients","text":"<p>Connect to the NoSQL interface using a MongoDB client library or compatible application.\u00a0Documentation on official MongoDB libraries\u00a0is available from MongoDB.</p> <p>Documentation on installing\u00a0<code>mongosh</code>\u00a0(the MongoDB Shell)\u00a0is available from MongoDB.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20MongoDB%20clients/#connection-parameters","title":"Connection Parameters","text":"<p>From the Dashboard, the details needed to connect to your SkySQL service can be seen by clicking on the \"CONNECT\" button for the desired service.</p> <p>The \"NoSQL port\" is the TCP port used to connect to the NoSQL interface.</p> <p>The\u00a0firewall\u00a0must be configured to allowlist the client's IP address or netblock before connections can occur.</p> <p>See the \"Connecting using Mongosh\" section of the Connect page for an example\u00a0<code>mongosh</code>\u00a0command-line, authentication instructions, and instructions to change the default password.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/","title":"Connect from Node.js App","text":"<p>Node.js developers can connect to SkySQL through a native MariaDB Connector. Using MariaDB Connector/Node.js you can connect to SkySQL to use and administer databases from within your Node.js application.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/#install-mariadb-connectornodejs","title":"Install MariaDB Connector/Node.js","text":"<p>MariaDB Connector/Node.js is usually installed either from the Node.js repository or manually from the source code package.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/#install-mariadb-connectornodejs-via-repository","title":"Install MariaDB Connector/Node.js via Repository","text":"<p>To install MariaDB Connector/Node.js from the Node.js repository, use NPM:</p> <pre><code>npm install mariadb\n</code></pre> <p>NPM connects to the Node.js repository and downloads MariaDB Connector/Node.js and all relevant dependencies into the\u00a0<code>node_modules/</code>\u00a0directory.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/#install-mariadb-connectornodejs-via-source-code","title":"Install MariaDB Connector/Node.js via Source Code","text":"<p>To download and install the MariaDB Connector/Node.js manually from source code:</p> <ol> <li>Go to the MariaDB Connectors download page:<ul> <li>https://mariadb.com/downloads/connectors/connectors-data-access/nodejs-connector</li> </ul> </li> <li>In the \"Product\" dropdown, select the Node.js connector.</li> <li>Click the \"Download\" button to download the source code package</li> <li> <p>When the source code package finishes downloading, install it with NPM:</p> <p><code>$ npm install mariadb-connector-nodejs-*.tar.gz</code></p> </li> </ol> <p>NPM untars the download and installs MariaDB Connector/Node.js in the\u00a0<code>node_modules/</code>\u00a0directory.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/#connect-with-mariadb-connectornodejs-callback-api","title":"Connect with MariaDB Connector/Node.js (Callback API)","text":"<p>Node.js developers can use MariaDB Connector/Node.js to establish client connections with SkySQL.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/#require-callback-api","title":"Require Callback API","text":"<p>MariaDB Connector/Node.js provides two different connection implementations: one built on the\u00a0Promise API\u00a0and the other built on the Callback API.</p> <p>To use the Callback API, use the following module:</p> <pre><code>const** mariadb = require**(**'mariadb/callback'**);\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/#connect","title":"Connect","text":"<p><pre><code>createConnection(options)\u00a0-&gt;\u00a0Connection\n</code></pre> is the base function used to create a\u00a0<code>Connection</code>\u00a0object.</p> <p>The\u00a0<code>createConnection(options)</code>\u00a0function returns a\u00a0<code>Connection</code>\u00a0object.</p> <p>Determine the\u00a0connection information\u00a0for your SkySQL database service:</p> Option Description host The fully Qualified Domain Name from the \"Connect\" window in SkySQL portal port The Read-Write Port or Read-Only Port from the \"Connect\" window in SkySQL portal user The desired username, which might be the default username in the Service Credentials view password The user's password, which might be the default password in the Service Credentials view if it was not yet customized database Database name to establish a connection to. No default is configured. connectTimeout Connection timeout in milliseconds. In Connector/Node.js 2.5.6, the default value changed to 1000. The default value for earlier versions is 10000. rowsAsArray A boolean value to indicate whether to return result sets as arrays instead of the default JSON. Arrays are comparatively faster."},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/#code-example-connect","title":"Code Example: Connect","text":"<p>The following code example connects using the database and user account created in the\u00a0example setup:</p> <pre><code>const mariadb = require('mariadb/callback');\n\n// Certificate Authority (CA)\",\nvar serverCert = [fs.readFileSync(process.env.SKYSQL_CA_PEM, \"utf8\")];\n\n// Declare async function\nfunction main() {\n   let conn;\n\n   try {\n      conn = mariadb.createConnection({\n         host: \"example.skysql.com\",\n         port: 5009,\n         ssl: { ca: serverCert },\n         user: \"db_user\",\n         password: \"db_user_password\",\n         database: \"test\",\n      });\n\n      // Use Connection\n      // ...\n   } catch (err) {\n      // Manage Errors\n      console.log(\"SQL error in establishing a connection: \", err);\n   } finally {\n      // Close Connection\n      if (conn) conn.end(err =&gt; {if(err){\n         console.log(\"SQL error in closing a connection: \", err);}\n      });\n   }\n}\n\nmain();\n</code></pre> <ul> <li>A\u00a0<code>try...catch...finally</code>\u00a0statement is used for exception handling.</li> <li>New connections are created in auto-commit mode by default.</li> <li>When you are done with a connection, close it to free resources. Close the connection using the\u00a0<code>connection.end([callback])</code>\u00a0function.</li> <li>The script calls the\u00a0<code>connection.end([callback])</code>\u00a0function to close/end the connection in the\u00a0<code>finally</code>\u00a0block after the queries that are running have completed.</li> <li>The\u00a0<code>end()</code>\u00a0function takes a callback function that defines one implicit argument for the\u00a0<code>Error</code>\u00a0object if thrown in closing the connection as argument. If no error is generated in closing a connection the\u00a0<code>Error</code>\u00a0object is\u00a0<code>null</code>.</li> </ul>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/#connect-with-mariadb-connectornodejs-promise-api","title":"Connect with MariaDB Connector/Node.js (Promise API)","text":"<p>Node.js developers can use MariaDB Connector/Node.js to establish client connections with SkySQL.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/#require-promise-api","title":"Require Promise API","text":"<p>MariaDB Connector/Node.js provides two different connection implementations: one built on the Promise API and the other built on the\u00a0Callback API. Promise is the default.</p> <p>To use the Promise API, use the\u00a0<code>mariadb</code>\u00a0module:</p> <pre><code>const** mariadb = require**(**'mariadb'**);\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/#connect_1","title":"Connect","text":"<p><code>createConnection(options)\u00a0-&gt;\u00a0Promise</code>\u00a0is the base function used to create a\u00a0<code>Connection</code>\u00a0object.</p> <p>The\u00a0<code>createConnection(options)</code>\u00a0returns a\u00a0<code>Promise</code>\u00a0that resolves to a\u00a0<code>Connection</code>\u00a0object if no error occurs, and rejects with an\u00a0<code>Error</code>\u00a0object if an error occurs.</p> <p>Determine the\u00a0connection information\u00a0for your SkySQL database service:</p> Option Description host The fully Qualified Domain Name from the \"Connect\" window in SkySQL portal port The Read-Write Port or Read-Only Port from the \"Connect\" window in SkySQL portal user The desired username, which might be the default username in the Service Credentials view password The user's password, which might be the default password in the Service Credentials view if it was not yet customized database Database name to establish a connection to. No default is configured. connectTimeout Connection timeout in milliseconds. In Connector/Node.js 2.5.6, the default value changed to 1000. The default value for earlier versions is 10000. rowsAsArray A boolean value to indicate whether to return result sets as arrays instead of the default JSON. Arrays are comparatively faster. <p>Create a file named\u00a0<code>.env</code>\u00a0to store your database credentials:</p> <pre><code>MDB_HOST = 192.0.2.50\nMDB_PORT = 3306\nMDB_USER = db_user\nMDB_PASS = db_user_password\nMDB_HOST = example.skysql.com\nMDB_PORT = 5001\nMDB_CA_PEM = /path/to/skysql_chain.pem\nMDB_USER = db_user\nMDB_PASS = db_user_password\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Node%20js%20App/#code-example-connect_1","title":"Code Example: Connect","text":"<p>The following code example connects\u00a0using the database and user account created in\u00a0Setup for Examples:</p> <pre><code>// Required Modules\nconst fs = require(\"fs\");\nconst mariadb = require(\"mariadb\");\nrequire(\"dotenv\").config()\n\n// Certificate Authority (CA)\nconst serverCert = [fs.readFileSync(process.env.MDB_CA_PEM, \"utf8\")];\n\n// Declare async function\nasync function main() {\n   let conn;\n\n   try {\n      conn = await mariadb.createConnection({\n         host: process.env.MDB_HOST,\n         port: process.env.MDB_PORT,\n         user: process.env.MDB_USER,\n         password: process.env.MDB_PASS,\n         ssl: { ca: serverCert },\n         database: \"test\",\n      });\n\n      // Use Connection\n      // ...\n   } catch (err) {\n      // Manage Errors\n      console.log(\"SQL error in establishing a connection: \", err);\n   } finally {\n      // Close Connection\n      if (conn) conn.close();\n   }\n}\n\nmain();\n</code></pre> <ul> <li>Load the\u00a0<code>mariadb</code>\u00a0module using the\u00a0<code>require()</code>\u00a0function.</li> <li>Declare an async function called\u00a0<code>main()</code>\u00a0using the\u00a0<code>async</code>\u00a0keyword.</li> <li>An async function provides asynchronous, Promise-based code behavior.</li> <li>Async functions may declare\u00a0<code>await</code>\u00a0expressions using the\u00a0<code>await</code>\u00a0keyword.</li> <li>Await expressions yield control to a promise-based asynchronous operation.</li> <li>Await expressions resume control after the awaited operation is either fulfilled or rejected.</li> <li>The return value of an\u00a0<code>await</code>\u00a0expression is the resolved value of the\u00a0<code>Promise</code>.</li> <li>The async function name\u00a0<code>main</code>\u00a0is arbitrary and does not have special meaning as in some other programming languages.</li> <li>Declare a variable called\u00a0<code>conn</code>\u00a0for the connection to be created using a\u00a0<code>let</code>\u00a0statement with the async function\u00a0<code>main</code>.</li> <li>A\u00a0<code>try...catch...finally</code>\u00a0statement is used for exception handling.</li> <li>New connections are by default created in auto-commit mode.</li> <li>In the\u00a0<code>try</code>\u00a0block, create a new connection using the\u00a0<code>mariadb#createConnection(options)</code>\u00a0function in the Promise API.</li> <li>Send error messages if any to the console in the\u00a0<code>catch</code>\u00a0block.</li> <li>When you are done with a connection, close it to free resources. Close the connection using the\u00a0<code>close()</code>\u00a0function.</li> </ul>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Python%20App/","title":"Connect from Python App","text":""},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Python%20App/#overview","title":"Overview","text":"<p>Python developers can use MariaDB Connector/Python to establish client connections with SkySQL.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Python%20App/#connections","title":"Connections","text":"<p>Connections are managed using the following Python class:</p> Class Description Connection Represents a connection to SkySQL. <p>Connections are created, used, and managed using the following <code>Connection</code> class functions:</p> Function Description connect() Establishes a connection to a database server and returns a connection object. cursor() Returns a new cursor object for the current connection. change_user() Changes the user and default database of the current connection. reconnect() Tries to make a connection object active again by reconnecting to the server using the same credentials which were specified in connect() method. close() Closes the connection. <p>Determine the connection information for your SkySQL database service:</p> connect() parameter Where to find it user Default username in the Service Credentials view, or the username you created passwd Default password in the Service Credentials view, the password you set on the default user, or the password for the user you created host Fully Qualified Domain Name in the Connection Parameters Portal ssl_verify_cert Set to True to support SSL port Read-Write Port or Read-Only Port in the Connection Parameters Portal"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Python%20App/#code-example-connect","title":"Code Example: Connect","text":"<p>The following code example connects to an example server.</p> <p>Examples:</p> <pre><code># Module Import\nimport mariadb\nimport sys\n\n# Instantiate Connection\ntry:\n   conn = mariadb.connect(\n      host=\"192.0.2.1\",\n      port=3306,\n      user=\"db_user\",\n      password=\"USER_PASSWORD\")\nexcept mariadb.Error as e:\n   print(f\"Error connecting to the database: {e}\")\n   sys.exit(1)\n\n# Use Connection\n# ...\n\n# Close Connection\nconn.close()\n</code></pre> <pre><code># Module Import\nimport mariadb\nimport sys\n\n# Instantiate Connection\ntry:\n   conn = mariadb.connect(\n      host=\"SKYSQL_SERVICE.mdb0000001.db.skysql.com\",\n      port=5009,\n      ssl_verify_cert=True,\n      user=\"DB00000001\",\n      password=\"USER_PASSWORD\")\nexcept mariadb.Error as e:\n   print(f\"Error connecting to the database: {e}\")\n   sys.exit(1)\n\n# Use Connection\n# ...\n\n# Close Connection\nconn.close()\n</code></pre> <ul> <li>The <code>connect()</code> function returns an instance of the <code>Connection</code> class, which is assigned to the <code>conn</code> variable.</li> <li>The connection attributes are passed as keyword arguments to the<code>connect()</code>function.</li> <li>When you are done with a connection, close it to free resources. Close the connection using the <code>close()</code>method.</li> </ul>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Python%20App/#multiple-connections","title":"Multiple Connections","text":"<p>Instantiating the <code>Connection</code> class creates a single connection to MariaDB database products. Applications that require multiple connections may benefit from pooling connections.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Python%20App/#close-a-connection","title":"Close a Connection","text":"<p>MariaDB Connector/Python closes the connection as part of the class's destructor, which is executed when an instance of the class goes out of scope. This can happen in many cases, such as:</p> <ul> <li>When the program exits</li> <li>When the instance of the <code>Connection</code> class is defined in the local scope of a function, and the function returns</li> <li>When the instance of the <code>Connection</code> class is defined as an attribute of a custom class's instance, and the custom class's instance goes out of scope.</li> </ul> <p>Connections can also be explicitly closed using the <code>close()</code> method, which is helpful when the connection is no longer needed, but the variable is still in scope.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20Python%20App/#connection-failover","title":"Connection Failover","text":"<p>Starting with MariaDB Connector/Python 1.1 when MariaDB Connector/Python is built with MariaDB Connector/C 3.3, the connector supports connection failover when <code>auto_reconnect</code> is enabled and the connection string contains a comma-separated list of multiple server addresses.</p> <p>To enable connection failover:</p> <ul> <li>Call the <code>mariadb.connect</code> function with the <code>host</code> argument specified as a comma-separated list containing multiple server addresses. The connector attempts to connect to the addresses in the order specified in the list.</li> <li>Set <code>auto_reconnect</code> to <code>True</code>. If the connection fails, the connector will attempt to reconnect to the addresses in the order specified in the list.</li> </ul> <p>The following code example connects with connection failover enabled:</p> <pre><code># Module Import\nimport mariadb\nimport sys\n\n# Instantiate Connection\ntry:\n   conn = mariadb.connect(\n      host=\"192.0.2.1,192.0.2.0,198.51.100.0\",\n      port=3306,\n      user=\"db_user\",\n      password=\"USER_PASSWORD\")\n   conn.auto_reconnect = True\nexcept mariadb.Error as e:\n   print(f\"Error connecting to the database: {e}\")\n   sys.exit(1)\n\n# Use Connection\n# ...\n\n# Close Connection\nconn.close()\n</code></pre> <pre><code># Module Import\nimport mariadb\nimport sys\n\n# Instantiate Connection\ntry:\n   conn = mariadb.connect(\n      host=\"SKYSQL_SERVICE.mdb0000001.db.skysql.com,SKYSQL_SERVICE.mdb0000002.db.skysql.com\",\n      port=5009,\n      ssl_verify_cert=True,\n      user=\"DB00000001\",\n      password=\"USER_PASSWORD\")\n   conn.auto_reconnect = True\nexcept mariadb.Error as e:\n   print(f\"Error connecting to the database: {e}\")\n   sys.exit(1)\n\n# Use Connection\n# ...\n\n# Close Connection\nconn.close()\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%2B%2B%E2%80%99%20App/","title":"Connect from \u2018C++\u2019 App","text":"<p>MariaDB Connector/C++ enables C++ applications to establish client connections to SkySQL over TLS.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%2B%2B%E2%80%99%20App/#requirements","title":"Requirements","text":"<p>MariaDB Connector/C++ has dependencies. You must install MariaDB Connector/C to use it.</p> MariaDB Connector/C++ MariaDB Connector/C 1.1 3.2.3 or later 1.0 3.1.1 or later <p>For additional information, see \"MariaDB Connector/C++ Release Notes\".</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%2B%2B%E2%80%99%20App/#linux-installation-binary-tarball","title":"Linux Installation (Binary Tarball)","text":"<p>To install MariaDB Connector/C++ on Linux:</p> <ol> <li>Install MariaDB Connector/C.</li> <li>Go to the\u00a0MariaDB Connector C++ download page.</li> <li>In the \"OS\" dropdown, select the Linux distribution you want to use.</li> <li>Click the \"Download\" button to download the binary tarball.</li> <li> <p>Extract the tarball:</p> <pre><code>tar -xvzf mariadb-connector-cpp-*.tar.gz\n</code></pre> </li> <li> <p>Change into the relevant directory:</p> <pre><code>cd mariadb-connector-cpp-*/\n</code></pre> </li> <li> <p>Install the directories for the header files:</p> <pre><code>sudo install -d /usr/include/mariadb/conncpp\nsudo install -d /usr/include/mariadb/conncpp/compat\n</code></pre> </li> <li> <p>Install the header files:</p> <pre><code>sudo install include/mariadb/* /usr/include/mariadb/\nsudo install include/mariadb/conncpp/* /usr/include/mariadb/conncpp\nsudo install include/mariadb/conncpp/compat/* /usr/include/mariadb/conncpp/compat\n</code></pre> </li> <li> <p>Install the directories for the shared libraries:</p> <ul> <li> <p>On CentOS, RHEL, Rocky Linux:</p> <pre><code>sudo install -d /usr/lib64/mariadb\nsudo install -d /usr/lib64/mariadb/plugin\n</code></pre> </li> <li> <p>On Debian, Ubuntu:</p> <pre><code>sudo install -d /usr/lib/mariadb\nsudo install -d /usr/lib/mariadb/plugin\n</code></pre> </li> </ul> </li> <li> <p>Install the shared libraries:</p> <ul> <li> <p>On CentOS, RHEL, Rocky Linux:</p> <pre><code>sudo install lib64/mariadb/libmariadbcpp.so /usr/lib64\nsudo install lib64/mariadb/plugin/* /usr/lib64/mariadb/plugin\n</code></pre> </li> <li> <p>On Debian, Ubuntu:</p> <pre><code>sudo install lib/mariadb/libmariadbcpp.so /usr/lib\nsudo install lib/mariadb/plugin/* /usr/lib/mariadb/plugin\n</code></pre> </li> </ul> </li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%2B%2B%E2%80%99%20App/#windows-installation-msi","title":"Windows Installation (MSI)","text":"<p>To install MariaDB Connector/C++ on Windows:</p> <ol> <li>MariaDB Connector/C dependency will be installed when Connector/C++ is installed.</li> <li>Go to the\u00a0MariaDB Connector C++ download page for MS Windows.</li> <li>Click the \"Download\" button to download the MSI package.</li> <li>Run the MSI package and click \"Next\" to start the Setup Wizard.</li> <li>On the second screen, click the license agreement checkbox, then click \"Next.\"</li> <li>On the third screen, click \"Typical.\"</li> <li>On the fourth screen, click \"Install.\"</li> <li>Click \"Finish.\"</li> <li>Add the directory path that contains the\u00a0<code>mariadbcpp</code> <code>LIB</code>\u00a0file (example\u00a0<code>\"C:\\Program\u00a0Files\\MariaDB\\MariaDB\u00a0C++\u00a0Connector\u00a064-bit\"</code>) to\u00a0<code>PATH</code>\u00a0environment variable.</li> </ol> <p>For latest release visit C &amp; C++ Connectors</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%2B%2B%E2%80%99%20App/#connection-info","title":"Connection Info","text":"<p>The connection is configured via the information that is initially acquired from the SkySQL Portal pages:</p> What to set Where to find it Hostname in the URL The fully Qualified Domain Name from the \"Connect\" window in SkySQL portal Port number in the URL The Read-Write Port or Read-Only Port from the \"Connect\" window in SkySQL portal user\u00a0parameter The desired username, which might be the default username in the Service Credentials view password\u00a0parameter The user's password, which might be the default password in the Service Credentials view if it was not yet customized"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%2B%2B%E2%80%99%20App/#connection-url-syntax","title":"Connection URL Syntax","text":"<p>While MariaDB Connector/C++ supports several connection styles, we are going to detail just the JDBC syntax since all connections to SkySQL use a single idiom of hostname, port, user, password, and SSL parameters.</p> <p>The base URL is specified as follows:</p> <pre><code>jdbc:mariadb://example.skysql.com:5001/dbname\n</code></pre> <p>If the trailing database name is left off of the URL, the connection will start without selecting a database.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%2B%2B%E2%80%99%20App/#optional-connection-parameters","title":"Optional Connection Parameters","text":"<p>MariaDB Connector/C++ supports several optional connection parameters. These parameters can be specified using a\u00a0<code>Properties</code>\u00a0object, as we do in our examples, or appended to the URL in standard\u00a0<code>name=value</code>\u00a0query-string encoding.</p> <p>In the following list, we've left out any parameters that aren't pertinent to accessing SkySQL:</p> Parameter Name Description Type Default Aliases autoReconnect Defines whether the connector automatically reconnects after a connection failure. bool false OPT_RECONNECT connectTimeout Defines the connect timeout value in milliseconds. When set to\u00a00, there is no connect timeout. int 30000 enabledTlsCipherSuites A list of permitted ciphers or cipher suites to use for TLS. string enabledSslCipherSuites jdbcCompliantTruncation This mode is enabled by default. This mode configures the connector to add\u00a0STRICT_TRANS_TABLES\u00a0to\u00a0sql_mode, which causes ES to handle truncation issues as errors instead of warnings. bool true password Defines the password of the user account to connect with. socketTimeout Defines the network socket timeout (SO_TIMEOUT) in milliseconds. When set to\u00a00, there is no socket timeout. This connection parameter is not intended to set a maximum time for statements. To set a maximum time for statements, please see the\u00a0max_statement_time. int 0 OPT_READ_TIMEOUT tcpRcvBuf The buffer size for TCP/IP and socket communication.\u00a0tcpSndBuf\u00a0changes the same buffer value, and the biggest value of the two is selected. int 0x4000 tcpSndBuf tcpSndBuf The buffer size for TCP/IP and socket communication.\u00a0tcpRcvBuf\u00a0changes the same buffer value, and the biggest value of the two is selected. int 0x4000 tcpRcvBuf tlsCert Path to the X509 certificate file. string sslCert tlsCRL Path to a PEM file that should contain one or more revoked X509 certificates. string tlsCrl useCompression Compresses network traffic between the client and server. bool false CLIENT_COMPRESS user Defines the user name of the user account to connect with. userName useServerPrepStmts Defines whether the connector uses server-side prepared statements using the\u00a0PREPARE Statement,\u00a0EXECUTE statement, and\u00a0DEALLOCATE / DROP PREPARE statements\u00a0statements. By default, the connector uses client-side prepared statements. bool false useTls Whether to force TLS. This enables TLS with the default system settings. bool useSsl"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%2B%2B%E2%80%99%20App/#connection-methods","title":"Connection Methods","text":"<p>Two categories of methods are available to establish a connection.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%2B%2B%E2%80%99%20App/#sqldriverconnect","title":"sql::Driver::connect()","text":"<p>MariaDB Connector/C++ can connect using the non-static\u00a0<code>connect()</code>\u00a0methods in the\u00a0<code>sql::Driver</code>\u00a0class.</p> <p>The non-static\u00a0<code>connect()</code>\u00a0methods in the\u00a0<code>sql::Driver</code>\u00a0class have the following prototypes:</p> <ul> <li><code>Connection*\u00a0connect(const\u00a0SQLString&amp;\u00a0url,\u00a0Properties&amp;\u00a0props);</code></li> <li><code>Connection*\u00a0connect(const\u00a0SQLString&amp;\u00a0host,\u00a0const\u00a0SQLString&amp;\u00a0user,\u00a0const\u00a0SQLString&amp;\u00a0pwd);</code></li> <li><code>Connection*\u00a0connect(const\u00a0Properties&amp;\u00a0props);</code></li> </ul> <p>The non-static\u00a0<code>connect()</code>\u00a0methods in the\u00a0<code>sql::Driver</code>\u00a0class:</p> <ul> <li>Require an instance of the\u00a0<code>sql::Driver</code>\u00a0class to establish a connection.</li> <li>Return\u00a0<code>nullptr</code>\u00a0as the\u00a0<code>Connection*</code>\u00a0value when an error occurs, so applications should check the return value before use.</li> </ul> <p>For example:</p> <pre><code>// Instantiate Driver\nsql::Driver* driver = sql::mariadb::get_driver_instance();\n\n// Configure Connection, including an optional initial database name \"places\":\nsql::SQLString url(\"jdbc:mariadb://example.skysql.com:5009/places\");\n\n// Use a properties map for the other connection options\nsql::Properties properties({\n      {\"user\", \"db_user\"},\n      {\"password\", \"db_user_password\"},\n      {\"autocommit\", false},\n      {\"useTls\", true},\n      {\"tlsCert\", \"classpath:static/skysql_chain.pem\"},\n   });\n\n// Establish Connection\n// Use a smart pointer for extra safety\nstd::unique_ptr&lt;sql::Connection&gt; conn(driver-&gt;connect(url, properties));\n\nif (!conn) {\n   cerr &lt;&lt; \"Invalid database connection\" &lt;&lt; endl;\n   exit (EXIT_FAILURE);\n}\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%2B%2B%E2%80%99%20App/#sqldrivermanagergetconnection","title":"sql::DriverManager::getConnection()","text":"<p>MariaDB Connector/C++ can connect using the static\u00a0<code>getConnection()</code>\u00a0methods in the\u00a0<code>sql::DriverManager</code>\u00a0class.</p> <p>The static\u00a0<code>getConnection()</code>\u00a0methods in the\u00a0<code>sql::DriverManager</code>\u00a0class have the following prototypes:</p> <ul> <li><code>static\u00a0Connection*\u00a0getConnection(const\u00a0SQLString&amp;\u00a0url);</code></li> <li><code>static\u00a0Connection*\u00a0getConnection(const\u00a0SQLString&amp;\u00a0url,\u00a0Properties&amp;\u00a0props);</code></li> <li><code>static\u00a0Connection*\u00a0getConnection(const\u00a0SQLString&amp;\u00a0url,\u00a0const\u00a0SQLString&amp;\u00a0user,\u00a0const\u00a0SQLString&amp;\u00a0pwd);</code></li> </ul> <p>The static\u00a0<code>getConnection()</code>\u00a0methods in the\u00a0<code>sql::DriverManager</code>\u00a0class:</p> <ul> <li>Do not require an instance of the\u00a0<code>sql::DriverManager</code>\u00a0class to establish a connection, because they are static.</li> <li>Throw an exception when an error occurs, so applications should use\u00a0<code>try\u00a0{\u00a0..\u00a0}\u00a0catch\u00a0(\u00a0..\u00a0)\u00a0{\u00a0..\u00a0}</code>\u00a0to catch the exception.</li> </ul> <p>For example:</p> <pre><code>try {\n    // Configure Connection, including an optional initial database name \"places\":\n    sql::SQLString url(\"jdbc:mariadb://example.skysql.com:5009/places\");\n\n    // Use a properties map for the other connection options\n    sql::Properties properties({\n          {\"user\", \"db_user\"},\n          {\"password\", \"db_user_password\"},\n          {\"autocommit\", false},\n          {\"useTls\", true},\n          {\"tlsCert\", \"classpath:static/skysql_chain.pem\"},\n       });\n\n    // Establish Connection\n    // Use a smart pointer for extra safety\n    std::unique_ptr&lt;sql::Connection&gt; conn(DriverManager::getConnection(url, properties));\n } catch (...) {\n    cerr &lt;&lt; \"Invalid database connection\" &lt;&lt; endl;\n    exit (EXIT_FAILURE);\n}\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%2B%2B%E2%80%99%20App/#code-example-connect","title":"Code Example: Connect","text":"<p>The following code demonstrates how to connect using the\u00a0example database and user account:</p> <pre><code>// Includes\n#include &lt;iostream&gt;\n#include &lt;mariadb/conncpp.hpp&gt;\n\n// Main Process\nint main(int argc, char **argv)\n{\n   try {\n      // Instantiate Driver\n      sql::Driver* driver = sql::mariadb::get_driver_instance();\n\n      // Configure Connection, including initial database name \"test\":\n      sql::SQLString url(\"jdbc:mariadb://example.skysql.com:5009/test\");\n\n      // Use a properties map for the other connection options\n      sql::Properties properties({\n            {\"user\", \"db_user\"},\n            {\"password\", \"db_user_password\"},\n            {\"autocommit\", false},\n            {\"useTls\", true},\n            {\"tlsCert\", \"classpath:static/skysql_chain.pem\"},\n         });\n\n      // Establish Connection\n      // Use a smart pointer for extra safety\n      std::unique_ptr&lt;sql::Connection&gt; conn(driver-&gt;connect(url, properties));\n\n      // Use Connection\n      // ...\n\n      // Close Connection\n      conn-&gt;close();\n   }\n\n   // Catch Exceptions\n   catch (sql::SQLException&amp; e) {\n      std::cerr &lt;&lt; \"Error Connecting to the database: \"\n         &lt;&lt; e.what() &lt;&lt; std::endl;\n\n      // Exit (Failed)\n      return 1;\n   }\n\n   // Exit (Success)\n   return 0;\n}\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%E2%80%99%20App/","title":"Connect from \u2018C\u2019 App","text":"<p>MariaDB Connector/C enables C and C++ applications to establish client connections to SkySQL over TLS. MariaDB Connector/C is a native connector that is written in C.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%E2%80%99%20App/#first-install-mariadb-connectorc","title":"First Install MariaDB Connector/C","text":"<p>MariaDB Connector/C enables C and C++ applications to establish client connections to SkySQL and MariaDB database products over TLS.</p> <p>Additional information on MariaDB Connector/C is available in the\u00a0MariaDB Knowledge Base.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%E2%80%99%20App/#connection-info","title":"Connection Info","text":"<p>The connection is configured via the information that is initially acquired from the SkySQL Portal pages:</p> Function Option/Argument Where to find it mysql_real_connect() host\u00a0argument The fully Qualified Domain Name from the \"Connect\" window in SkySQL portal mysql_real_connect() user\u00a0argument The desired username, which might be the default username in the Service Credentials view mysql_real_connect() passwd\u00a0argument The user's password, which might be the default password in the Service Credentials view if it was not yet customized mysql_real_connect() port\u00a0argument The Read-Write Port or Read-Only Port from the \"Connect\" window in SkySQL portal"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20from%20%E2%80%98C%E2%80%99%20App/#code-example","title":"Code Example","text":"<p>The following code demonstrates how to use MariaDB Connector/C to connect to SkySQL. This example uses the\u00a0example database and user account:</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;mysql.h&gt;\n\nint main (int argc, char* argv[])\n{\n\n   // Initialize Connection\n   MYSQL *conn;\n   if (!(conn = mysql_init(0)))\n   {\n      fprintf(stderr, \"unable to initialize connection struct\\n\");\n      exit(1);\n   }\n\n   // Connect to the database\n   if (!mysql_real_connect(\n         conn,                 // Connection\n         \"example.skysql.com\", // Host\n         \"db_user\",            // User account\n         \"db_user_password\",   // User password\n         \"test\",               // Default database\n         3006,                 // Port number\n         NULL,                 // Path to socket file\n         0                     // Additional options\n      ))\n   {\n      // Report the failed-connection error &amp; close the handle\n      fprintf(stderr, \"Error connecting to Server: %s\\n\", mysql_error(conn));\n      mysql_close(conn);\n      exit(1);\n   }\n\n   // Use the Connection\n   // ...\n\n   // Close the Connection\n   mysql_close(conn);\n\n   return 0;\n}\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20Connector%20R2DBC/","title":"Connect using Connector/R2DBC","text":"<p>Java developers can use MariaDB Connector/R2DBC to connect to SkySQL using the Reactive Relational Database Connectivity (R2DBC) API. R2DBC operations are non-blocking, which makes the R2DBC API more scalable than Java's standard JDBC API. MariaDB Connector/R2DBC is available both with a native R2DBC implementation and the Spring Data R2DBC framework.</p> <p>Visit MariaDB R2DBC Connector page.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20Connector%20R2DBC/#resources","title":"Resources","text":"<ul> <li>Release notes</li> </ul>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20MariaDB%20CLI/","title":"Connect using MariaDB CLI","text":"<p>MariaDB Client is available for all major operating systems.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20MariaDB%20CLI/#1-installation","title":"1. Installation","text":"<p>Installation of MariaDB Client varies by operating system.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20MariaDB%20CLI/#macos","title":"MacOS","text":"<ol> <li> <p>Install Homebrew if you don't have it already:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre> </li> <li> <p>Install MariaDB Client:</p> <pre><code>brew install mariadb\n</code></pre> </li> <li> <p>Verify the installation:</p> <pre><code>mariadb --version\n</code></pre> </li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20MariaDB%20CLI/#centos-rhel","title":"CentOS / RHEL","text":"<ol> <li> <p>Configure YUM package repositories:</p> <pre><code>sudo yum install wget\nwget https://downloads.mariadb.com/MariaDB/mariadb_repo_setup\necho \"30d2a05509d1c129dd7dd8430507e6a7729a4854ea10c9dcf6be88964f3fdc25 mariadb_repo_setup\" \\\n    | sha256sum -c -\n\nchmod +x mariadb_repo_setup\n\nsudo ./mariadb_repo_setup --mariadb-server-version=\"mariadb-10.11\"\n</code></pre> </li> <li> <p>Install MariaDB Client and package dependencies:</p> <pre><code>sudo yum install MariaDB-client\n</code></pre> </li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20MariaDB%20CLI/#debian-ubuntu","title":"Debian / Ubuntu","text":"<ol> <li> <p>Configure APT package repositories:</p> <pre><code>sudo apt install wget\n\nwget https://downloads.mariadb.com/MariaDB/mariadb_repo_setup\n\necho \"30d2a05509d1c129dd7dd8430507e6a7729a4854ea10c9dcf6be88964f3fdc25 mariadb_repo_setup\" \\\n    | sha256sum -c -\n\nchmod +x mariadb_repo_setup\n\nsudo ./mariadb_repo_setup --mariadb-server-version=\"mariadb-10.11\"\n\nsudo apt update\n</code></pre> </li> <li> <p>Install MariaDB Client and package dependencies:</p> <pre><code>sudo apt install mariadb-client\n</code></pre> </li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20MariaDB%20CLI/#sles","title":"SLES","text":"<ol> <li> <p>Configure ZYpp package repositories:</p> <pre><code>sudo zypper install wget\n\nwget https://downloads.mariadb.com/MariaDB/mariadb_repo_setup\n\necho \"30d2a05509d1c129dd7dd8430507e6a7729a4854ea10c9dcf6be88964f3fdc25 mariadb_repo_setup\" \\\n    | sha256sum -c -\n\nchmod +x mariadb_repo_setup\n\nsudo ./mariadb_repo_setup --mariadb-server-version=\"mariadb-10.6\"\n</code></pre> </li> <li> <p>Install MariaDB Client and package dependencies:     <pre><code>sudo zypper install MariaDB-client\n</code></pre></p> </li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20MariaDB%20CLI/#windows","title":"Windows","text":"<ol> <li> <p>Access MariaDB Downloads for MariaDB Community Server.</p> </li> <li> <p>In the \"Version\" dropdown, select the version you want to download.</p> </li> <li> <p>In the \"OS\" dropdown, select \"MS Windows (64-bit)\".</p> </li> <li> <p>Click the \"Download\" button to download the MSI package.</p> </li> <li> <p>When the MSI package finishes downloading, run it.</p> </li> <li> <p>On the first screen, click \"Next\" to start the Setup Wizard.</p> </li> <li> <p>On the second screen, click the license agreement checkbox, and then click \"Next\".</p> </li> <li> <p>On the third screen, select the components you want to install. If you only want the standard MariaDB Client tools:</p> <ul> <li>Deselect \"Database instance\".</li> <li>Deselect \"Backup utilities\".</li> <li>Deselect \"Development Components\".</li> <li>Deselect \"Third party tools\".</li> </ul> <p>When only \"Client programs\" is selected, click \"Next\".</p> </li> <li> <p>On the next screen, click \"Install\".</p> </li> <li> <p>When the installation process completes, click \"Finish\".</p> </li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20MariaDB%20CLI/#2-connect","title":"2. Connect","text":""},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20MariaDB%20CLI/#linux","title":"Linux","text":"<ol> <li> <p>Determine the connection parameters for your SkySQL service.</p> </li> <li> <p>Use your connection parameters in the following command line:</p> <pre><code>mariadb --host dbpwf03798702.sysp0000.db1.skysql.com --port 3306 \\\n    --user dbpwf03798702 -p --ssl-verify-server-cert\n</code></pre> <ul> <li> <p>Replace 'dbpwf03798702.sysp0000.db1.skysql.com' with the Fully Qualified Domain Name of your service.</p> </li> <li> <p>You can use 3307 for the port if running with Replicas. This is the read-only port of your service.</p> </li> <li> <p>Replace the user name with the one for your service. </p> </li> </ul> </li> <li> <p>After the command is executed, you will be prompted for the password of your database user account. Enter the default password for your default user, the password you set for the default user, or the password for the database user you created.</p> </li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20MariaDB%20CLI/#windows_1","title":"Windows","text":"<ol> <li> <p>Fix your executable search path.</p> </li> <li> <p>On Windows, MariaDB Client is not typically found in the executable search path by default. You must find its installation path, and add that path to the executable search path:</p> <pre><code>SET \"PATH=C:\\Program Files\\MariaDB 10.6\\bin;%PATH%\"\n</code></pre> </li> <li> <p>Use your connection parameters in the following command line:</p> <pre><code>mariadb --host dbpwf03798702.sysp0000.db1.skysql.com --port 3306 \\\n    --user dbpwf03798702 -p --ssl-verify-server-cert\n</code></pre> <ul> <li> <p>Replace 'dbpwf03798702.sysp0000.db1.skysql.com' with the Fully Qualified Domain Name of your service.</p> </li> <li> <p>You can use 3307 for the port if running with Replicas. This is the read-only port of your service.</p> </li> <li> <p>Replace the user name with the one for your service. </p> </li> </ul> </li> <li> <p>After the command is executed, you will be prompted for the password of your database user account. Enter the default password for your default user, the password you set for the default user, or the password for the database user you created.</p> </li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20ODBC/","title":"Connect using ODBC","text":""},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20ODBC/#overview","title":"Overview","text":"<p>Application developers can use MariaDB Connector/ODBC to establish a data source for client connections with SkySQL.</p> <p>The method for configuring the data source varies between operating systems.</p>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20ODBC/#configuring-a-data-source-on-linux","title":"Configuring a Data Source on Linux","text":"<ol> <li> <p>Configure <code>unixODBC</code> to recognize the driver by creating a file called <code>MariaDB_odbc_driver_template.ini</code>with the relevant driver definition.</p> <p>For example, on CentOS / RHEL / Rocky Linux:</p> <pre><code>[MariaDB ODBC 3.1 Driver]\nDescription = MariaDB Connector/ODBC v.3.1\nDriver      = /usr/lib64/libmaodbc.so\n</code></pre> <p>On Debian / Ubuntu:</p> <pre><code>[MariaDB ODBC 3.1 Driver]\nDescription = MariaDB Connector/ODBC v.3.1\nDriver      = /usr/lib/libmaodbc.so\n</code></pre> </li> <li> <p>Install the driver using the <code>odbcinst</code> command.</p> <p>For example:</p> <pre><code>sudo odbcinst -i -d -f MariaDB_odbc_driver_template.ini\n</code></pre> </li> <li> <p>Determine the connection parameters for your database.</p> </li> <li> <p>Configure <code>unixODBC</code> to connect to the data source by creating a file called <code>MariaDB_odbc_data_source_template.ini</code>with the relevant data source parameters. Be sure to specify <code>SSLVERIFY = 1</code> for your SkySQL database.</p> <p>For example:</p> <pre><code># Data Source for unixODBC\n[My-Test-Server]\nDescription = Describe your database setup here\nDriver      = MariaDB ODBC 3.1 Driver\nTrace       = Yes\nTraceFile   = /tmp/trace.log\nSERVER      = localhost\nSOCKET      = /var/run/mysqld/mysqld.sock\nUSER        = db_user\nPASSWORD    = db_user_password\nDATABASE    = test\n</code></pre> <pre><code># Data Source for unixODBC\n[My-Test-Server]\nDescription = Describe your database setup here\nDriver      = MariaDB ODBC 3.1 Driver\nTrace       = Yes\nTraceFile   = /tmp/trace.log\nSERVER      = example.skysql.com\nPORT        = 3306\nSSLVERIFY   = 1\nUSER        = db_user\nPASSWORD    = db_user_password\nDATABASE    = test\n</code></pre> <ul> <li>Customize the values of the parameters with the relevant information for your environment.</li> <li>If you have SSL certificate files, you can add the following parameters to your data source file:</li> </ul> <pre><code>SSLCA = /path/to/ca-cert.pem\nSSLKEY = /path/to/client-key.pem\nSSL_CERT = /path/to/client-cert.pem\n</code></pre> </li> <li> <p>Install the <code>unixODBC</code> data source template file:</p> <pre><code>$ sudo odbcinst -i -s -h -f MariaDB_odbc_data_source_template.ini\n</code></pre> </li> <li> <p>Test the data source <code>My-Test-Server</code>configured in the <code>MariaDB_odbc_data_source_template.ini</code> file using the <code>isql</code> command. If you see the output below, you have successfully connected to your Sky database.</p> <pre><code>$ isql -v My-Test-Server\n+-------------------------+\n| Connected!              |\n| sql-statement           |\n| help[tablename]         |\n| quit                    |\n+-------------------------+\nSQL&gt;\n</code></pre> </li> <li> <p>To select your new data source in your application, select the data source with the name that you configured, which is <code>My-Test-Server</code> in the above example.</p> </li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20ODBC/#configuring-a-data-source-on-macos","title":"Configuring a Data Source on macOS","text":"<ol> <li> <p>Confirm that MariaDB Connector/ODBC has been registered with<code>iODBC</code> by confirming that the following options are set in the <code>iODBC</code>configuration file at <code>/Library/ODBC/odbcinst.ini</code>:</p> <pre><code>[ODBC]\nTrace     = no\nTraceFile = /tmp/iodbc_trace.log\n\n[ODBC Drivers]\nMariaDB ODBC 3.1 Unicode Driver = Installed\n\n[MariaDB ODBC 3.1 Unicode Driver]\nDriver      = /Library/MariaDB/MariaDB-Connector-ODBC/libmaodbc.dylib\nDescription = MariaDB Connector/ODBC(Unicode) 3.1 64bit\nThreading   = 0\n</code></pre> </li> <li> <p>Determine the connection parameters for your database.</p> </li> <li> <p>Add a data source for your database to <code>iODBC</code> by adding the following options to the <code>iODBC</code> configuration file at <code>/Library/ODBC/odbc.ini</code>:</p> <pre><code>[ODBC Data Sources]\nMy-Test-Server = MariaDB ODBC 3.1 Unicode Driver\n\n[My-Test-Server]\nDriver   = /Library/MariaDB/MariaDB-Connector-ODBC/libmaodbc.dylib\nSERVER   = 192.0.2.1\nDATABASE = test\nUSER     = db_user\nPASSWORD = db_user_password\n</code></pre> <ul> <li>Substitute the values of the <code>SERVER</code>, <code>SOCKET</code>, <code>DATABASE</code>, <code>PORT</code>, <code>USER</code>, and <code>PASSWORD</code> parameters with the relevant value for your environment.</li> <li>Test the data source using the <code>iodbctest</code>command:</li> </ul> <pre><code>iodbctest \"DSN=My-Test-Server\"\n</code></pre> </li> <li> <p>To select your new data source in your application, select the data source with the name that you configured, which is <code>My-Test-Server</code> in the above example.</p> </li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20ODBC/#configuring-a-data-source-on-windows","title":"Configuring a Data Source on Windows","text":"<p>MariaDB Connector/ODBC requires at least Windows 8.</p> <p>Windows 10 was used to prepare these instructions. When using other versions of Windows, these instructions may require adjustment.</p> <ol> <li>In the start menu, search for \"ODBC Data Sources\".</li> <li>In the search results, open the application called \"ODBC Data Sources (32-bit)\" or \"ODBC Data Sources (64-bit)\", depending on whether you need a data source for a 32-bit or 64-bit application.</li> <li>In the ODBC Data Source Administrator, click the \"Add\" button on the right side.</li> <li>In the \"Create New Data Source\" window:<ul> <li>Click on \"MariaDB ODBC 3.1 Driver\" in the list.</li> <li>Click the \"Finish\" button.</li> </ul> </li> <li>In the \"Create a new Data Source to MariaDB\" window:<ul> <li>In the \"Name\" text box, enter a name for the data source.</li> <li>In the \"Description\" test box, enter a description for the data source.</li> <li>Click the \"Next\" button.</li> </ul> </li> <li>In the next window, provide the connection credentials:<ul> <li>In the \"Server Name\" field, provide the IP address or domain name for the Server.</li> <li>In the \"User name\" field, provide the username for the database user account.</li> <li>In the \"Password\" field, provide the password for that user.</li> <li>In the \"Database\" field, provide the default database to use.</li> <li>Then, click the \"Next\" button.</li> </ul> </li> </ol> <p></p> <ol> <li>Continue configuring the data source using the wizard:<ul> <li>The wizard provides a series of windows for configuring various aspects of the connection. Enable settings you want to use.</li> <li>Click the \"Next\" button to move onto the next window in the wizard.</li> <li>In the \"TLS Settings\" window, make sure that \"Verify Certificate\" is checked. You can also add your certificate information here.</li> </ul> </li> </ol> <p></p> <ol> <li>Click the \"Finish\" on the last window to exit the wizard and save your data source.<ul> <li>To test your connection, double-click the data source you have created to open the configuration window again. Click \"Next\" to reach the window titled \"How do you want to connect to MariaDB\" and click the button labeled \"Test DSN\". If you see the message below, you have successfully connected.</li> </ul> </li> </ol> <p></p> <ol> <li>To select your new data source in your application, select the data source with the name that you configured for the \"Name\" field.</li> </ol>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20ODBC/#failover","title":"Failover","text":"<p>MariaDB Connector/ODBC supports failover in case one or more hosts are not available.</p> <p>The failover feature requires using MariaDB Connector/ODBC 3.1.16 or greater with MariaDB Connector/C 3.3 or greater.</p> <p><code>MariaDB Connector/ODBC 3.1.16</code> and greater is statically linked for Windows and macOS with <code>MariaDB Connector/C 3.3.1</code>.  <code>MariaDB Connector/ODBC 3.1.16</code> and greater is dynamically linked for Linux with MariaDB Connector/C.</p> <p>The failover feature is enabled by providing a comma separated list of hosts as a server name.</p> <p>The failover host string is the <code>SERVER</code> string. If the <code>SERVER</code> string does not include a port, the default port will be used.</p> <p>The following syntax is required:</p> <ul> <li>IPv6 addresses must be enclosed within square brackets <code>\"[]\"</code></li> <li>hostname and port must be separated by a colon <code>\":\"</code></li> <li><code>hostname:port</code> pairs must be be separated by a comma <code>\",\"</code></li> <li>If only one <code>hostname:port</code> is specified, the host string must end with a comma</li> <li>If no port is specified, the default port will be used</li> </ul> <p>An example of a failover host string:</p> <pre><code>[::1]:3306,192.168.0.1:3307,test.example.com\n</code></pre>"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20ODBC/#connection-parameters","title":"Connection Parameters","text":"Connection Parameter Description Default Value DRIVER \u2022 On Linux, the name of the driver, which is configured in the unixODBC driver template file. On macOS, the path to the driver's shared library, which is installed at /Library/MariaDB/MariaDB-Connector-ODBC/libmaodbc.dylib by default. SERVER Host name, IPv4 address, or IPv6 address of the database server. localhost SOCKET The path to the socket file. On Linux, MariaDB Mariadb Server uses different default socket files on different Linux distributions. On Debian / Ubuntu, the default socket file is /var/run/mysqld/mysqld.sock or /run/mysqld/mysqld.sock. On CentOS / RHEL / Rocky Linux, the default socket file is /var/lib/mysql/mysql.sock. /tmp/mysql.sock DATABASE Database name to select upon successful connection. The database must already exist, and the user account must have privileges to select it. PORT TCP port of the database server. 3306 USER The username to use for authentication. PASSWORD User password. FORWARDONLY When enabled, cursors are created as SQL_CURSOR_FORWARD_ONLY, so they can only move forward. Starting in Connector/ODBC 3.2, cursors are SQL_CURSOR_FORWARD_ONLY by default. In previous releases, cursors were created as SQL_CURSOR_STATIC by default. NO_CACHE When enabled, result set streaming is enabled, which enables the application to fetch result sets from the server row-by-row instead of caching the entire result set on the client side. Since the application is not caching the entire result set, the application is less likely to run out of memory when working with large result sets. STREAMRS Alias for the NO_CACHE connection parameter. OPTIONS See OPTIONS Bitmask PREPONCLIENT When enabled, the SQLPrepare ODBC API function uses the text protocol and client-side prepared statements (CSPS). ATTR Sets connection attributes that can be queried via the Performance Schema session_connect_attrs Table when the Performance Schema is enabled. Specify attributes in the format ATTR={=[,&lt;attrname2=attrvalue2,...]} What Where to find it DRIVER \u2022 On Linux, the name of the driver, which is configured in the unixODBC driver template file. On macOS, the path to the driver's shared library, which is installed at /Library/MariaDB/MariaDB-Connector-ODBC/libmaodbc.dylib by default. SERVER Fully Qualified Domain Name in the https://www.notion.so../../../connection-parameters-portal/ PORT Read-Write Port or Read-Only Port in the https://www.notion.so../../../connection-parameters-portal/ USER Default username in the Service Credentials view, or the username you created PASSWORD Default password in the Service Credentials view, the password you set on the default user, or the password for the user you created SSLVERIFY Set to 1 to connect with SSL FORCETLS Set to 1 to enable TLS FORWARDONLY When enabled, cursors are created as SQL_CURSOR_FORWARD_ONLY, so they can only move forward. Starting in Connector/ODBC 3.2, cursors are SQL_CURSOR_FORWARD_ONLY by default. In previous releases, cursors were created as SQL_CURSOR_STATIC by default. NO_CACHE When enabled, result set streaming is enabled, which enables the application to fetch result sets from the server row-by-row instead of caching the entire result set on the client side. Since the application is not caching the entire result set, the application is less likely to run out of memory when working with large result sets. STREAMRS Alias for the NO_CACHE connection parameter. OPTIONS See OPTIONS Bitmask PREPONCLIENT When enabled, the SQLPrepare ODBC API function uses the text protocol and client-side prepared statements (CSPS). ATTR Sets connection attributes that can be queried via the Performance Schema session_connect_attrs Table when the Performance Schema is enabled. Specify attributes in the format ATTR={=[,&lt;attrname2=attrvalue2,...]}"},{"location":"Connecting%20to%20SkySQL%20DBs/Connect%20using%20ODBC/#options-bitmask","title":"<code>OPTIONS</code> Bitmask","text":"<p>The <code>OPTIONS</code> bitmask contains the following bits:</p> Bit Number Bit Value Description 0 1 Unused 1 2 Tells connector to return the number of matched rows instead of number of changed rows 4 16 Same as NO_PROMPT connection parameter 5 32 Forces all cursors to be dynamic 6 64 Forbids the DATABASE_NAME.TABLE_NAME.COLUMN_NAME syntax 11 2048 Enables compression in the protocol 13 8192 Same as the NAMEDPIPE connection parameter 16 65536 Same as the USE_MYCNF connection parameter 20 1048576 Same as the NO_CACHE connection parameter 21 2097152 Same as the FORWARDONLY connection parameter 22 4194304 Same as the AUTO_RECONNECT connection parameter 26 67108864 Enables multi-statement queries"},{"location":"Data%20loading%2C%20Migration/","title":"Migrate your database to SkySQL","text":"<p>SkySQL provides a range of options to suit different migration scenarios.</p> <ul> <li> Databases can be migrated to SkySQL from many different database platforms, including Oracle, MySQL, PostgreSQL, Microsoft SQL Server, IBM DB2, and more. </li> <li> SkySQL supports migration from both on-premise and cloud-based infrastructure and provides a range of options to suit different migration scenarios. </li> </ul> <p>Below are the most common scenarios for database migration to SkySQL.</p>"},{"location":"Data%20loading%2C%20Migration/#prerequisites","title":"Prerequisites","text":"<ol> <li>An active SkySQL account. </li> <li>An existing source database with the IP added to your SkySQL allowlist.</li> </ol> Considerations   Ensure that your SkySQL servce deploymned configuration is compatible with your existing source database one, including: <ul> <li>Deployment region - Ensure that the SkySQL deployment region is the same as the source database region.</li> <li>Topology - Mariadb Server Single node or with Replica(s)</li> <li> Server version - Ensure that the SkySQL server version is compatible with the source database version. </li> <li>Instance size - Ensure that the SkySQL instance is compatible with the source database instance type and size</li> <li>Storage - Ensure that the SkySQL storage type and size is compatible with the source database</li>"},{"location":"Data%20loading%2C%20Migration/#skydba-assisted-migration","title":"SkyDBA Assisted Migration","text":"<ul> <li>Existing customers can submit a\u00a0support case\u00a0to request assistance with a migration.</li> <li>New customers can\u00a0contact us\u00a0to begin the migration planning process.</li> </ul> <p>Our SkyDBA team can help design a migration plan to suit your needs.</p> SkyDBA Assisted Migration Approach   We use a multi-step process to assist customers with migrations: <ul> <li>Assessment of application requirements, inventory, and identified challenges</li> <li>Schema Migration including tables, constraints, indexes, and views</li> <li>Application Code Migration by porting and testing SQL and application code</li> <li>Data Migration and Replication with import of data, with conversion to the new schema, and ongoing inbound replication of new data</li> <li>Quality Assurance to assess data validity, data integrity, performance, accuracy of query results, stored code, and running code such as client applications, APIs, and batch jobs</li> <li>Cutover including final database preparation, fallback planning, switchover, and decommissioning of old databases</li>"},{"location":"Data%20loading%2C%20Migration/#self-service-migration-to-skysql","title":"Self-Service Migration to SkySQL","text":"<p>SkySQL provides two diffeent options for self-service migration </p>"},{"location":"Data%20loading%2C%20Migration/#option-1-migrate-using-the-skysql-rest-api","title":"Option 1: Migrate using the SkySQL REST API","text":"<p>SkySQL Managed Migration is a REST-based service that handles the migration process, including data migration, schema migration, and user migration. It provides a follow us steps to set up a live replication of your database to SkySQL and various insights to monitor the migration process.</p> <ul> <li>Sky SQL Managed Migration Tutorial</li> </ul>"},{"location":"Data%20loading%2C%20Migration/#option-2-custom-migration","title":"Option 2: Custom Migration","text":"<p>For most small, mid-size and large migrations SkySQL Managed Migration is the quickest and safest option. However, for large migrations or migrations with specific requirements, you and your team may require more flexibility and control over the migration process. In these cases, you and your team can design a custom migration plan considering the options suggested below.</p> <ul> <li>Migrating Using a Logical Dump and Replication</li> <li>Importing data using Mariadb Import</li> <li>Importing using CSV Data</li> <li>Replicating Data from an External DB</li> </ul>"},{"location":"Data%20loading%2C%20Migration/Import-CSV-data/","title":"Import CSV data","text":"<p>SkySQL customers can import data into a SkySQL service using the\u00a0<code>LOAD\u00a0DATA\u00a0LOCAL\u00a0INFILE</code>\u00a0SQL statement:</p> <ul> <li>The\u00a0<code>LOAD\u00a0DATA\u00a0LOCAL\u00a0INFILE</code>\u00a0statement can import data from TSV and CSV files</li> <li>The\u00a0<code>LOAD\u00a0DATA\u00a0LOCAL\u00a0INFILE</code>\u00a0statement can be executed by any client or connector</li> </ul> <p>Note</p> <p>Make sure your schema is already created in the database. If you need to import entire databases or create tables, you should use mariab-import.</p>"},{"location":"Data%20loading%2C%20Migration/Import-CSV-data/#enable-local-infiles","title":"Enable Local Infiles","text":"<p>Support for local infiles must be enabled on the client side and on the SkySQL service.</p>"},{"location":"Data%20loading%2C%20Migration/Import-CSV-data/#enable-local-infiles-on-the-client-or-connector","title":"Enable Local Infiles on the Client or Connector","text":"<p>To execute the\u00a0<code>LOAD\u00a0DATA\u00a0LOCAL\u00a0INFILE</code>\u00a0statement, most clients and connectors require a specific option to be enabled.</p> <p>If you are using\u00a0<code>mariadb</code>\u00a0client, the\u00a0<code>--local-infile</code>\u00a0option\u00a0must be specified.</p>"},{"location":"Data%20loading%2C%20Migration/Import-CSV-data/#enable-local-infiles-in-skysql","title":"Enable Local Infiles in SkySQL","text":"<p>Support for local infiles must be enabled on the SkySQL service.</p> <p>For SkySQL services that use MariaDB Server, the\u00a0local_infile\u00a0system variable\u00a0must be enabled:</p> <ul> <li>For Replicated Transactions and Single Node Transactions services, the\u00a0<code>local_infile</code>\u00a0system variable\u00a0is\u00a0<code>OFF</code>\u00a0by default</li> </ul> <p>Configuration Manager\u00a0can be used to modify the value of the\u00a0<code>local_infile</code>\u00a0system variable.</p>"},{"location":"Data%20loading%2C%20Migration/Import-CSV-data/#import-data","title":"Import Data","text":"<ol> <li>Determine the\u00a0connection parameters\u00a0for your SkySQL service.</li> <li>Connect with the\u00a0<code>mariadb</code>\u00a0client and specify the\u00a0-local-infile\u00a0option, which is needed by the next step:</li> </ol> <pre><code>mariadb --host FULLY_QUALIFIED_DOMAIN_NAME --port TCP_PORT \\\n      --user DATABASE_USER --password \\\n      --ssl-verify-server-cert \\\n      --default-character-set=utf8 \\\n      --local-infile\n</code></pre> <p>After the command is executed, you will be prompted for a password. Enter the default password for your default user, the password you set for the default user, or the password for the database user you created.</p> <p>For each table that you want to import, execute the\u00a0LOAD\u00a0DATA\u00a0LOCAL\u00a0INFILE\u00a0statement to import the data from the TSV or CSV file into your SkySQL database service.</p> <p>For a TSV file:</p> <pre><code>LOAD DATA LOCAL INFILE 'contacts.tsv'\nINTO TABLE accounts.contacts;\n</code></pre> <p>For a CSV file:</p> <pre><code>LOAD DATA LOCAL INFILE 'contacts.csv'\nINTO TABLE accounts.contacts\nFIELDS TERMINATED BY ',';\n</code></pre>"},{"location":"Data%20loading%2C%20Migration/Import-CSV-data/#using-a-connector","title":"Using a Connector","text":"<p>If you are using a MariaDB Connector, then you must select the method for the specific connector from the list below.</p> <p>If you are using <code>MariaDB Connector/C</code>, the\u00a0<code>MYSQL_OPT_LOCAL_INFILE</code>\u00a0option can be set with the\u00a0<code>mysql_optionsv()</code>\u00a0function:</p> <pre><code>/* enable local infile */\nunsigned int enable_local_infile = 1;\nmysql_optionsv(mysql, MYSQL_OPT_LOCAL_INFILE, (void *) &amp;enable_local_infile);\n</code></pre> <p>If you are using <code>MariaDB Connector/J</code>, the\u00a0<code>allowLocalInfile</code>\u00a0parameter can be set for the connection:</p> <pre><code>Connection connection = DriverManager.getConnection(\"jdbc:mariadb://FULLY_QUALIFIED_DOMAIN_NAME:TCP_PORT/test?user=DATABASE_USER&amp;password=DATABASE_PASSWORD&amp;allowLocalInfile=true\");\n</code></pre> <p>If you are using <code>MariaDB Connector/Node.js</code>, the\u00a0<code>permitLocalInfile</code>\u00a0parameter can be set for the connection:</p> <pre><code>mariadb.createConnection({\n   host: 'FULLY_QUALIFIED_DOMAIN_NAME',\n   port: 'TCP_PORT',\n   user:'DATABASE_USER',\n   password: 'DATABASE_PASSWORD',\n   permitLocalInfile: 'true'\n });\n</code></pre> <p>If you are using <code>MariaDB Connector/Python</code>, the\u00a0<code>local_infile</code>\u00a0parameter can be set for the connection:</p> <pre><code>conn = mariadb.connect(\n   user=\"DATABASE_USER\",\n   password=\"DATABASE_PASSWORD\",\n   host=\"FULLY_QUALIFIED_DOMAIN_NAME\",\n   port=TCP_PORT,\n   local_infile=true)\n</code></pre>"},{"location":"Data%20loading%2C%20Migration/Install%20Mariadb-dump/","title":"Install Mariadb-dump","text":"<p>SkySQL customers can manually create a backup of a SkySQL service using the\u00a0<code>mariadb-dump</code>\u00a0utility:</p> <ul> <li>The\u00a0<code>mariadb-dump</code>\u00a0utility provides a command-line interface (CLI)</li> <li>The\u00a0<code>mariadb-dump</code>\u00a0utility is available for Linux and Windows</li> <li>The\u00a0<code>mariadb-dump</code>\u00a0utility supports\u00a0many command-line options</li> <li>Egress charges may apply for customer-initiated backups</li> </ul> <p>For details about restoring a backup created with the\u00a0<code>mariadb-dump</code>\u00a0utility, see \"Restore a Manual Backup\".</p>"},{"location":"Data%20loading%2C%20Migration/Install%20Mariadb-dump/#installation","title":"Installation","text":"<p>Installation of MariaDB Dump varies by operating system.</p>"},{"location":"Data%20loading%2C%20Migration/Install%20Mariadb-dump/#centos-rhel","title":"CentOS / RHEL","text":"<ol> <li> <p>Configure YUM package repositories:</p> <pre><code>sudo yum install wget\nwget https://downloads.mariadb.com/MariaDB/mariadb_repo_setup\necho \"935944a2ab2b2a48a47f68711b43ad2d698c97f1c3a7d074b34058060c2ad21b mariadb_repo_setup\" \\\n    | sha256sum -c -\nchmod +x mariadb_repo_setup\nsudo ./mariadb_repo_setup --mariadb-server-version=\"mariadb-10.6\"\n</code></pre> </li> <li> <p>Install MariaDB Dump and package dependencies:</p> <pre><code>sudo yum install MariaDB-client\n</code></pre> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/Install%20Mariadb-dump/#debian-ubuntu","title":"Debian / Ubuntu","text":"<ol> <li> <p>Configure APT package repositories:</p> <pre><code>sudo apt install wget\nwget https://downloads.mariadb.com/MariaDB/mariadb_repo_setup\n$ echo \"935944a2ab2b2a48a47f68711b43ad2d698c97f1c3a7d074b34058060c2ad21b mariadb_repo_setup\" \n    | sha256sum -c -\nchmod +x mariadb_repo_setup\nsudo ./mariadb_repo_setup --mariadb-server-version=\"mariadb-10.6\"$ sudo apt update\n</code></pre> </li> <li> <p>Install MariaDB Dump and package dependencies:</p> <pre><code>sudo apt install mariadb-client\n</code></pre> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/Install%20Mariadb-dump/#sles","title":"SLES","text":"<ol> <li> <p>Configure ZYpp package repositories:</p> <pre><code>sudo zypper install wget\nwget https://downloads.mariadb.com/MariaDB/mariadb_repo_setup\necho \"935944a2ab2b2a48a47f68711b43ad2d698c97f1c3a7d074b34058060c2ad21b mariadb_repo_setup\" \\\n    | sha256sum -c -\nchmod +x mariadb_repo_setup\nsudo ./mariadb_repo_setup --mariadb-server-version=\"mariadb-10.6\"\n</code></pre> </li> <li> <p>Install MariaDB Dump and package dependencies:</p> <pre><code>sudo zypper install MariaDB-client\n</code></pre> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/Install%20Mariadb-dump/#windows","title":"Windows","text":"<ol> <li>Access\u00a0MariaDB Downloads\u00a0for MariaDB Community Server.</li> <li>In the \"Version\" dropdown, select the version you want to download.</li> <li>In the \"OS\" dropdown, select \"MS Windows (64-bit)\".</li> <li>Click the \"Download\" button to download the MSI package.</li> <li>When the MSI package finishes downloading, run it.</li> <li>On the first screen, click \"Next\" to start the Setup Wizard.</li> <li>On the second screen, click the license agreement checkbox, and then click \"Next\".</li> <li>On the third screen, select the components you want to install. If you only want the standard MariaDB Client tools:<ul> <li>Deselect \"Database instance\".</li> <li>Deselect \"Backup utilities\".</li> <li>Deselect \"Development Components\".</li> <li>Deselect \"Third party tools\".</li> <li>When only \"Client programs\" is selected, click \"Next\".</li> </ul> </li> <li>On the next screen, click \"Install\".</li> <li>When the installation process completes, click \"Finish\".</li> </ol>"},{"location":"Data%20loading%2C%20Migration/Install%20Mariadb-dump/#create-a-logical-dump-sql-file","title":"Create a logical \u201cDump\u201d SQL file","text":"<p>The procedure to create a backup depends on the operating system.</p> <p>If you plan to restore the backup to a SkySQL service, the\u00a0<code>mysql</code>\u00a0database should be excluded from the backup by specifying\u00a0<code>--ignore-database=mysql</code>, because SkySQL user accounts do not have sufficient privileges to restore that database.</p>"},{"location":"Data%20loading%2C%20Migration/Install%20Mariadb-dump/#linux","title":"Linux","text":"<ol> <li>Determine the\u00a0connection parameters\u00a0for your SkySQL service.</li> <li>Use your connection parameters in the following command line:</li> </ol> <pre><code>mariadb-dump --host FULLY_QUALIFIED_DOMAIN_NAME --port TCP_PORT \\\n      --user DATABASE_USER --password \\\n      --ssl-verify-server-cert \\\n      --all-databases \\\n      --ignore-database=mysql \\\n      --single-transaction \\\n      --events \\\n      --routines \\\n      --default-character-set=utf8mb4 \\\n      &gt; skysql_dump.sql\n</code></pre> <ul> <li>Replace\u00a0<code>FULLY_QUALIFIED_DOMAIN_NAME</code>\u00a0with the Fully Qualified Domain Name of your service.</li> <li>Replace\u00a0<code>TCP_PORT</code>\u00a0with the read-write or read-only port of your service.</li> <li>Replace\u00a0<code>DATABASE_USER</code>\u00a0with the default username for your service, or the username you created.</li> </ul> <p>After the command is executed, you will be prompted for a password. Enter the default password for your default user, the password you set for the default user, or the password for the database user you created.</p>"},{"location":"Data%20loading%2C%20Migration/Install%20Mariadb-dump/#windows_1","title":"Windows","text":"<ol> <li> <p>Fix your executable search path.</p> <p>On Windows, MariaDB Dump is not typically found in the executable search path by default. You must find its installation path, and add that path to the executable search path:</p> <pre><code>SET \"PATH=C:\\Program Files\\MariaDB 10.6\\bin;%PATH%\"\n</code></pre> </li> <li> <p>Determine the\u00a0connection parameters\u00a0for your SkySQL service.</p> </li> <li>Use your connection parameters in the following command line:</li> </ol> <pre><code>mariadb-dump --host FULLY_QUALIFIED_DOMAIN_NAME --port TCP_PORT \\\n      --user DATABASE_USER --password \\\n      --ssl-verify-server-cert \\\n      --all-databases \\\n      --ignore-database=mysql \\\n      --single-transaction \\\n      --events \\\n      --routines \\\n      --default-character-set=utf8mb4 \\\n      &gt; skysql_dump.sql\n</code></pre> <ul> <li>Replace\u00a0<code>FULLY_QUALIFIED_DOMAIN_NAME</code>\u00a0with the Fully Qualified Domain Name of your service.</li> <li>Replace\u00a0<code>TCP_PORT</code>\u00a0with the read-write or read-only port of your service.</li> <li>Replace\u00a0<code>DATABASE_USER</code>\u00a0with the default username for your service, or the username you created.</li> </ul> <p>After the command is executed, you will be prompted for a password. Enter the default password for your default user, the password you set for the default user, or the password for the database user you created.</p>"},{"location":"Data%20loading%2C%20Migration/Install%20Mariadb-dump/#mariadb-dump-103-and-older","title":"MariaDB Dump 10.3 and Older","text":"<p>The instructions provided above are written for MariaDB Dump 10.4 and later, which uses the binary filename of\u00a0<code>mariadb-dump</code>.</p> <p>For MariaDB Dump 10.3 and older, the binary filename was\u00a0<code>mysqldump</code>. The instructions can be adapted for MariaDB Dump 10.3 and older by executing\u00a0<code>mysqldump</code>\u00a0rather than\u00a0<code>mariadb-dump</code>.</p>"},{"location":"Data%20loading%2C%20Migration/Install%20Mariadb-dump/#temporal-tables","title":"Temporal Tables","text":"<p>For system-versioned tables and transaction-precise tables, MariaDB Dump only backs up current row versions. It does not back up historical row versions.</p>"},{"location":"Data%20loading%2C%20Migration/Install-mariadb-import/","title":"Install mariadb-import","text":"<p>SkySQL customers can import data into a SkySQL service using the\u00a0<code>mariadb-import</code>\u00a0utility:</p> <ul> <li>The\u00a0<code>mariadb-import</code>\u00a0utility provides a command-line interface (CLI)</li> <li>The\u00a0<code>mariadb-import</code>\u00a0utility can import data from TSV and CSV files</li> <li>The\u00a0<code>mariadb-import</code>\u00a0utility is available for Linux and Windows</li> <li>The\u00a0<code>mariadb-import</code>\u00a0utility supports\u00a0many command-line options</li> </ul>"},{"location":"Data%20loading%2C%20Migration/Install-mariadb-import/#installation","title":"Installation","text":"<p>Installation of MariaDB Import varies by operating system.</p>"},{"location":"Data%20loading%2C%20Migration/Install-mariadb-import/#centos-rhel","title":"CentOS / RHEL","text":"<ol> <li> <p>Configure YUM package repositories:</p> <pre><code>sudo yum install wget  \nwget https://downloads.mariadb.com/MariaDB/mariadb_repo_setup\necho \"935944a2ab2b2a48a47f68711b43ad2d698c97f1c3a7d074b34058060c2ad21b mariadb_repo_setup\" \\\n    | sha256sum -c -\nchmod +x mariadb_repo_setup   \nsudo ./mariadb_repo_setup --mariadb-server-version=\"mariadb-10.6\"\n</code></pre> </li> <li> <p>Install MariaDB Import and package dependencies:</p> <pre><code>sudo yum install MariaDB-client\n</code></pre> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/Install-mariadb-import/#debian-ubuntu","title":"Debian / Ubuntu","text":"<ol> <li> <p>Configure APT package repositories:</p> <pre><code>sudo apt install wget\nwget https://downloads.mariadb.com/MariaDB/mariadb_repo_setup\necho \"935944a2ab2b2a48a47f68711b43ad2d698c97f1c3a7d074b34058060c2ad21b mariadb_repo_setup\" \\\n    | sha256sum -c -\nchmod +x mariadb_repo_setup\nsudo ./mariadb_repo_setup --mariadb-server-version=\"mariadb-10.6\"\nsudo apt update\n</code></pre> </li> <li> <p>Install MariaDB Import and package dependencies:</p> <pre><code>sudo apt install mariadb-client\n</code></pre> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/Install-mariadb-import/#sles","title":"SLES","text":"<ol> <li> <p>Configure ZYpp package repositories:</p> <pre><code>sudo zypper install wget\nwget https://downloads.mariadb.com/MariaDB/mariadb_repo_setup\n$ echo \"935944a2ab2b2a48a47f68711b43ad2d698c97f1c3a7d074b34058060c2ad21b mariadb_repo_setup\" \\\n    | sha256sum -c -\nchmod +x mariadb_repo_setup\nsudo ./mariadb_repo_setup --mariadb-server-version=\"mariadb-10.6\"\n</code></pre> </li> <li> <p>Install MariaDB Import and package dependencies:</p> <pre><code>sudo zypper install MariaDB-client\n</code></pre> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/Install-mariadb-import/#windows","title":"Windows","text":"<ol> <li>Access\u00a0MariaDB Downloads\u00a0for MariaDB Community Server.</li> <li>In the \"Version\" dropdown, select the version you want to download.</li> <li>In the \"OS\" dropdown, select \"MS Windows (64-bit)\".</li> <li>Click the \"Download\" button to download the MSI package.</li> <li>When the MSI package finishes downloading, run it.</li> <li>On the first screen, click \"Next\" to start the Setup Wizard.</li> <li>On the second screen, click the license agreement checkbox, and then click \"Next\".</li> <li>On the third screen, select the components you want to install. If you only want the standard MariaDB Client tools:<ul> <li>Deselect \"Database instance\".</li> <li>Deselect \"Backup utilities\".</li> <li>Deselect \"Development Components\".</li> <li>Deselect \"Third party tools\".</li> <li>When only \"Client programs\" is selected, click \"Next\".</li> </ul> </li> <li>On the next screen, click \"Install\".</li> <li>When the installation process completes, click \"Finish\".</li> </ol>"},{"location":"Data%20loading%2C%20Migration/Install-mariadb-import/#import-data","title":"Import Data","text":"<p>The procedure to import data depends on the operating system.</p>"},{"location":"Data%20loading%2C%20Migration/Install-mariadb-import/#linux","title":"Linux","text":"<ol> <li>Determine the\u00a0connection parameters\u00a0for your SkySQL service.</li> <li> <p>Use MariaDB Import with the connection information to import the data from the TSV or CSV file into your SkySQL database service:</p> <pre><code>mariadb-import --host FULLY_QUALIFIED_DOMAIN_NAME --port TCP_PORT \\\n      --user DATABASE_USER --password \\\n      --ssl-verify-server-cert \\\n      --ssl-ca ~/PATH_TO_PEM_FILE \\\n      --local \\\n      --ignore-lines=1 \\\n      accounts contacts.tsv\n</code></pre> <ul> <li>Replace\u00a0<code>FULLY_QUALIFIED_DOMAIN_NAME</code>\u00a0with the Fully Qualified Domain Name of your service</li> <li>Replace\u00a0<code>TCP_PORT</code>\u00a0with the read-write or read-only port of your service</li> <li>Replace\u00a0<code>DATABASE_USER</code>\u00a0with the default username for your service, or the username you created</li> <li>Replace\u00a0<code>~/PATH_TO_PEM_FILE</code>\u00a0with the path to the certificate authority chain (.pem) file</li> <li>If your file is a CSV file, rather than a TSV file, specify\u00a0<code>-fields-terminated-by=,</code></li> <li>Specify the database name as the first argument (from above,\u00a0<code>accounts</code>)</li> <li>The table name is extracted from the TSV or CSV file's basename (from above,\u00a0<code>contacts</code>)</li> <li>After the command is executed, you will be prompted for a password. Enter the default password for your default user, the password you set for the default user, or the password for the database user you created.</li> </ul> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/Install-mariadb-import/#windows_1","title":"Windows","text":"<ol> <li> <p>Fix your executable search path.</p> <p>On Windows, MariaDB Import is not typically found in the executable search path by default. You must find its installation path, and add that path to the executable search path:</p> <pre><code>SET \"PATH=C:\\Program Files\\MariaDB 10.6\\bin;%PATH%\"\n</code></pre> </li> <li> <p>Determine the\u00a0connection parameters\u00a0for your SkySQL service.</p> </li> <li> <p>Use MariaDB Import with the connection information to import the data from the TSV or CSV file into your SkySQL database service:</p> <pre><code>mariadb-import --host FULLY_QUALIFIED_DOMAIN_NAME --port TCP_PORT \\\n      --user DATABASE_USER --password \\\n      --ssl-verify-server-cert \\\n      --ssl-ca ~/PATH_TO_PEM_FILE \\\n      --local \\\n      --ignore-lines=1 \\\n      accounts contacts.tsv\n</code></pre> <ul> <li>Replace\u00a0<code>FULLY_QUALIFIED_DOMAIN_NAME</code>\u00a0with the Fully Qualified Domain Name of your service</li> <li>Replace\u00a0<code>TCP_PORT</code>\u00a0with the read-write or read-only port of your service</li> <li>Replace\u00a0<code>DATABASE_USER</code>\u00a0with the default username for your service, or the username you created</li> <li>Replace\u00a0<code>~/PATH_TO_PEM_FILE</code>\u00a0with the path to the certificate authority chain (.pem) file</li> <li>If your file is a CSV file, rather than a TSV file, specify\u00a0<code>-fields-terminated-by=,</code></li> <li>Specify the database name as the first argument (from above,\u00a0<code>accounts</code>)</li> <li>The table name is extracted from the TSV or CSV file's basename (from above,\u00a0<code>contacts</code>)</li> <li>After the command is executed, you will be prompted for a password. Enter the default password for your default user, the password you set for the default user, or the password for the database user you created.</li> </ul> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/Install-mariadb-import/#mariadb-import-103-and-older","title":"MariaDB Import 10.3 and Older","text":"<p>The instructions provided above are written for MariaDB Import 10.4 and later, which uses the binary filename of\u00a0<code>mariadb-import</code>.</p> <p>For MariaDB Import 10.3 and older, the binary filename was\u00a0<code>mysqlimport</code>. The instructions can be adapted for MariaDB Import 10.3 and older by executing\u00a0<code>mysqlimport</code>\u00a0rather than\u00a0<code>mariadb-import</code>.</p>"},{"location":"Data%20loading%2C%20Migration/Migrate-your-database-to-SkySQL/","title":"Migrate your database to SkySQL","text":"<p>SkySQL provides a range of options to suit different migration scenarios.</p> <ul> <li> Databases can be migrated to SkySQL from many different database platforms, including Oracle, MySQL, PostgreSQL, Microsoft SQL Server, IBM DB2, and more. </li> <li> SkySQL supports migration from both on-premise and cloud-based infrastructure and provides a range of options to suit different migration scenarios. </li> </ul> <p>Below are the most common scenarios for database migration to SkySQL.</p>"},{"location":"Data%20loading%2C%20Migration/Migrate-your-database-to-SkySQL/#prerequisites","title":"Prerequisites","text":"<ol> <li>An active SkySQL account. </li> <li>An existing source database with the IP added to your SkySQL allowlist.</li> </ol> Considerations   Ensure that your SkySQL servce deploymned configuration is compatible with your existing source database one, including: <ul> <li>Deployment region - Ensure that the SkySQL deployment region is the same as the source database region.</li> <li>Topology - Mariadb Server Single node or with Replica(s)</li> <li> Server version - Ensure that the SkySQL server version is compatible with the source database version. </li> <li>Instance size - Ensure that the SkySQL instance is compatible with the source database instance type and size</li> <li>Storage - Ensure that the SkySQL storage type and size is compatible with the source database</li>"},{"location":"Data%20loading%2C%20Migration/Migrate-your-database-to-SkySQL/#skydba-assisted-migration","title":"SkyDBA Assisted Migration","text":"<ul> <li>Existing customers can submit a\u00a0support case\u00a0to request assistance with a migration.</li> <li>New customers can\u00a0contact us\u00a0to begin the migration planning process.</li> </ul> <p>Our SkyDBA team can help design a migration plan to suit your needs.</p> SkyDBA Assisted Migration Approach   We use a multi-step process to assist customers with migrations: <ul> <li>Assessment of application requirements, inventory, and identified challenges</li> <li>Schema Migration including tables, constraints, indexes, and views</li> <li>Application Code Migration by porting and testing SQL and application code</li> <li>Data Migration and Replication with import of data, with conversion to the new schema, and ongoing inbound replication of new data</li> <li>Quality Assurance to assess data validity, data integrity, performance, accuracy of query results, stored code, and running code such as client applications, APIs, and batch jobs</li> <li>Cutover including final database preparation, fallback planning, switchover, and decommissioning of old databases</li>"},{"location":"Data%20loading%2C%20Migration/Migrate-your-database-to-SkySQL/#self-service-migration-to-skysql","title":"Self-Service Migration to SkySQL","text":"<p>SkySQL provides two different options for self-service migration </p>"},{"location":"Data%20loading%2C%20Migration/Migrate-your-database-to-SkySQL/#option-1-migrate-using-the-skysql-rest-api","title":"Option 1: Migrate using the SkySQL REST API","text":"<p>SkySQL Managed Migration is a REST-based service that handles the migration process, including data migration, schema migration, and user migration. It provides a follow us steps to set up a live replication of your database to SkySQL and various insights to monitor the migration process.</p> <ul> <li>Sky SQL Managed Migration Tutorial</li> </ul>"},{"location":"Data%20loading%2C%20Migration/Migrate-your-database-to-SkySQL/#option-2-custom-migration","title":"Option 2: Custom Migration","text":"<p>For most small, mid-size and large migrations SkySQL Managed Migration is the quickest and safest option. However, for large migrations or migrations with specific requirements, you and your team may require more flexibility and control over the migration process. In these cases, you and your team can design a custom migration plan considering the options suggested below.</p> <ul> <li>Migrating Using a Logical Dump and Replication</li> <li>Importing data using Mariadb Import</li> <li>Importing using CSV Data</li> <li>Replicating Data from an External DB</li> </ul>"},{"location":"Data%20loading%2C%20Migration/Migrating%20Using%20a%20Logical%20Dump%20and%20Replication/","title":"Migrating Using a Logical Dump and Replication","text":"<p>To minimize downtime during migration, you can set up live replication from your source database to the SkySQL database.</p>"},{"location":"Data%20loading%2C%20Migration/Migrating%20Using%20a%20Logical%20Dump%20and%20Replication/#prerequisites","title":"Prerequisites","text":"<ol> <li>An active SkySQL account. Identify requirements for your SkySQL implementation prior to deployment, including:</li> <li>Topology - Mariadb Server Single node or with Replica(s)</li> <li>Instance size</li> <li>Storage requirements</li> <li>Desired server version</li> <li>An existing source database with the IP added to your SkySQL allowlist.</li> </ol>"},{"location":"Data%20loading%2C%20Migration/Migrating%20Using%20a%20Logical%20Dump%20and%20Replication/#steps","title":"Steps","text":"<ol> <li> <p>Dump the Source Database: Take a dump of your source database using <code>mysqldump</code> or <code>mariadb-dump</code>. Include triggers, procedures, views, and schedules in the dump, and ignore the system databases to avoid conflicts with the existing SkySQL schemas.</p> <pre><code>mysqldump -u [username] -p -h [hostname] --single-transaction --master-data=2 --routines --triggers --all-databases --ignore-database=mysql --ignore-database=information_schema --ignore-database=performance_schema --ignore-database=sys &gt; dump.sql\n</code></pre> </li> <li> <p>Create the Users and Grants Separately: To avoid conflicts with the existing SkySQL users, use <code>SELECT CONCAT</code> on your source database to create users and grants in separate files. Note that you may need to create the schema and table grants separately as well.</p> <pre><code>mysql -u [username] -p -h [hostname] --silent --skip-column-names -e \"SELECT CONCAT('CREATE USER \\'', user, '\\'@\\'', host, '\\' IDENTIFIED BY PASSWORD \\'', authentication_string, '\\';') FROM mysql.user;\" &gt; users.sql\n\nmysql -h [hostname] -u [username] -p --silent --skip-column-names -e \"SELECT CONCAT('GRANT ', privilege_type, ' ON ', table_schema, '.* TO \\'', grantee, '\\';') FROM information_schema.schema_privileges;\" &gt; grants.sql\n\nmysql -h [hostname] -u [username] -p --silent --skip-column-names -e \"SELECT CONCAT('GRANT ', privilege_type, ' ON ', table_schema, '.', table_name, ' TO \\'', grantee, '\\';') FROM information_schema.table_privileges;\" &gt;&gt; grants.sql\n</code></pre> </li> <li> <p>Import the Dumps into SkySQL: Import the logical dumps (SQL files) into your SkySQL database, ensuring to load the user and grant dumps after the main dump.</p> <pre><code>mariadb -u [SkySQL username] -p -h [SkySQL hostname] --port 3306 --ssl-verify-server-cert &lt; dump.sql\nmariadb -u [SkySQL username] -p -h [SkySQL hostname] --port 3306 --ssl-verify-server-cert &lt; users.sql\nmariadb -u [SkySQL username] -p -h [SkySQL hostname] --port 3306 --ssl-verify-server-cert &lt; grants.sql\n</code></pre> </li> </ol> <p>If you encounter an error while importing your users, you may need to uninstall the <code>simple_password_check</code> plugin on your SkySQL instance.</p> <pre><code>```sql\nUNINSTALL PLUGIN simple_password_check;\n```\n</code></pre> <ol> <li> <p>Start Replication: Turn on replication using SkySQL stored procedures. There are procedures allowing you to set and start replication. See our documentation for details. The <code>dump.sql</code> file you created in step 1 will contain the GTID and binary log information needed for the <code>change_external_primary</code> procedure.</p> <p>```sql CALL sky.change_external_primary(    host VARCHAR(255),    port INT,    logfile TEXT,    logpos LONG ,    use_ssl_encryption BOOLEAN );</p> <p>CALL sky.replication_grants(); CALL sky.start_replication(); ```</p> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/Migrating%20Using%20a%20Logical%20Dump%20and%20Replication/#performance-optimization-during-migration","title":"Performance Optimization During Migration","text":"<ul> <li> <p>Disable Foreign Key Checks: Temporarily disable foreign key checks during import to speed up the process.</p> <pre><code>SET foreign_key_checks = 0;\n</code></pre> </li> <li> <p>Disable Binary Logging: If binary logging is not required during the import process, and you are using a standalone instance, it can potentially be disabled to improve performance. SkyDBA Services can assist with this as part of a detailed migration plan.</p> </li> </ul>"},{"location":"Data%20loading%2C%20Migration/Migrating%20Using%20a%20Logical%20Dump%20and%20Replication/#data-integrity-and-validation","title":"Data Integrity and Validation","text":"<ul> <li> <p>Consistency Checks: Perform consistency checks on the source database before migration. Use a supported SQL client to connect to your SkySQL instance and run the following.</p> <pre><code>CHECK TABLE [table_name] FOR UPGRADE;\n</code></pre> </li> <li> <p>Post-Import Validation: Validate the data integrity and consistency after the import.</p> <pre><code>CHECKSUM TABLE [table_name];\n</code></pre> </li> </ul>"},{"location":"Data%20loading%2C%20Migration/Migrating%20Using%20a%20Logical%20Dump%20and%20Replication/#advanced-migration-techniques","title":"Advanced Migration Techniques","text":"<ul> <li> <p>Adjust Buffer Sizes: Temporarily increase buffer sizes to optimize the import performance. This can be done via the Configuration Manager in the portal.</p> <pre><code>innodb_buffer_pool_size = 2G\ninnodb_log_file_size = 512M\n</code></pre> </li> <li> <p>Parallel Dump and Import: Use tools that support parallel processing for dumping and importing data.</p> <pre><code>mysqldump -u [username] -p --default-parallelism=4 --add-drop-database \\\n    --databases [database_name] &gt; dump.sql\n</code></pre> </li> <li> <p>Incremental Backups: For large datasets, incremental backups can be used to minimize the amount of data to be transferred. SkyDBA Services can assist you with setting these up as part of a custom migration plan.</p> </li> </ul>"},{"location":"Data%20loading%2C%20Migration/Migrating%20Using%20a%20Logical%20Dump%20and%20Replication/#monitoring-and-logging","title":"Monitoring and Logging","text":"<ul> <li> <p>Enable Detailed Logging: Enable detailed logging while testing the migration process to monitor and troubleshoot effectively. The slow_log can be enabled in the SkySQL configuration manager.</p> </li> <li> <p>Resource Monitoring: Use monitoring tools to track resource usage (CPU, memory, I/O) during the migration to ensure system stability. See our monitoring documentation for details.</p> </li> </ul>"},{"location":"Data%20loading%2C%20Migration/Migrating%20Using%20a%20Logical%20Dump%20and%20Replication/#additional-resources","title":"Additional Resources","text":"<ul> <li>Backup with mariadb-dump</li> <li>MariaDB Backup Documentation</li> <li>Advanced Backup Techniques</li> <li>Migrate RDS MySQL to SkySQL using the AWS Data Migration Service (DMS)</li> </ul>"},{"location":"Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/","title":"Replicating Data from an External Database to SkySQL","text":"<p>MariaDB SkySQL customers can configure inbound replication from both MySQL and MariaDB to a compatible MariaDB running in SkySQL. This guide will walk you through setting up replication for both MySQL and MariaDB as the source databases.</p> <p>For additional information about the stored procedures used to configure replication with Replicated Transactions services, see SkySQL Replication Helper Procedures for Replicated Transactions.</p>"},{"location":"Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/#requirements","title":"Requirements","text":"<ol> <li>For MySQL :</li> <li> <p>Replication must be configured using the binary log file and position (GTID is not supported).</p> </li> <li> <p>For MariaDB:</p> </li> <li>GTID-based replication can be used instead of binary log for complex replication setups.</li> </ol> <p>Ensure that the external primary server is compatible with the version of MariaDB used in SkySQL.</p>"},{"location":"Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/#step-1-obtain-the-log-file-and-position","title":"Step 1: Obtain the Log File and Position","text":""},{"location":"Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/#mysql","title":"MySQL:","text":"<p>If using MySQL, obtain the binary log file and position from which to start replication. This can be retrieved from a logical dump or <code>xtrabackup_binlog_info</code> file. If the source database is idle, use the <code>SHOW MASTER STATUS</code> statement to get the current binary log file and position:</p> <pre><code>SHOW MASTER STATUS;\n</code></pre>"},{"location":"Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/#mariadb","title":"MariaDB:","text":"<p>For MariaDB, replication can be done using GTID. Obtain the GTID position using the <code>@@current_gtid_pos</code> variable:</p> <pre><code>SELECT @@current_gtid_pos;\n</code></pre>"},{"location":"Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/#step-2-configure-the-log-file-and-position","title":"Step 2: Configure the Log File and Position","text":""},{"location":"Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/#for-mysql-binary-log-position-based","title":"For MySQL (Binary Log Position Based)","text":"<p>Configure the binary log file and position on the SkySQL service using the following stored procedure:</p> <pre><code>CALL sky.change_external_primary('mysql1.example.com', 3306, 'mysql-bin.000001', 154, false);\n</code></pre> <p>This procedure can be referenced in the official documentation: sky.change_external_primary()</p> <p>This will return a <code>GRANT</code> statement that needs to be executed on the external MySQL server:</p> <pre><code>GRANT REPLICATION SLAVE ON *.* TO 'skysql_replication'@'%' IDENTIFIED BY '&lt;password_hash&gt;';\n</code></pre> <p>For MariaDB (GTID Based) if preferred refer to sky.change_external_primary_gtid()</p>"},{"location":"Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/#step-3-start-replication","title":"Step 3: Start Replication","text":"<p>Once the configuration is complete, start replication on the SkySQL service using the following command:</p> <pre><code>CALL sky.start_replication();\n</code></pre> <p>This will return a confirmation message such as:</p> <pre><code>+----------------------------------------+\n| Message                                |\n+----------------------------------------+\n| External replication running normally. |\n+----------------------------------------+\n</code></pre> <p>You can find the documentation for this procedure here: sky.start_replication()</p>"},{"location":"Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/#step-4-check-replication-status","title":"Step 4: Check Replication Status","text":"<p>To verify the status of replication, you can run the following stored procedure on SkySQL:</p> <pre><code>CALL sky.replication_status()\\G;\n</code></pre> <p>The output will provide detailed information about the replication process, including the position of the replication logs and the state of the slave threads. An example output is shown below:</p> <pre><code>*************************** 1. row ***************************\n                Slave_IO_State: Waiting for master to send event\n                   Master_Host: mariadb1.example.com\n                   Master_User: skysql_replication\n                   Master_Port: 3306\n                 Connect_Retry: 60\n               Master_Log_File: mysql-bin.000001\n           Read_Master_Log_Pos: 462\n                Relay_Log_File: mariadb-relay-bin.000002\n                 Relay_Log_Pos: 665\n         Relay_Master_Log_File: mysql-bin.000001\n              Slave_IO_Running: Yes\n             Slave_SQL_Running: Yes\n               Replicate_Do_DB:\n           Replicate_Ignore_DB:\n            Replicate_Do_Table:\n        Replicate_Ignore_Table:\n       Replicate_Wild_Do_Table:\n   Replicate_Wild_Ignore_Table:\n                    Last_Errno: 0\n                    Last_Error:\n                  Skip_Counter: 0\n           Exec_Master_Log_Pos: 462\n               Relay_Log_Space: 985\n               Until_Condition: None\n                Until_Log_File:\n                 Until_Log_Pos: 0\n            Master_SSL_Allowed: No\n            Master_SSL_CA_File:\n            Master_SSL_CA_Path:\n               Master_SSL_Cert:\n             Master_SSL_Cipher:\n                Master_SSL_Key:\n         Seconds_Behind_Master: 0\n Master_SSL_Verify_Server_Cert: No\n                 Last_IO_Errno: 0\n                 Last_IO_Error:\n                Last_SQL_Errno: 0\n                Last_SQL_Error:\n   Replicate_Ignore_Server_Ids:\n              Master_Server_Id: 200\n                Master_SSL_Crl:\n            Master_SSL_Crlpath:\n                    Using_Gtid: No\n                   Gtid_IO_Pos:\n       Replicate_Do_Domain_Ids:\n   Replicate_Ignore_Domain_Ids:\n                 Parallel_Mode: conservative\n                     SQL_Delay: 0\n           SQL_Remaining_Delay: NULL\n       Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates\n              Slave_DDL_Groups: 0\nSlave_Non_Transactional_Groups: 0\n    Slave_Transactional_Groups: 0\n</code></pre> <p>You can reference the replication status procedure here: sky.replication_status()</p>"},{"location":"Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/#compatibility-notes","title":"Compatibility Notes","text":"<ul> <li> <p>For MySQL: Only binary log-based replication is supported; GTID is not available.</p> </li> <li> <p>For MariaDB: GTID-based replication can be used.</p> </li> </ul>"},{"location":"Data%20loading%2C%20Migration/Replicating%20data%20from%20external%20DB/#supported-mariadb-versions-for-replication","title":"Supported MariaDB Versions for Replication","text":"<p>Ensure that the external primary server uses a supported version of MariaDB, which must be the same or older than the SkySQL service version.</p> <ul> <li>For SkySQL using ES 10.6:<ul> <li>MariaDB Server 10.2, 10.3, 10.4, 10.5, 10.6</li> </ul> </li> <li>For SkySQL using ES 10.5:<ul> <li>MariaDB Server 10.2, 10.3, 10.4, 10.5</li> </ul> </li> <li>For SkySQL using ES 10.4:<ul> <li>MariaDB Server 10.2, 10.3, 10.4</li> </ul> </li> </ul>"},{"location":"Data%20loading%2C%20Migration/SkySQL-custom-migration/","title":"SkySQL custom migration","text":"<p>//TODO Add a  section on physical backup and restore </p>"},{"location":"Data%20loading%2C%20Migration/SkySQL-custom-migration/#live-replication-for-minimal-downtime","title":"Live Replication for Minimal Downtime","text":"<p>To minimize downtime during migration, set up live binary-loggd based replication from your source database to the SkySQL database.  Click here for a detailed walk through of the steps involved. </p> <p>Follow these steps:</p>"},{"location":"Data%20loading%2C%20Migration/SkySQL-custom-migration/#replicating-data-from-an-external-db","title":"Replicating data from an External DB","text":"<ol> <li> <p>Create the Users and Grants Separately: To avoid conflicts with the existing SkySQL users, use <code>SELECT CONCAT</code> on your source database to create users and grants in separate files. Note that you may need to create the schema and table grants separately as well.</p> <pre><code>mysql -u [username] -p -h [hostname] --silent --skip-column-names -e \"SELECT CONCAT('CREATE USER \\'', user, '\\'@\\'', host, '\\' IDENTIFIED BY PASSWORD \\'', authentication_string, '\\';') FROM mysql.user;\" &gt; users.sql\n\nmysql -h [hostname] -u [username] -p --silent --skip-column-names -e \"SELECT CONCAT('GRANT ', privilege_type, ' ON ', table_schema, '.* TO \\'', grantee, '\\';') FROM information_schema.schema_privileges;\" &gt; grants.sql\n\nmysql -h [hostname] -u [username] -p --silent --skip-column-names -e \"SELECT CONCAT('GRANT ', privilege_type, ' ON ', table_schema, '.', table_name, ' TO \\'', grantee, '\\';') FROM information_schema.table_privileges;\" &gt;&gt; grants.sql\n</code></pre> </li> <li> <p>Import the Dumps into SkySQL: Import the logical dumps (SQL files) into your SkySQL database, ensuring to load the user and grant dumps after the main dump.</p> <pre><code>mariadb -u [SkySQL username] -p -h [SkySQL hostname] --port 3306 --ssl-verify-server-cert &lt; dump.sql\nmariadb -u [SkySQL username] -p -h [SkySQL hostname] --port 3306 --ssl-verify-server-cert &lt; users.sql\nmariadb -u [SkySQL username] -p -h [SkySQL hostname] --port 3306 --ssl-verify-server-cert &lt; grants.sql\n</code></pre> </li> </ol> <p>If you encounter an error while importing your users, you may need to uninstall the <code>simple_password_check</code> plugin on your SkySQL instance.</p> <pre><code>```sql\nUNINSTALL PLUGIN simple_password_check;\n```\n</code></pre> <ol> <li> <p>Start Replication: Turn on replication using SkySQL stored procedures. There are procedures allowing you to set and start replication. See our documentation for details. The <code>dump.sql</code> file you created in step 1 will contain the GTID and binary log information needed for the <code>change_external_primary</code> procedure.</p> <p>```sql CALL sky.change_external_primary(    host VARCHAR(255),    port INT,    logfile TEXT,    logpos LONG ,    use_ssl_encryption BOOLEAN );</p> <p>CALL sky.replication_grants(); CALL sky.start_replication(); ```</p> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/SkySQL-custom-migration/#performance-optimization-during-migration","title":"Performance Optimization During Migration","text":"<ul> <li> <p>Disable Foreign Key Checks: Temporarily disable foreign key checks during import to speed up the process.</p> <pre><code>SET foreign_key_checks = 0;\n</code></pre> </li> <li> <p>Disable Binary Logging: If binary logging is not required during the import process, and you are using a standalone instance, it can potentially be disabled to improve performance. SkyDBA Services can assist with this as part of a detailed migration plan.</p> </li> </ul>"},{"location":"Data%20loading%2C%20Migration/SkySQL-custom-migration/#data-integrity-and-validation","title":"Data Integrity and Validation","text":"<ul> <li> <p>Consistency Checks: Perform consistency checks on the source database before migration. Use a supported SQL client to connect to your SkySQL instance and run the following.</p> <pre><code>CHECK TABLE [table_name] FOR UPGRADE;\n</code></pre> </li> <li> <p>Post-Import Validation: Validate the data integrity and consistency after the import.</p> <pre><code>CHECKSUM TABLE [table_name];\n</code></pre> </li> </ul>"},{"location":"Data%20loading%2C%20Migration/SkySQL-custom-migration/#advanced-migration-techniques","title":"Advanced Migration Techniques","text":"<ul> <li> <p>Adjust Buffer Sizes: Temporarily increase buffer sizes to optimize the import performance. This can be done via the Configuration Manager in the portal.</p> <pre><code>innodb_buffer_pool_size = 2G\ninnodb_log_file_size = 512M\n</code></pre> </li> <li> <p>Parallel Dump and Import: Use tools that support parallel processing for dumping and importing data.</p> <pre><code>mysqlpump -u [username] -p --default-parallelism=4 --add-drop-database \\\n    --databases [database_name] &gt; dump.sql\n</code></pre> </li> <li> <p>Incremental Backups: For large datasets, incremental backups can be used to minimize the amount of data to be transferred. SkyDBA Services can assist you with setting these up as part of a custom migration plan.</p> </li> </ul>"},{"location":"Data%20loading%2C%20Migration/SkySQL-custom-migration/#monitoring-and-logging","title":"Monitoring and Logging","text":"<ul> <li> <p>Enable Detailed Logging: Enable detailed logging while testing the migration process to monitor and troubleshoot effectively. The slow_log can be enabled in the SkySQL configuration manager.</p> </li> <li> <p>Resource Monitoring: Use monitoring tools to track resource usage (CPU, memory, I/O) during the migration to ensure system stability. See our monitoring documentation for details.</p> </li> </ul>"},{"location":"Data%20loading%2C%20Migration/SkySQL-custom-migration/#additional-resources","title":"Additional Resources","text":"<ul> <li>Backup with mariadb-dump</li> <li>MariaDB Backup Documentation</li> <li>Advanced Backup Techniques</li> <li>Migrate RDS MySQL to SkySQL using the AWS Data Migration Service (DMS)</li> </ul>"},{"location":"Data%20loading%2C%20Migration/SkySQL-managed-migration/","title":"SkySQL Managed Migration","text":""},{"location":"Data%20loading%2C%20Migration/SkySQL-managed-migration/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>An active SkySQL account. Identify requirements for your SkySQL implementation prior to deployment, including:</p> <ul> <li>Topology: Mariadb Server Single node or with Replica(s)</li> <li>Instance size</li> <li>Storage requirements</li> <li>Desired server version</li> </ul> </li> <li> <p>An existing source database with the IP added to your SkySQL allowlist.</p> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/SkySQL-managed-migration/#migration-steps","title":"Migration Steps","text":"<ol> <li> <p>Dump using logical or physical backup. Refer to  the steps mentioned in the Backup and Restore tutorial.</p> </li> <li> <p>Upload the dump. Transfer the data dump to an S3/GCS bucket under your control.</p> </li> <li> <p>Call the migration API. Refer to the SkySQL Managed Migration Tutorial.</p> </li> <li> <p>Start Replication. To minimize downtime during migration, set up live replication from your source database to your SkySQL database. Refer to the Replicating data from external DB Tutorial.</p> </li> </ol>"},{"location":"Data%20loading%2C%20Migration/SkySQL-managed-migration/#additional-resources","title":"Additional Resources","text":"<ul> <li>Backup with mariadb-dump</li> <li>MariaDB Backup Documentation</li> <li>Advanced Backup Techniques</li> </ul>"},{"location":"Data%20loading%2C%20Migration/nr-support-assisted/","title":"Support-Assisted Data Import","text":"<p>SkySQL customers can receive assistance when importing data into a SkySQL service:</p> <ul> <li>Many file formats are supported</li> <li>Data of large size can be imported efficiently</li> <li>Contact Support to request assistance with a data import</li> </ul>"},{"location":"Data%20offloading/","title":"Data offloading","text":"<p>There are multiple options to copy/offload data from a SkySQL DB. You can do a logical dump(i.e. output all data and DDL as SQL) to your local machine. Or, dump large data sets securely using the SkySQL Backup service to your own S3 or GCS bucket. </p> <p>You can then use the offloaded data to resurrect the DB elsewhere. You can also optionally setup \"outbound replication\" to keep the new DB in sync with SkySQL. </p>"},{"location":"Data%20offloading/#1-offload-your-database-using-mariadb-dump","title":"1. Offload your Database using <code>mariadb-dump</code>","text":"<p>The <code>mariadb-dump</code> utility is a powerful command-line tool that allows you to export databases, tables, or specific data from your MariaDB instance in SkySQL. </p>"},{"location":"Data%20offloading/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the mariadb-dump utility installed on your system. See here Obtain the necessary connection details for your SkySQL instance, including the host, username, and password.</p>"},{"location":"Data%20offloading/#exporting-all-databases","title":"Exporting All Databases","text":"<p>To export all databases from your SkySQL instance, use the following command:</p> <pre><code>mariadb-dump -h your_skysql_host -u your_username -p \\\n    --all-databases &gt; all_databases_backup.sql\n</code></pre> <ul> <li><code>-h your_skysql_host</code>: Specifies the host of your SkySQL instance.</li> <li><code>-u your_username</code>: Specifies the username to connect to the SkySQL instance.</li> <li><code>-p</code>: Prompts for the password for the specified username.</li> <li><code>--all-databases</code>: Exports all databases in the SkySQL instance.</li> <li><code>&gt; all_databases_backup.sql</code>: Redirects the output to a file named all_databases_backup.sql.</li> </ul>"},{"location":"Data%20offloading/#exporting-selected-databases","title":"Exporting Selected Databases","text":"<p>To export specific databases, list the database names after the connection details:</p> <pre><code>mariadb-dump -h your_skysql_host -u your_username \\\n    -p database1 database2 &gt; selected_databases_backup.sql\n</code></pre> <ul> <li><code>database1 database2</code>: Replace with the names of the databases you want to export.</li> <li><code>`&gt; selected_databases_backup.sql</code>: Redirects the output to a file named selected_databases_backup.sql.</li> </ul>"},{"location":"Data%20offloading/#exporting-just-the-schema","title":"Exporting Just the Schema","text":"<p>To export only the schema (structure) of a database without the data, use the --no-data option:</p> <pre><code>mariadb-dump -h your_skysql_host -u your_username -p \\\n    --no-data your_database &gt; schema_backup.sql\n</code></pre> <ul> <li><code>--no-data</code>: Ensures that only the schema is exported, not the data.</li> <li><code>your_database</code>: Replace with the name of the database whose schema you want to export.</li> <li><code>&gt; schema_backup.sql</code>: Redirects the output to a file named schema_backup.sql.</li> </ul>"},{"location":"Data%20offloading/#file-format-of-exported-data","title":"File Format of Exported Data","text":"<p>The files exported by mariadb-dump are in plain text format and contain SQL statements. These files can be used to recreate the databases, tables, and data by executing the SQL statements in a MariaDB instance.</p> <ul> <li>Database Creation: The file begins with statements to create the databases.</li> <li>Table Creation: For each table, the file includes CREATE TABLE statements that define the table structure.</li> <li>Data Insertion: If data is included, the file contains INSERT INTO statements to populate the tables with data.</li> <li>Comments: The file may include comments that provide additional information about the export process.</li> </ul> <p>Example of Exported File Content </p> <p>Here is a snippet of what an exported file might look like: <pre><code>-- MariaDB dump 10.16  Distrib 10.5.9-MariaDB, for debian-linux-gnu (x86_64)\n--\n-- Host: your_skysql_host    Database: \n-- ------------------------------------------------------\n-- Server version   10.5.9-MariaDB-1:10.5.9+maria~focal\n\n/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\n/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\n/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\n/*!40101 SET NAMES utf8mb4 */;\n\n--\n-- Database: `your_database`\n--\n\n-- --------------------------------------------------------\n\n--\n-- Table structure for table `your_table`\n--\n\nDROP TABLE IF EXISTS `your_table`;\n/*!40101 SET @saved_cs_client     = @@character_set_client */;\n/*!40101 SET character_set_client = utf8 */;\nCREATE TABLE `your_table` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(255) DEFAULT NULL,\n  `created_at` datetime DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n/*!40101 SET character_set_client = @saved_cs_client */;\n\n--\n-- Dumping data for table `your_table`\n--\n\nLOCK TABLES `your_table` WRITE;\n/*!40000 ALTER TABLE `your_table` DISABLE KEYS */;\nINSERT INTO `your_table` VALUES (1,'Example Name','2023-01-01 00:00:00'),(2,'Another Name','2023-01-02 00:00:00');\n/*!40000 ALTER TABLE `your_table` ENABLE KEYS */;\nUNLOCK TABLES;\n</code></pre></p> <p>Finally, here is the reference to the utility where you will find all the\u00a0many command-line options</p> <p>Note </p> <p>Egress charges may apply when data is exported</p>"},{"location":"Data%20offloading/#2-using-mariadb-client","title":"2. Using MariaDB client","text":"<p>Use\u00a0MariaDB Client with the connection information to export your schema from your SkySQL database service. Here is an example to export all rows from a single table:</p> <pre><code>mariadb --host FULLY_QUALIFIED_DOMAIN_NAME --port TCP_PORT \\\n      --user DATABASE_USER --password \\\n      --ssl-verify-server-cert \\\n      --default-character-set=utf8 \\\n      --batch \\\n      --skip-column-names \\\n      --execute='SELECT * FROM accounts.contacts;' \\\n      &gt; contacts.tsv\n</code></pre> <ul> <li>Replace\u00a0<code>FULLY_QUALIFIED_DOMAIN_NAME</code>\u00a0with the Fully Qualified Domain Name of your service.</li> <li>Replace\u00a0<code>TCP_PORT</code>\u00a0with the read-write or read-only port of your service.</li> <li>Replace\u00a0<code>DATABASE_USER</code>\u00a0with the default username for your service, or the username you created.</li> <li>Optionally, for large tables, specify the\u00a0<code>-quick\u00a0command-line option</code> to disable result caching and reduce memory usage.</li> <li>You can customize the SQL along with providing multiple SQL statements to <code>-execute</code>. </li> </ul>"},{"location":"Data%20offloading/#3-exporting-data-using-skysql-backup-service-api-to-s3-or-gcs-bucket","title":"3. Exporting Data Using SkySQL Backup Service API to S3 or GCS Bucket","text":"<p>The SkySQL Backup service API allows you to perform logical and physical dumps of your SkySQL databases to external storage buckets such as Amazon S3 or Google Cloud Storage (GCS). </p>"},{"location":"Data%20offloading/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>Obtain the necessary credentials for your S3 bucket.</li> <li>Ensure you have access to the SkySQL Backup service API. You need to generate the API Key from the portal. </li> <li>Obtain the service ID for your SkySQL instance.</li> <li>Base64 encodes your S3 credentials.</li> </ul>"},{"location":"Data%20offloading/#performing-a-logical-dump-to-an-s3-bucket","title":"Performing a Logical Dump to an S3 Bucket","text":"<p>To perform a logical dump of a SkySQL database to an S3 bucket, you need to make an API call to the SkySQL Backup service. Below is an example of how to do this.</p> <p>Example API Call for Logical Dump (The output is all SQL statements) <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n    \"backup_type\": \"logical\",\n    \"schedule\": \"once\",\n    \"service_id\": \"your_service_id\",\n    \"external_storage\": {\n        \"bucket\": {\n            \"path\": \"s3://your_s3_bucket_name/path/to/backup\",\n            \"credentials\": \"your_base64_encoded_credentials\"\n        }\n    }\n}'\n</code></pre></p> <ul> <li>backup_type: Set to \"logical\" for a logical dump.</li> <li>schedule: Set to \"once\" to schedule the backup immediately.</li> <li>service_id: The ID of your SkySQL service.</li> <li>external_storage.bucket.path: The S3 bucket path where the backup will be stored.</li> <li>external_storage.bucket.credentials: Base64 encoded S3 credentials.</li> </ul>"},{"location":"Data%20offloading/#performing-a-physical-dump-to-an-s3-bucket","title":"Performing a Physical Dump to an S3 Bucket","text":"<p>When databases are large and you want to move the data around securely this is likely the best option. To perform a physical dump of a SkySQL database to an S3 bucket, you need to make a similar API call but specify the backup type as \"physical\".</p> <p>Example API Call for Physical Dump <pre><code>curl --location 'https://api.skysql.com/skybackup/v1/backups/schedules' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n    \"backup_type\": \"physical\",\n    \"schedule\": \"once\",\n    \"service_id\": \"your_service_id\",\n    \"external_storage\": {\n        \"bucket\": {\n            \"path\": \"s3://your_s3_bucket_name/path/to/backup\",\n            \"credentials\": \"your_base64_encoded_credentials\"\n        }\n    }\n}'\n</code></pre></p> <ul> <li>backup_type: Set to \"physical\" for a physical dump.</li> <li>schedule: Set to \"once\" to schedule the backup immediately.</li> </ul>"},{"location":"Data%20offloading/#checking-the-status-of-initiated-backups","title":"Checking the Status of Initiated Backups","text":"<p>Backups are always scheduled as jobs and the time taken will depend on the size of yourDB. To check the status of the initiated backups, you can use the following API call:</p> <pre><code>Example API Call to Check Backup Status\ncurl --location 'https://api.skysql.com/skybackup/v1/backups/status' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'X-API-Key: ${API_KEY}' \\\n--data '{\n    \"service_id\": \"your_service_id\"\n}'\n</code></pre> <ul> <li>service_id: The ID of your SkySQL service. This API call will return the status of the backups, including whether they are in progress, completed, or failed.</li> </ul>"},{"location":"Data%20offloading/#4-replicating-changes-from-skysql-to-a-compatible-external-db","title":"4. Replicating changes from SkySQL to a compatible external DB","text":"<p>See Replicating data From SkySQL to External Database for details.</p>"},{"location":"Data%20offloading/Replicating%20data%20from%20SkySQL%20to%20external%20database/","title":"Replicating data from SkySQL to external database","text":"<p>SkySQL customers can configure outbound replication from a Replicated Transactions service to a compatible MariaDB Server running elsewhere - could be your data center, self-managed MariaDB DB on the cloud or even other managed services like AWS RDS. </p> <p>SkySQL uses stored procedures to configure replication to other MariaDB or MySQL database servers. </p> <p>For additional information about the stored procedures used to configure replication with Replicated Transactions services, see SkySQL Replication Helper Procedures for Replicated Transactions</p>"},{"location":"Data%20offloading/Replicating%20data%20from%20SkySQL%20to%20external%20database/#requirements","title":"Requirements","text":"<p>To configure outbound replication from your Replicated Transactions service in SkySQL to an external replica server using MariaDB Server, the following requirements must be met:</p> <ul> <li>The external replica server must use a supported version of MariaDB Server, and the external replica server must use a version in the same or newer release series as the version used by the SkySQL service.</li> <li>When the SkySQL service uses\u00a0ES 10.6, the following versions are supported for the external replica server:<ul> <li>MariaDB Server 10.6</li> </ul> </li> <li>When the SkySQL service uses\u00a0ES 10.5, the following versions are supported for the external replica server:<ul> <li>MariaDB Server 10.5</li> <li>MariaDB Server 10.6</li> </ul> </li> <li>When the SkySQL service uses\u00a0ES 10.4, the following versions are supported for the external replica server:<ul> <li>MariaDB Server 10.4</li> <li>MariaDB Server 10.5</li> <li>MariaDB Server 10.6</li> </ul> </li> </ul>"},{"location":"Data%20offloading/Replicating%20data%20from%20SkySQL%20to%20external%20database/#create-user-for-outbound-replication","title":"Create User for Outbound Replication","text":"<p>With the default database admin user provided, create an external_replication user as seen below.</p> <pre><code>CREATE USER 'replication_user'@'%' IDENTIFIED BY 'bigs3cret';\nGRANT REPLICATION SLAVE ON *.* TO \u2018external_replication\u2019@'hostname';\n</code></pre>"},{"location":"Data%20offloading/Replicating%20data%20from%20SkySQL%20to%20external%20database/#check-user-account","title":"Check User Account","text":"<p>On the SkySQL service, confirm that the new user has sufficient privileges by executing\u00a0</p> <p><pre><code>SHOW GRANTS FOR 'external_replication'@'%';\n</code></pre> <pre><code>+-------------+\n| Grants for external_replication@%                                                                                                              |\n+-------------+\n| GRANT REPLICATION SLAVE, SLAVE MONITOR ON *.* TO `external_replication`@`%` IDENTIFIED BY PASSWORD '*CCD3A959D6A004B9C3807B728BC2E55B67E10518' |\n+-------------+\n</code></pre></p>"},{"location":"Data%20offloading/Replicating%20data%20from%20SkySQL%20to%20external%20database/#add-external-replica-to-allowlist","title":"Add External Replica to Allowlist","text":"<p>On the SkySQL Customer Portal, add the IP address of the external replica server to the SkySQL service's\u00a0allowlist - Click \u2018Manage\u2019\u2192 \u2018Manage Allowlist\u2019 to add the IP address to the allowed list. </p>  \ud83d\udca1 Note that if your \u2018external replica server\u2019 is also running on SkySQL (say for DR), you can find the outbound IP address from the \u2018Details\u2019 tab (Select on the Service name on the dashboard, then click \u2018Details\u2019)"},{"location":"Data%20offloading/Replicating%20data%20from%20SkySQL%20to%20external%20database/#obtain-gtid-position","title":"Obtain GTID Position","text":"<p>On the SkySQL service, obtain the GTID position from which to start replication.</p> <p>When you want to start replication from the most recent transaction, the current GTID position can be obtained by querying the value of the\u00a0'gtid_current_pos:</p> <pre><code>SHOW GLOBAL VARIABLES\n   LIKE 'gtid_current_pos';\n</code></pre> <pre><code>`+------------------+-------------------+\n| Variable_name    | Value             |\n+------------------+-------------------+\n| gtid_current_pos | 435700-435700-124 |\n+------------------+-------------------+`\n</code></pre>"},{"location":"Data%20offloading/Replicating%20data%20from%20SkySQL%20to%20external%20database/#configure-gtid-position","title":"Configure GTID Position","text":"<p>On the external replica server, configure the GTID position from which to start replication.</p> <p>The GTID position can be configured by setting the\u00a0'gtid_slave_pos':</p> <pre><code>SET GLOBAL gtid_slave_pos='435700-435700-124';\n</code></pre>"},{"location":"Data%20offloading/Replicating%20data%20from%20SkySQL%20to%20external%20database/#configure-replication","title":"Configure Replication","text":"<p>On the external replica server, configure replication using the\u00a0connection parameters for your SkySQL service.</p> <p>Replication can be configured using the\u00a0'CHANGE\u00a0MASTER\u00a0TO' SQL\u00a0statement:</p> <pre><code>CHANGE MASTER TO\n   MASTER_HOST='FULLY_QUALIFIED_DOMAIN_NAME',\n   MASTER_PORT=TCP_PORT,\n   MASTER_USER='external_replication',\n   MASTER_PASSWORD='my_password',\n   MASTER_SSL=1,\n   MASTER_SSL_CA='~/PATH_TO_PEM_FILE',\n   MASTER_USE_GTID=slave_pos;\n</code></pre> <ul> <li>Replace\u00a0<code>FULLY_QUALIFIED_DOMAIN_NAME</code>\u00a0with the Fully Qualified Domain Name of your service</li> <li>Replace\u00a0<code>TCP_PORT</code>\u00a0with the read-write or read-only port of your service</li> <li>Replace\u00a0<code>~/PATH_TO_PEM_FILE</code>\u00a0with the path to the certificate authority chain (.pem) file</li> </ul>"},{"location":"Data%20offloading/Replicating%20data%20from%20SkySQL%20to%20external%20database/#start-replication","title":"Start Replication","text":"<p>On the external replica server, start replication.</p> <p>Replication can be started using the\u00a0'START\u00a0REPLICA' SQL\u00a0statement:</p> <pre><code>START REPLICA;\n</code></pre>"},{"location":"Data%20offloading/Replicating%20data%20from%20SkySQL%20to%20external%20database/#finally-check-replication-status","title":"Finally, Check Replication Status","text":"<p>On the external replica server, check replication status.</p> <p>Replication status can be checked using the\u00a0'SHOW\u00a0REPLICA\u00a0STATUS' SQL\u00a0statement:</p> <pre><code>SHOW REPLICA STATUS \\G\n\n*************************** 1. row ***************************\n                Slave_IO_State: Waiting for master to send event\n                   Master_Host: my-service.mdb0002147.db.skysql.net\n                   Master_User: external_replication\n                   Master_Port: 5003\n                 Connect_Retry: 60\n               Master_Log_File: mariadb-bin.000001\n           Read_Master_Log_Pos: 558\n                Relay_Log_File: mariadb-relay-bin.000002\n                 Relay_Log_Pos: 674\n         Relay_Master_Log_File: mariadb-bin.000001\n              Slave_IO_Running: Yes\n             Slave_SQL_Running: Yes\n               Replicate_Do_DB:\n           Replicate_Ignore_DB:\n            Replicate_Do_Table:\n        Replicate_Ignore_Table:\n       Replicate_Wild_Do_Table:\n   Replicate_Wild_Ignore_Table:\n                    Last_Errno: 0\n                    Last_Error:\n                  Skip_Counter: 0\n           Exec_Master_Log_Pos: 558\n               Relay_Log_Space: 985\n               Until_Condition: None\n                Until_Log_File:\n                 Until_Log_Pos: 0\n            Master_SSL_Allowed: Yes\n            Master_SSL_CA_File: /var/lib/mysql/skysql_chain.pem\n            Master_SSL_CA_Path:\n               Master_SSL_Cert:\n             Master_SSL_Cipher:\n                Master_SSL_Key:\n         Seconds_Behind_Master: 0\n Master_SSL_Verify_Server_Cert: No\n                 Last_IO_Errno: 0\n                 Last_IO_Error:\n                Last_SQL_Errno: 0\n                Last_SQL_Error:\n   Replicate_Ignore_Server_Ids:\n              Master_Server_Id: 435701\n                Master_SSL_Crl: /var/lib/mysql/skysql_chain.pem\n            Master_SSL_Crlpath:\n                    Using_Gtid: Slave_Pos\n                   Gtid_IO_Pos: 435700-435700-127\n       Replicate_Do_Domain_Ids:\n   Replicate_Ignore_Domain_Ids:\n                 Parallel_Mode: optimistic\n                     SQL_Delay: 0\n           SQL_Remaining_Delay: NULL\n       Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates\n              Slave_DDL_Groups: 0\nSlave_Non_Transactional_Groups: 0\n    Slave_Transactional_Groups: 0\n</code></pre>"},{"location":"High%20Availability%2C%20DR/","title":"Higher Availability and Disaster Recovery Concepts","text":"<p>Note</p> <p>SkySQL provides HA using semi-synchronous replicas. Unlike hyperscalers these replicas are not standy DB servers but actively used for Reads. When the primary crashes our intelligent proxy allows us to failover near instantly to an alternate replica. Or, failback when the original primary recovers. Ensuring data consistency even when replicas have a replication lag through \u201ccausal reads\u201d, or transaction replay. </p>"},{"location":"High%20Availability%2C%20DR/#use-replicated-topology-for-ha","title":"Use 'Replicated Topology' for HA","text":"<p>For HA and Load balancing client requests there is no configuration required. Just launch a <code>replicated topology</code> DB service. SkySQL automatically starts an intelligent proxy that does all the heavy lifting. Detecting failures and replaying transactions, awareness of who the primary is at all times, balancing load and much more. </p> <p>You should be aware of the <code>causal_reads</code> configuration as outlined below. The sections below provide a more detailed description of how SkySQL delivers on HA and scaling across replicas. </p>"},{"location":"High%20Availability%2C%20DR/#level-1-resiliency-container-health-checks-compute-storage-isolation","title":"Level 1 Resiliency - container health checks, compute-storage isolation","text":"<p>To provide high resiliency we try to protect every layer of the stack \u2013 disks, compute, Zones/cloud regions, network and even the load balancer accepting incoming DB connections. The graphic below depicts this architecture. Let\u02bcs peel the onion a bit.</p> <p>All Cloud databases configured for HA replicate the data across multiple availability zones (AZ). Ensuring your data is protected against data center failures. This is necessary, but not sufficient. In SkySQL, data is always isolated from compute on the underlying block storage device of each AZ. This device keeps a copy of each block on multiple servers providing the first layer of protection against component failures or corruption.</p> <p>The deployment of DB servers occurs within containers orchestrated by Kubernetes (k8s). In the event of cloud instance failures, SkySQL\u2019s health monitoring prompts k8s to revive the container in an alternate instance, seamlessly reconnecting to the same storage volume. AWS RDS, for example, runs MariaDB on VMs requiring a replicated setup for any protection against node failures.</p>"},{"location":"High%20Availability%2C%20DR/#level-2-resiliency-failover-using-intelligent-proxy","title":"Level 2 Resiliency - Failover using Intelligent proxy","text":"<p>While hardware failures are a possibility, a more common scenario we see in practice involves a DB crash due to resource exhaustion or timeouts\u2014such as running out of allocated temp space due to rogue queries or an unplanned large spike in data load. In such instances, it is crucial for application connections to smoothly transition to an alternate server.</p> <p>Behind the scenes, SkySQL consistently directs SQL through its intelligent proxy. This proxy not only continuously monitors servers for failures but also remains acutely aware of any replication lags in the replica servers. Should a primary server fail, an immediate election process ensues to select a replica with the least lag. Simultaneously, attempts are made to flush any pending events, ensuring synchronization and full data consistency. Any pending transactions on the primary server are also replayed. Collectively, these measures enable applications to operate without connection-level interruptions or SQL exceptions. Achieving heightened levels of High Availability (HA) is effortlessly attainable by expanding the number of replicas. Replication can even extend across different cloud providers or to a self-managed (\u02eepeace of mind\u02ee) replica within a customer\u02bcs own environment.</p> <p></p> <p>HA in a single region</p>"},{"location":"High%20Availability%2C%20DR/#scaling-concurrent-users-without-compromising-consistency","title":"Scaling Concurrent Users without Compromising Consistency","text":"<p>Cloud offerings of open source relational databases often achieve scalability by distributing data across a cluster of nodes, often relying on a replication model where \u2018writes\u2019 to the primary node are asynchronously transmitted to one or more replicas. Typically, the onus is on the customer to manage the distribution of traffic across the cluster, either through client application logic or by configuring a proxy service. Several customers have told us that this is simply too big a challenge, effectively capping the scalability of these cloud solutions. Even when customers successfully navigate this challenge, with this approach data consistency might not be uniform across the entire cluster at any given moment.</p> <p>When application client connections are evenly load balanced across these replicas for \u2018reads,\u2019 the application must either tolerate potentially stale reads or consistently direct all requests to the primary, severely limiting scalability. Replicas are relegated to offline tasks like reporting \u2014 a common scenario from our observations in AWS RDS.</p> <p>Contrastingly, in SkySQL, the intelligent proxy provides consistency options without compromising its ability to load balance requests across replicas, supporting both \u2018causal\u2019 and \u2018strong, global\u2019 consistency models. Let\u2019s delve deeper.</p> <p>Causal consistency ensures that \u2018reads\u2019 are fresh only concerning the writes they are causally dependent on. For instance, when an app client executes a \u2018write\u2019 followed by a \u2018read,\u2019 it expects to see the changed value, causally dependent on the preceding \u2018write.\u2019 This sequence may need to be satisfied exclusively by the primary if the replicas lag behind. Concurrent clients, however, continue to be load balanced across all servers.</p> <p>This model functions optimally when application clients utilize sticky SQL connections. However, in the modern landscape where applications are often distributed (micro services) and rely on connection pooling frameworks, a \u2018write\u2019 and the subsequent \u2018read\u2019 might occur on different connections. To ensure consistent reads, awareness of the \u2018lag\u2019 at a global level is imperative. Fortunately, this is seamlessly achieved with a simple switch in SkySQL. If the \u2018write\u2019 rate is moderate and the replicas can keep up (a prevalent scenario in practice), clients continue to uniformly utilize the entire cluster.</p>"},{"location":"High%20Availability%2C%20DR/#configuring-causal-read-in-skysql","title":"Configuring Causal Read in SkySQL","text":"<p>Causal consistency is configured in the SkySQL Configuration Manager, under Maxscale Variables (applies to Replicated clusters only). Search for causal reads.</p> <p></p> <p>[!IMPORTANT] We do not advise adjusting <code>causal_reads</code> unless absolutely necessary. Adjust the max_slave_replication_lag, which determines the max lag &gt; for any read. The load balancer will only routes to slaves with a lag less than this value. By default, this is unbounded. Make sure none of the replicas ever cross 70-80% CPU in a sustained manner.</p> <p>In general, if the application is not performing large transactions or batch writes, given our default semi-sync replication, the replica SQL threads will keep up - i.e. getting an inconsistent read is unlikely.</p> <p>Our replication model is fast as it is configured to be parallel and optimistic - on the replica multiple SQL threads process incoming writes concurrently. It is designed to detect conflicts and revert to proper sequencing, thus being transparent to the app and ensuring consistency.</p> <ul> <li>Set causal_reads to 'local' to achieve consistency at a connection/session level.<ul> <li>We recommend first exploring to see if <code>causal_reads</code> set to <code>local</code> will suffice. This is quite fast (minimal to no tradeoff) and ensures read consistency at a connection/session level. If the app is using a connection pool, it is important to understand how it is being used.</li> <li>Example: A banking app lets a user transfer $100 between accounts in a single session. The app writes the debit and credit, then reads the updated balances to show the user. The connection pool reuses the same session for the transaction and follow-up read. Replica lag is 500ms, but semi-sync replication and parallel SQL threads keep it minimal. The write (debit $100, credit $100) is committed on the primary. Within the same session, the read on the replica waits for the write to be applied (up to 500ms), then returns the correct balances.</li> </ul> </li> <li>Set causal_reads to 'global' for strict consistency across all connections.<ul> <li>If global read consistency is a must, first try <code>global</code>. To use this, you will also need to tune the causal_reads_timeout. Reads will be load balanced, and a reader will wait a max of this timeout before giving up and retrying on the primary node. That is, if the replica is lagging, it will wait for this time to see if the replica catches up.</li> <li>Example: A social media app displays a user\u2019s post immediately after they submit it. Reads are load-balanced across replicas, but one replica is lagging due to a batch write. Assume the setup is causal_read_timeout = 300ms, replica lag is 400ms; primary CPU is at 50%, replicas at 70-80%. User posts a message (write goes to primary). Read is routed to a lagging replica, which waits 300ms for the write to apply but times out (lag &gt; timeout). Query retries on the primary, taking 301ms total instead of the usual 1ms. The takeaway here is that global ensures consistency across all nodes but can degrade performance if replicas lag beyond causal_read_timeout. Tune the timeout and monitor lag carefully.</li> </ul> </li> <li>Set causal_reads to 'fast' to achieve consistency at a connection/session level but is faster than 'local' but at the cost of load balancing.<ul> <li>If and only if your application is very read heavy, you should consider <code>fast_global</code>. This relies on <code>monitor_interval</code> (Maxscale tracks each replica once in this interval) to know if the replicas have caught up or are behind. This will likely need to be configured in milliseconds.</li> <li>Example: A real-time analytics dashboard updates every 200ms with new data. The app is read-heavy, querying replicas constantly. The setup is monitor_interval = 300ms (MaxScale polls replicas every 300ms). Writes occur every 200ms; replicas lag by 100-200ms. A write updates the data at T=0ms. At T=200ms, a read hits a replica. MaxScale\u2019s last poll (T=-100ms) shows the replica as caught up, but it\u2019s now behind by 200ms. The read returns stale data because monitor_interval &gt; write frequency. All traffic shifts to the primary since replicas can\u2019t keep up reliably. The takeaway is that fast_global works for read-heavy apps only if monitor_interval is tuned lower than the write frequency (e.g., 100ms here), but it risks routing all traffic to the primary if misconfigured.</li> </ul> </li> </ul>"},{"location":"High%20Availability%2C%20DR/#increased-throughput-using-active-active","title":"Increased throughput using Active-Active","text":"<p>Unlike RDS or GCP, where the standby is not used for client requests (wasting resources), SkySQL maximizes the available compute power across all nodes, delivering unparalleled cost effectiveness.</p> <p>A notable feature enhancing performance is the \u2018Read-Write Splitting,\u2019 allowing for custom routing to achieve consistently lower latencies for specific application patterns. For example, point queries and index-optimized queries can be directed to select nodes hosting frequently accessed data, while more resource-intensive scan-aggregation class queries (such as those for reporting dashboards or complex queries based on end-user selections of historical data) can be routed to a separate set of nodes. These routing strategies effectively segment actively used data sets, optimizing the DB buffer cache and resulting in lower latencies.</p> <p>The implementation of these routing strategies is straightforward, primarily through the use of \u201cHint Filters.\u201d Standard SQL comments are utilized to customize routing to the appropriate server. Additional details on Hint Filters and Read-Write Splitting can be found in the MariaDB documentation.</p> <p>In SkySQL you can control routing using 2 strategies:</p> <ul> <li>Using the <code>read port</code> for the service: Typically this will be port 3307. When using this port the request (read_only) will be load balanced only across the available replicas. </li> <li>Using the Hintfilter  (TODO: provide detailed example using SkySQL node names)</li> </ul>"},{"location":"High%20Availability%2C%20DR/#level-3-resiliency-disaster-recovery-across-regions-cloud-providers-or-self-managed-environments","title":"Level 3 Resiliency -  Disaster Recovery \u2013 Across Regions, Cloud Providers, or \u201cSelf-managed\u201d Environments","text":"<p>Note</p> <p>Please refer to this document for the steps to setup a distant replica for DR. </p> <p>The major cloud providers tout disaster recover across regions, ensuring resilience against natural disasters impacting an entire geographical region. But in reality, such disasters are exceedingly rare. What\u02bcs far more common are technical issues impacting an entire region for a specific cloud provider. For instance, we\u2019ve encountered DNS-level failures in GCP regions, rendering all services dependent on DNS, including SkySQL, inaccessible.</p> <p>One effective strategy to mitigate such risks is to replicate data to a data center owned by a different cloud provider within the same geographical area, minimizing network latencies. Disaster recovery across cloud providers is of course something an individual provider such as AWS or GCP simply don\u02bct support. Alternatively, customers can maintain their own \u201cstandby\u201d database for emergencies\u2014an environment entirely under their control, ensuring a near-real time copy of the data at all times.</p> <p></p> <p>Failover when entire region becomes unavailable</p> <p>SkySQL empowers users to configure \u201cexternal\u201d replicas that can run anywhere, offering flexibility and resilience.</p> <p>To facilitate this, SkySQL provides several built-in stored procedures for configuring both \u201coutbound\u201d and \u201cinbound\u201d replication to any compatible MariaDB or MySQL server environment. This flexibility allows users to tailor their disaster recovery strategy based on their specific needs, whether replicating across regions, cloud providers, or maintaining self-managed standby environments.</p>"},{"location":"High%20Availability%2C%20DR/Setup%20Global%20Replication/","title":"Setup Global Replication","text":"<p>SkySQL offers a robust platform for managing databases in the cloud and supports Global Replication for various use cases including disaster recovery, cross-region failover and global distribution of data. In this guide, we\u2019ll explore how to automate the creation, restoration and replication of SkySQL database services for global availability using the SkySQL API. We will use the following SkySQL resources for the setup:</p> <ul> <li>Provisioning APIs: To launch primary and secondary SkySQL services.</li> <li>Backup APIs: To backup the primary service and restore the data to the secondary service.</li> <li>Replication Procedures: To setup active replication between the primary and the secondary services.</li> </ul>"},{"location":"High%20Availability%2C%20DR/Setup%20Global%20Replication/#step-1-generate-skysql-api-key","title":"Step 1: Generate SkySQL API Key","text":"<p>1. Go to the User Profile page of the SkySQL Portal to generate an API key. 2. Export the value from the token field to an environment variable $API_KEY</p> <pre><code>$ export API_KEY='... key data ...'\n</code></pre> <p>The\u00a0<code>API_KEY</code>\u00a0environment variable will be used in the subsequent steps.</p>"},{"location":"High%20Availability%2C%20DR/Setup%20Global%20Replication/#step-2-launch-skysql-services","title":"Step 2: Launch SkySQL Services","text":"<p>Launch two SkySQL services - a Primary that your application(s) will connect to and a Secondary that will act as a globally available service. If you already have your Primary service running, you simply need to create a new Secondary service. </p> <p>Note</p> <p>You can launch these services using the Portal or Using the REST API as shown below. Launching a new service will take about 5 minutes. </p> <p>1. Following API requests will create two services in Google Cloud - 'skysql-primary' in the Virginia region and 'skysql-secondary' in the Oregon region. </p> <pre><code>curl --location --request POST https://api.skysql.com/provisioning/v1/services \\\n   --header \"X-API-Key: ${API_KEY}\" --header \"Content-type: application/json\" \\\n   --data '{\n\"service_type\": \"transactional\",\n\"topology\": \"standalone\",\n\"provider\": \"gcp\",\n\"region\": \"us-east4\",\n\"architecture\": \"amd64\",\n\"size\": \"sky-2x8\",\n\"storage\": 100,\n\"nodes\": 1,\n\"name\": \"skysql-primary\",\n\"ssl_enabled\": true\n}'\n</code></pre> <pre><code>curl --location --request POST https://api.skysql.com/provisioning/v1/services \\\n   --header \"X-API-Key: ${API_KEY}\" --header \"Content-type: application/json\" \\\n   --data '{\n\"service_type\": \"transactional\",\n\"topology\": \"standalone\",\n\"provider\": \"gcp\",\n\"region\": \"us-west1\",\n\"architecture\": \"amd64\",\n\"size\": \"sky-2x8\",\n\"storage\": 100,\n\"nodes\": 1,\n\"name\": \"skysql-secondary\",\n\"ssl_enabled\": true\n}'\n</code></pre> <p>2. Each SkySQL service has a unique identifier. Please make note of the identifier shown in the API response. We will need it later.</p>"},{"location":"High%20Availability%2C%20DR/Setup%20Global%20Replication/#step-3-backup-the-primary-and-restore-to-the-secondary-service","title":"Step 3: Backup the Primary and Restore to the Secondary Service","text":"<p>In a real world scenario, the Primary service will contain data which will need to be restored to the Standby service before the replication can be set up. SkySQL performs full backup of your services every night. You can either use an existing nightly backup or create a schedule to perform a new full backup.</p> <p>Note</p> <p>Depending on the size of your databases, backing up a service can take substantial time. Creating a new backup is not necessary if you already have an existing full backup of your service. If you have a recent backup (usually available) you can skip the step. After we restore from the backup we have to replay all the subsequent DB changes from the Source DB 'binlog'. Binlogs expire in 4 days, by default. So, you cannot use a backup older than 4 days. </p> <p>1. Use the following API to list backups associated with the Primary service. Replace {id} with the database id of the Primary service. Look for a \"FULL\" backup or \"snapshot\". </p> <pre><code>curl --location --request GET https://api.skysql.com/skybackup/v1/backups?service_id={id} \\\n   --header \"X-API-Key: ${API_KEY}\" --header \"Content-type: application/json\"\n</code></pre> <p>You can also look for recent \"FULL\" backups from the Portal. If not available you can also initiate a backup from the Portal or using the API below. </p> <p>1. Use the following API to create a one-time schedule to perform a new full backup. Replace {id} with the id of the Primary service.</p> <pre><code>curl --location --request POST https://api.skysql.com/skybackup/v1/backups/schedules \\\n   --header \"X-API-Key: ${API_KEY}\" --header \"Content-type: application/json\" \\\n   --data '{\n\"backup_type\": \"full\",\n\"schedule\": \"once\",\n\"service_id\": \"{id}\"\n}'\n</code></pre> <p>2. Each backup also has a unique identifier. Make note of the identifier shown in the API response. Now use the following API to restore the backup to the Secondary service. </p> <p>Note</p> <p>Please note that restoring the backup on a SkySQL service will stop the service if it is running and will wipe out all existing data. </p> <p>Replace {backup-id} with the backup id that you want to restore and {service-id} with the id of the Secondary service.</p> <pre><code>curl --location --request POST https://api.skysql.com/skybackup/v1/restores \\\n   --header \"X-API-Key: ${API_KEY}\" --header \"Content-type: application/json\" \\\n   --data '{\n\"id\": \"{backup-id}}\",\n\"service_id\": \"{service-id}\"\n}'\n</code></pre> <p>Note</p> <p>As of July 2024, you can only restore from Backups within the same Cloud provider. To restore to a different provider, you would need to explicitly Backup to your own S3/GCS bucket, copy the folder over to the other provider's bucket and initiate a Restore. Please refer to the Backup Service docs.</p> <p>Note</p> <p>Once the restore is complete, the default username and password displayed in the \"connect\" window of the Secondary service will not work. Restore overwrites this information with the username and password of the Primary service. Hence, you will have to use Primary service's username and password to connect to the Secondary service.</p>"},{"location":"High%20Availability%2C%20DR/Setup%20Global%20Replication/#step-4-set-up-replication-between-the-primary-and-the-secondary","title":"Step 4: Set up Replication between the Primary and the Secondary","text":"<p>1. Since we want to set up replication between the two SkySQL services, the Secondary service should be able to connect to the Primary service. Add the Outbound IP address of the Secondary service to the Allowlist of the Primary service. Outbound IP can be obtained from the \"Service Details\" page in the SkySQL portal. Please add this IP to the allowlist of Primary service in the portal.</p> <p>2. Next, obtain the GTID position from which to start the replication by using the following API. Please replace {service_id} with the service id of the primary service. <pre><code>curl --location --request GET \"https://api.skysql.com/skybackup/v1/backups?service_id={service_id}\" \\\n  --header \"X-API-Key: ${API_KEY}\" --header \"Content-type: application/json\" | jq\n</code></pre> Make  note of the gtid position (\"binlog_gtid_position\") in the API response output. </p> <p>3. Now configure the Secondary service by calling the following stored procedure. Replace 'host' and 'port' with the Primary service's hostname and port. Replace 'gtid' with the GTID position obtained from the previous step. Use true/false for whether to use SSL.</p> <p><pre><code>CALL sky.change_external_primary_gtid(host, port, gtid, use_ssl_encryption);\n</code></pre> Alternatively, the above command can be used with \"binlog_file\" and \"binlog_position\" output from step #2 above. </p> <pre><code>CALL sky.change_external_primary\n  ('dbpwfxxxx.sysp0000.db1.skysql.com',\n   3306,\n   'mariadb-bin.000007',\n   xxxxx,\n   true);\n</code></pre> <p>If successful, you should see an output similar to below. </p> <pre><code>+-----------------------------------------------------------------------------------------------------------------------------------------+\n| Run_this_grant_on_your_external_primary                                                                                                 |\n+-----------------------------------------------------------------------------------------------------------------------------------------+\n| GRANT REPLICATION SLAVE ON *.* TO 'skysql_replication_dbpwxxxxx'@'174.x.x.x' IDENTIFIED BY 'xxxxxxxxxx'; |\n+-----------------------------------------------------------------------------------------------------------------------------------------+\n</code></pre> <p>Please copy the \"GRANT REPLICATION...\" command from the output and run in the primary service. </p> <p>4. Start replication and check status on the Secondary service using the following procedures:</p> <pre><code>CALL sky.start_replication();\nCALL sky.replication_status();\n</code></pre> <p>5. Once the replication is setup, verify the status of the new database service in the SkySQL console. Ensure that the service is replicating for your use case for global replication.</p>"},{"location":"Integrations/DBGate/","title":"DBGate","text":""},{"location":"Integrations/DBGate/#steps","title":"Steps:","text":"<ol> <li>Open DBGate and create a new connection.</li> <li>Select MariaDB as the database type.</li> <li>Enter the SkySQL hostname, port, username, and password.</li> <li>Navigate to the SSL tab in the Connection window.</li> <li>Check the Use SSL option.</li> <li>Click Connect to establish the connection.</li> </ol>"},{"location":"Integrations/DBGate/#notes","title":"Notes:","text":"<ul> <li>No need to configure additional SSL certificate files in most cases, just select Use SSL and you're good to go.</li> <li>Make sure DBGate is updated to the latest version for best compatibility.</li> </ul>"},{"location":"Integrations/DBeaver/","title":"DBeaver","text":""},{"location":"Integrations/DBeaver/#steps","title":"Steps:","text":"<ol> <li>Open DBeaver and create a new connection.</li> <li>Select MariaDB as the database type.</li> <li>Enter the hostname, port, username, and password provided by your SkySQL instance.</li> <li>Navigate to the SSL tab.</li> <li>Check the Use SSL option if SSL is enabled for your SkySQL instance.</li> <li>Click Test Connection to ensure everything is set up correctly.</li> </ol>"},{"location":"Integrations/DBeaver/#notes","title":"Notes:","text":"<ul> <li>Ensure you are using the latest MariaDB driver in DBeaver to avoid compatibility issues.</li> <li>If you experience connection issues, verify your firewall settings and database credentials.</li> </ul>"},{"location":"Integrations/HeidiSQL/","title":"HeidiSQL","text":""},{"location":"Integrations/HeidiSQL/#steps","title":"Steps:","text":"<ol> <li>Open HeidiSQL and create a new session.</li> <li>Choose MySQL as the connection type.</li> <li>Enter the SkySQL credentials including hostname, port, username, and password.</li> <li>If SSL is enabled, go to the SSL tab.</li> <li>Check Use SSL.</li> <li>Test the connection and click Open.</li> </ol>"},{"location":"Integrations/HeidiSQL/#notes","title":"Notes:","text":"<ul> <li>Ensure your HeidiSQL client is up to date.</li> <li>Using updated drivers on new MariaDB versions is essential as out of date drivers will return \"Authentication failed\" errors. It may be nessecary to manually install new drivers on Windows.</li> </ul>"},{"location":"Integrations/TablePlus/","title":"TablePlus","text":""},{"location":"Integrations/TablePlus/#steps","title":"Steps:","text":"<ol> <li>Open TablePlus and create a new connection.</li> <li>Select MariaDB as the connection type.</li> <li>Input the connection details (hostname, port, username, and password) from your SkySQL instance.</li> <li>If SSL is configured, set the SSL Mode to ENFORCE.</li> <li>Click Connect to test the connection.</li> </ol>"},{"location":"Integrations/TablePlus/#notes","title":"Notes:","text":""},{"location":"Portal%20features/","title":"Portal features","text":"<p>From the SkySQL Portal, you can launch, monitor, and manage your SkySQL services.</p>"},{"location":"Portal%20features/#access-the-portal","title":"Access the Portal","text":"<p>You can access the Portal here</p>"},{"location":"Portal%20features/#dashboard","title":"Dashboard","text":"<p>From the Dashboard, you can see a list of your SkySQL services and status information for each service.</p> <p>From a different view, the Dashboard can be accessed by clicking the \"Dashboard\" link in the main menu (left navigation in the Portal).</p>"},{"location":"Portal%20features/#launch","title":"Launch","text":"<p>To launch a new service, click the \"+ Launch New Service\" button on the Dashboard.</p> <p>See \"Service Launch\" for details on the service launch process and launch-time selections.</p>"},{"location":"Portal%20features/#service-specific-interfaces","title":"Service-Specific Interfaces","text":"<p>Service-specific interfaces are available from the Dashboard by clicking on the service name for the desired service.</p> <p>Service-specific interfaces will vary by topology.</p> <p>Service-specific interfaces are provided to:</p> <ul> <li>Connect</li> <li>Manage</li> <li>Monitor</li> <li>Service Details</li> <li>Alerts</li> <li>Logs</li> </ul>"},{"location":"Portal%20features/#connect","title":"Connect","text":"<p>From the Dashboard, the details needed to connect to your SkySQL service can be seen by clicking on the \"CONNECT\" button for the desired service.</p> <p>See \"Client Connections\" for details on how to connect to a service.</p>"},{"location":"Portal%20features/#manage","title":"Manage","text":"<p>From the Dashboard, the \"MANAGE\" button for a service provides access to:</p> <ul> <li>Self-Service Operations\u00a0to stop/start, delete, or scale your service</li> <li>Security access\u00a0to manage the firewall</li> <li>Autonomous\u00a0settings for auto-scale of nodes and auto-scale of storage</li> <li>Apply custom configuration</li> </ul>"},{"location":"Portal%20features/#billing","title":"Billing","text":"<p>The Dashboard includes a Spending gauge to indicate current charges. More detailed billing information can be accessed by clicking on the Spending gauge.</p> <p>Alternatively, you can access detailed billing and invoice information by clicking on your name in the upper-right corner of the interface, then select \"Billing\" from the menu.</p> <p>See \"Billing\" for additional details.</p>"},{"location":"Portal%20features/#monitoring","title":"Monitoring","text":"<p>The Dashboard includes monitoring gauges for Current SQL Commands, CPU Load, and QPS (Queries Per Second). More detailed monitoring can be accessed by clicking on one of these gauges.</p> <p>Alternatively, you can access detailed server and service monitoring by clicking on the service name from the Dashboard, then accessing the Monitoring tab (the default view).</p> <p>See \"Monitoring\" for additional details.</p>"},{"location":"Portal%20features/#alerts","title":"Alerts","text":"<p>The Dashboard includes the count of active monitoring alerts for your service. More detailed alert information can be accessed by clicking on the Alerts gauge.</p> <p>Alternatively, you can access monitoring alerts by clicking the \"Alerts\" link in the main menu (left navigation in the Portal).</p>"},{"location":"Portal%20features/#logs","title":"Logs","text":"<p>Server log files can be accessed by clicking the \"Logs\" link in the main menu (left navigation in the Portal).</p>"},{"location":"Portal%20features/#settings","title":"Settings","text":"<p>These settings can be accessed by clicking the \"Settings\" link in the main menu (left navigation in the Portal):</p> <ul> <li>User Management</li> <li>Configuration Manager</li> <li>Firewall</li> <li>Notification Channels\u00a0for delivery of monitoring alerts by email</li> <li>Policies\u00a0for monitoring alerts</li> </ul>"},{"location":"Portal%20features/#notifications","title":"Notifications","text":"<p>Actions performed through the Portal will generate a notification.</p> <p>To view current notifications, click the bell icon in the upper-right corner of the interface.</p> <p>See \"Notifications\" for additional details.</p>"},{"location":"Portal%20features/#user-preferences","title":"User Preferences","text":"<p>To customize your email notification preferences, click your name in the upper-right corner of the interface, then choose \"User preferences\".</p> <p>See \"Notifications\" for additional details.</p>"},{"location":"Portal%20features/#logout","title":"Logout","text":"<p>To log out from SkySQL, click your name in the upper-right corner of the interface, then choose \"Logout\" from the menu.</p>"},{"location":"Portal%20features/Billing/","title":"Billing","text":"<p>Billing is associated with a\u00a0SkySQL ID.</p> <p>For pricing information see \"Pricing\" .</p>"},{"location":"Portal%20features/Billing/#usage-information","title":"Usage Information","text":"<p>From the\u00a0Portal, you can access a current billing and usage summary:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Click your name in the upper-right corner of the interface, then select \"Billing\" from the menu.</li> <li>The \"Current Usage\" tab (the default) shows current billing and usage summary.</li> </ol> <p>Current charges, prior billing date, and next invoice date are shown.</p> <p>Usage information can be shown by service or by resource.</p> <p>Click the resource name or service name to expand the view.</p> <p></p> <p>Billing - Current Usage</p>"},{"location":"Portal%20features/Billing/#billing-history-invoices","title":"Billing History &amp; Invoices","text":"<p>From the\u00a0Portal, you can access prior invoices:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Click your name in the upper-right corner of the interface, then select \"Billing\" from the menu.</li> <li>Click the \"Billing History\" tab to show available invoices.</li> </ol>"},{"location":"Portal%20features/Infrastructure%20Upgrades/","title":"Infrastructure Upgrades","text":"<p>SkySQL runs on modern Kubernetes infrastructure across AWS, GCP, and Azure cloud providers. To maintain security, performance, and compliance with cloud provider requirements, periodic infrastructure upgrades are essential for all running services. Infrastructure upgrades are a critical component of maintaining a secure, performant, and compliant database service. By staying current with these upgrades, you ensure continued access to the latest features, security updates, and cloud provider support.</p>"},{"location":"Portal%20features/Infrastructure%20Upgrades/#understanding-infrastructure-vs-database-upgrades","title":"Understanding Infrastructure vs Database Upgrades","text":"<p>Infrastructure upgrades are different from database software upgrades:</p> <ul> <li>Infrastructure Upgrades: Update the underlying Kubernetes nodes, container runtime, and cloud provider components that host your database</li> <li>Database Upgrades: Update the MariaDB database software version itself</li> </ul>"},{"location":"Portal%20features/Infrastructure%20Upgrades/#service-impact-during-upgrades","title":"Service Impact During Upgrades","text":"<p>MariaDB Server with Replicas experience a brief service interruption while connections are cycled on the Load Balancer.</p> <p>MariaDB Server Single Node will experience a brief downtime during the database restart, typically lasting 2-5 minutes.</p> <p>Infrastructure upgrades ensure your service continues to receive: - Security patches and vulnerability fixes - Performance improvements and optimizations - Continued support from cloud providers (AWS, GCP, Azure) - Access to the latest cloud platform features</p>"},{"location":"Portal%20features/Infrastructure%20Upgrades/#why-infrastructure-upgrades-are-required","title":"Why Infrastructure Upgrades Are Required","text":""},{"location":"Portal%20features/Infrastructure%20Upgrades/#cloud-provider-requirements","title":"Cloud Provider Requirements","text":"<p>Our cloud providers (AWS, GCP, Azure) enforce strict upgrade schedules for Kubernetes infrastructure:</p> <ul> <li>Security Compliance: Outdated infrastructure versions may not receive critical security updates</li> <li>Support Limitations: Cloud providers eventually discontinue support for older infrastructure versions</li> </ul>"},{"location":"Portal%20features/Infrastructure%20Upgrades/#how-infrastructure-upgrades-work","title":"How Infrastructure Upgrades Work","text":""},{"location":"Portal%20features/Infrastructure%20Upgrades/#notification-timeline","title":"Notification Timeline","text":"<ol> <li>3 Months Prior to Automated Upgrade: SkySQL sends initial notification about upcoming infrastructure upgrade requirements</li> <li>Regular Reminders: Follow-up notifications are sent as the deadline approaches</li> <li>Grace Period: Customers have time to perform upgrades before the automatic deadline</li> <li>Automated Upgrade Deadline: If not upgraded by the deadline, SkySQL will automatically perform the upgrade to maintain compliance</li> </ol>"},{"location":"Portal%20features/Infrastructure%20Upgrades/#managing-infrastructure-upgrades-in-the-portal","title":"Managing Infrastructure Upgrades in the Portal","text":""},{"location":"Portal%20features/Infrastructure%20Upgrades/#viewing-available-upgrades","title":"Viewing Available Upgrades","text":"<ol> <li>Log in to the Portal.</li> <li>Any affected service will display an Upgrade Available or Upgrade Required notification.</li> <li>An upgrade deadline will be shown, indicating the last date to perform the upgrade before automatic enforcement.</li> </ol>"},{"location":"Portal%20features/Infrastructure%20Upgrades/#performing-an-upgrade","title":"Performing an Upgrade","text":"<ol> <li>Click Upgrade next to the available infrastructure update</li> <li>Review the upgrade details and impact</li> <li>Confirm to begin the immediate upgrade process</li> <li>Monitor the upgrade progress through the Portal</li> </ol> <p>Immediate Processing</p> <p>Infrastructure upgrades begin immediately when initiated and cannot be scheduled for a future time.</p>"},{"location":"Portal%20features/Infrastructure%20Upgrades/#upgrade-status-tracking","title":"Upgrade Status Tracking","text":"<p>Monitor your upgrade progress through: - Real-time status updates in the Portal - Email notifications at key milestones - Service monitoring panels showing restart progress</p>"},{"location":"Portal%20features/Infrastructure%20Upgrades/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>Q: Best time to upgrade A: Plan according to your maintenance windows.</p> <p>Q: Can I schedule an upgrade for later? A: No, infrastructure upgrades begin immediately when initiated. Plan to perform them during appropriate maintenance windows.</p> <p>Q: What happens if I don't upgrade by the deadline? A: SkySQL will automatically perform the upgrade to maintain cloud provider compliance and platform stability.</p> <p>Q: Will my data be affected during the upgrade? A: No, infrastructure upgrades only restart the database service. Your data remains intact and unchanged.</p> <p>Q: Can I opt out of infrastructure upgrades? A: No, infrastructure upgrades are mandatory to maintain security, compliance, and cloud provider support.</p>"},{"location":"Portal%20features/Launch%20page/","title":"Launch page","text":"<p>Launch page can be accessed at Launch</p> <p></p> <p>Launch Service</p> <p>While making launch-time selections, your selections and estimated costs are shown on the right panel.</p> <p>To launch a SkySQL service from the\u00a0Portal:</p> <ol> <li>From the Dashboard, click the <code>+ Launch New Service</code> button.</li> <li>Choose Service Type: <code>Transactions</code></li> <li>Choose the desired\u00a0Topology: <code>MariaDB Server Single Node</code> or <code>MariaDB Server With Replica(s)</code></li> <li>Choose the desired\u00a0Cloud Provider: <code>AWS</code>, <code>Google Cloud</code> or <code>Azure</code></li> <li>Choose the desired\u00a0Region.<ul> <li>Each region has a scheduled maintenance window.</li> </ul> </li> <li>Choose the desired\u00a0Instance Size.<ul> <li>If your workload requires a larger instance size, contact us regarding\u00a0Power Tier.</li> </ul> </li> <li>If needed, enable\u00a0Auto-Scaling of Nodes.</li> <li>Choose the desired\u00a0Storage Configuration.</li> <li>If needed, enable\u00a0Auto-Scaling of Storage.</li> <li>Choose number of nodes to deploy.</li> <li>Choose the desired\u00a0Server Version.</li> <li>Enter the desired Service Name between 4-24 characters.</li> <li>Enable topology-specific features, if desired:<ul> <li>Disable SSL/TLS</li> <li>NoSQL Interface</li> </ul> </li> </ol> <p>After initiating service launch, the service will be shown on the\u00a0Portal\u00a0Dashboard.</p> <p>A\u00a0notification\u00a0will be sent at time of service launch initiation and when service launch completes.</p>"},{"location":"Portal%20features/Manage%20your%20Service/","title":"Manage your Service","text":"<p>SkySQL's self-service management features enable authorized accounts to launch cloud databases, start and stop cloud databases, delete cloud databases, apply database configuration changes, and configure the cloud database's IP firewall.</p> <p>Self-service\u00a0user management\u00a0features enable you to define role-based access for your team to jointly manage SkySQL resources.</p>"},{"location":"Portal%20features/Manage%20your%20Service/#stop-a-service","title":"Stop a Service","text":"<p>Stop Service</p> <p>To stop a service:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Click the <code>MANAGE</code> button (at right) for the desired service.</li> <li>Choose the \"Stop Service\" menu item.</li> <li>Click the \"Yes, Stop this service\" button to confirm this operation.</li> </ol> <p>The service will be stopped. You will only be charged for storage on a stopped service.</p> <p>Notifications\u00a0will be generated when this operation is initiated and when the operation is performed.</p>"},{"location":"Portal%20features/Manage%20your%20Service/#start-a-service","title":"Start a Service","text":"<p>Start Service</p> <p>To start a service:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Click the \"MANAGE\" button (at right) for the desired service.</li> <li>Choose the \"Start Service\" menu item.</li> <li>Click the \"Yes, Start this service\" button to confirm this operation.</li> </ol> <p>The service will be started. Service start may take up to 10-15 minutes. The normal billing cycle for the service will resume.</p> <p>Notifications\u00a0will be generated when this operation is initiated and when the operation is performed.</p>"},{"location":"Portal%20features/Manage%20your%20Service/#scale-nodes-inout","title":"Scale Nodes In/Out","text":"<p>Service - Horizontal Scaling</p> <p>Horizontal scaling is performed by scaling nodes In (reducing node count) or Out (increasing node count).</p> <p>To scale nodes horizontally:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Identify the service you want to scale. Services must be in a \"Healthy\" state to scale.</li> <li>Click the \"MANAGE\" button (at right) for the desired service.</li> <li>Choose the \"Scale nodes in/out\" menu item.</li> <li>Change the node count to the desired value.</li> <li>Optionally, you can check the \"Auto-scale nodes horizontally\" checkbox to enable\u00a0Autonomous\u00a0features for this service.</li> <li>Click the \"Apply Changes\" button.</li> </ol> <p>The service immediately goes into scaling status.</p> <p>Notifications\u00a0will be generated when this operation is initiated and when the operation is performed.</p>"},{"location":"Portal%20features/Manage%20your%20Service/#scale-nodes-updown","title":"Scale Nodes Up/Down","text":"<p>Service - Vertical Scaling</p> <p>Vertical scaling is performed by scaling nodes Up (increasing node size) or Down (decreasing node size).</p> <p>To scale nodes vertically:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Identify the service you want to scale. Services must be in a \"Healthy\" state to scale.</li> <li>Click the \"MANAGE\" button (at right) for the desired service.</li> <li>Choose the \"Scale nodes up/down\" menu item.</li> <li>Change the node count to the desired value.</li> <li>Optionally, you can check the \"Auto-scale nodes vertically\" checkbox to enable\u00a0Autonomous\u00a0features for this service.</li> <li>Click the \"Apply Changes\" button.</li> </ol> <p>The service immediately goes into scaling status.</p> <p>Notifications\u00a0will be generated when this operation is initiated and when the operation is performed.</p>"},{"location":"Portal%20features/Manage%20your%20Service/#scale-storage","title":"Scale Storage","text":"<p>Service - Scale Storage</p> <p>To expand block storage capacity:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Identify the service you want to scale. Services must be in a \"Healthy\" state to scale.</li> <li>Click the \"MANAGE\" button (at right) for the desired service.</li> <li>Choose the \"Scale storage\" menu item.</li> <li>Use the slider to select the desired amount of storage.</li> <li>Click the \"Apply Changes\" button.</li> </ol> <p>Storage scaling is subject to a 6 hour cooldown period.</p> <p>Storage upgrades are not reversible.</p>"},{"location":"Portal%20features/Manage%20your%20Service/#delete-a-service","title":"Delete a Service","text":"<p>Service - Delete</p> <p>To delete a service:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Identify the service you want to delete.</li> <li>Click the \"MANAGE\" button (at right) for that service.</li> <li>Choose the \"Delete Service\" menu item.</li> <li>Read the warning and follow the provided instructions to confirm your delete operation.</li> <li>Click \"Yes, delete\".</li> </ol> <p>Your service and all its data will be deleted. This operation is non-reversible.</p> <p>Notifications\u00a0will be generated when this operation is initiated and when the operation is performed.</p>"},{"location":"Portal%20features/Manage%20your%20Service/#other-self-service-operations","title":"Other Self-Service Operations","text":"<ul> <li>Service Launch</li> <li>Firewall Management</li> <li>Configuration Management</li> <li>Private Connections:<ul> <li>AWS PrivateLink</li> <li>GCP Private Service Connect</li> </ul> </li> <li>User Management</li> </ul>"},{"location":"Portal%20features/Notifications/","title":"Notifications","text":"<p>Actions performed through the Portal will generate a notification.</p> <p>One notification is generated when an action is initiated.</p> <p>Additional notifications are generated to convey status as the action is carried out by the system.</p>"},{"location":"Portal%20features/Notifications/#access-to-notifications","title":"Access to Notifications","text":"<p>To access current notifications:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Click the bell icon in the upper-right corner of the interface.</li> </ol> <p>A menu of recent notifications will be displayed.</p> <p>The bell icon will include a red dot indicator when a new notification is present. This indicator can be cleared by clicking the \"Clear all\" link.</p> <p></p> <p>Notifications</p> <p>To view historical notifications, click the \"View more\" link at the bottom of the menu. When viewing historical notifications, notifications can be filtered by category and time frame.</p> <p></p> <p>Notifications - current and historical</p>"},{"location":"Portal%20features/Notifications/#notification-categories","title":"Notification Categories","text":"<ul> <li>Service Alerts, which are based on\u00a0<code>Alerts</code></li> <li>Billing</li> <li>Service, which are based on\u00a0Portal\u00a0actions</li> <li>Organization</li> </ul>"},{"location":"Portal%20features/Notifications/#user-preferences","title":"User Preferences","text":"<p>You can configure the notifications delivered to your email address from User Preferences.</p> <p>To access User Preferences:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Click your name in the upper-right corner of the interface.</li> <li>Choose <code>Profile</code>.</li> <li>Click to expand <code>Notification preferences</code> section.</li> </ol> <p>From User Preferences you can specify your notification preferences:</p> <ul> <li>Whether to send notifications to you by email</li> <li>Which Notification Categories you want to be sent</li> </ul> <p></p> <p>User Preferences</p>"},{"location":"Portal%20features/Notifications/#notification-channels","title":"Notification Channels","text":"<p>In addition to display in the Portal, notifications can also be delivered by email.</p> <p>Notification Channels define who receives what type of notifications.</p> <p>To access Notification Channel settings:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Click the \"Settings\" link in the main menu (left navigation in the Portal).</li> <li>Click the \"Notification Channel\" button.</li> </ol> <p></p> <p>Notification Channels</p>"},{"location":"Portal%20features/Notifications/#add-a-notification-channel","title":"Add a Notification Channel","text":"<p>To add a Notification Channel, from the Notification Channel settings interface:</p> <ol> <li>Click the \"Add\" button in the upper-right corner.</li> <li>Enter a channel name.</li> <li>Enter the email address that will receive notifications.</li> <li>Choose the notification categories that should be sent to that address.</li> </ol> <p></p> <p>Notification Channels - Adding a Channel</p>"},{"location":"Portal%20features/Notifications/#remove-a-notification-channel","title":"Remove a Notification Channel","text":"<p>To remove a Notification Channel, from the Notification Channel settings interface:</p> <ol> <li>Check the checkbox to the left of the notification channel to be removed.</li> <li>Click the \"Delete\" button (which appears when a notification channel is selected by checkbox).</li> <li>Confirm removal of the notification channel by clicking the \"Yes, delete\" button.</li> </ol>"},{"location":"Portal%20features/Notifications/#edit-a-notification-channel","title":"Edit a Notification Channel","text":"<p>To modify a Notification Channel, from the Notification Channel settings interface:</p> <ol> <li>Click the name of the channel to modify.</li> <li>Make the desired changes to the channel name, email address recipient list, and notification categories.</li> <li>Click the \"Save\" button.</li> </ol>"},{"location":"Portal%20features/Service%20Details%20page/","title":"Service Details page","text":"<p>After\u00a0service launch, a detailed summary of the service can be accessed in the Service Details interface.</p>"},{"location":"Portal%20features/Service%20Details%20page/#access-to-service-details","title":"Access to Service Details","text":"<ol> <li>Log in to the\u00a0Portal.</li> <li>From the Dashboard, click the name of the desired service.</li> <li>Click the \"Details\" tab.</li> </ol> <p>Service Details</p>"},{"location":"Portal%20features/Service%20Details%20page/#available-information","title":"Available Information","text":"<p>Service details vary based on topology.</p> <p>Service details may include:</p> <ul> <li>Hardware architecture</li> <li>Instance size</li> <li>Software version</li> <li>Timestamp of service launch</li> <li>Storage capacity</li> <li>Count of replicas</li> <li>Read-only TCP port</li> <li>Read-write TCP port</li> <li>NoSQL interface TCP port</li> <li>IP address used for outbound traffic</li> <li>Auto-scaling settings for nodes</li> <li>Auto-scaling settings for storage</li> <li>Fully Qualified Domain Name (hostname)</li> <li>Configuration settings applied to the service</li> <li>Current charges and hourly costs</li> <li>Scheduled maintenance window</li> </ul>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/","title":"Service Monitoring Panels","text":"<p>The available panels are :</p> <p> Monitoring page</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#current-sql-commands-service","title":"Current SQL Commands (service)","text":"<p>This panel shows the ratio between the types of SQL statements executed by the service during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#cpu-load-servicestatus","title":"CPU Load (service,status)","text":"<p>This panel shows the CPU usage for each server node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#qps-servicestatus","title":"QPS (service,status)","text":"<p>This panel shows the queries per second (QPS) executed by the server node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#connections-service","title":"Connections (service)","text":"<p>This panel shows the number of used and aborted connections for each ES node along with the max_connections value.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#replicas-status","title":"Replicas status","text":"<p>This panel shows summarized values for certain replication-related metadata to help determine if any replica ES nodes encountered replication issues during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#replicas-lags","title":"Replicas lags","text":"<p>This panel shows average values for certain replication-related metadata to help determine if the replica ES nodes are currently lagging behind the primary ES node.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#disk-size-of-data","title":"Disk Size of Data","text":"<p>This panel shows the amount of storage space used (as the usage percentage, actual size, and total size) by each server node.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#disk-size-of-logs","title":"Disk Size of Logs","text":"<p>This panel shows the amount of storage space used by each server node during the selected time interval.</p> <p></p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#gtid-replication-position-servicereplicas","title":"GTID Replication Position (service,replicas)","text":"<p>This panel shows the Global Transaction ID (GTID) for each ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#seconds-behind-primary","title":"Seconds Behind Primary","text":"<p>This panel shows the average number of seconds that the replica ES nodes lagged behind the primary ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#exec-primary-log-position","title":"Exec Primary Log Position","text":"<p>This panel shows the current binary log position of the replica SQL thread for each ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#read-primary-log-position","title":"Read Primary Log Position","text":"<p>This panel shows the current binary log position of the replica I/O thread for each ES node during the selected time interval.</p> <p></p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#top-command-counters-servicequeries","title":"Top Command Counters (service,queries)","text":"<p>This panel shows the top 30 statement types that were most frequently executed by all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#top-command-counters-server","title":"Top Command Counters (server)","text":"<p>This panel shows the top 30 statement types that were most frequently executed by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#top-command-counters-hourly-service","title":"Top Command Counters Hourly (service)","text":"<p>This panel shows the top 30 statement types that were most frequently executed by all ES and Xpand nodes in 1 hour intervals over the past 24 hours.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#top-command-counters-hourly-server","title":"Top Command Counters Hourly (server)","text":"<p>This panel shows the top 30 statement types that were most frequently executed by the ES node in 1 hour intervals over the past 24 hours.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-qps","title":"MariaDB QPS","text":"<p>This panel shows the number of queries per second (QPS) executed by all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-slow-queries-servicequeries","title":"MariaDB Slow Queries (service,queries)","text":"<p>This panel shows the number of slow queries executed by all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-slow-queries-server","title":"MariaDB Slow Queries (server)","text":"<p>This panel shows the number of slow queries executed by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-qps-and-questions","title":"MariaDB QPS and Questions","text":"<p>This panel shows the number of queries and questions per second executed by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-client-thread-activity-service","title":"MariaDB Client Thread Activity (service)","text":"<p>This panel shows the number of client threads running on all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-client-thread-activity-server","title":"MariaDB Client Thread Activity (server)","text":"<p>This panel shows the number of client threads connected and running on the ES node during the selected time interval.</p> <p></p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#maxscale-service-connections","title":"MaxScale Service Connections","text":"<p>This panel shows the number of clients connected to all MaxScale nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#maxscale-server-connections","title":"MaxScale Server Connections","text":"<p>This panel shows the number of client connections open between the MaxScale node and each ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-service-connections","title":"MariaDB Service Connections","text":"<p>This panel shows the number of clients connected to the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-aborted-connections","title":"MariaDB Aborted Connections","text":"<p>This panel shows the number of connections aborted by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-table-locks-service","title":"MariaDB Table Locks (service)","text":"<p>This panel shows the number of table locks requested by all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-table-locks-server","title":"MariaDB Table Locks (server)","text":"<p>This panel shows the number of table locks requested by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-open-tables-service","title":"MariaDB Open Tables (service)","text":"<p>This panel shows the number of tables opened by the database servers on all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-open-tables-server","title":"MariaDB Open Tables (server)","text":"<p>This panel shows the number of tables opened by the database server on the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-table-opened","title":"MariaDB Table Opened","text":"<p>This panel shows the number of tables that have been opened by all ES nodes during the selected time interval.</p> <p></p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#cpu-load","title":"CPU Load","text":"<p>This panel shows the CPU usage for each server node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#memory-usage","title":"Memory Usage","text":"<p>This panel shows memory usage details for all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#io-activity-page-in","title":"I/O Activity - Page In","text":"<p>This panel shows the total number of bytes read from the ES node's file system during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#io-activity-page-out","title":"I/O Activity - Page Out","text":"<p>This panel shows the total number of bytes written to the ES node's file system during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#io-activity-serversystem","title":"I/O Activity (server,system)","text":"<p>This panel shows the total number of bytes written to or read from the ES node's file system during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#iops","title":"IOPS","text":"<p>This panel shows the number of input/output operations per second performed by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#iops-page-in","title":"IOPS - Page In","text":"<p>This panel shows the total number of reads performed from the ES node's file system during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#iops-page-out","title":"IOPS - Page Out","text":"<p>This panel shows the total number of writes performed from the ES node's file system during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#network-traffic-inbound","title":"Network Traffic - Inbound","text":"<p>This panel shows the amount of data received over the network by the operating systems on all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#network-traffic-outbound","title":"Network Traffic - Outbound","text":"<p>This panel shows the amount of data sent over the network by the operating systems on all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-network-traffic-service","title":"MariaDB Network Traffic (service)","text":"<p>This panel shows the amount of data sent and received over the network by the database servers on all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-network-traffic-server","title":"MariaDB Network Traffic (server)","text":"<p>This panel shows the amount of data sent and received over the network by the database server on the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#network-traffic-serverstatus","title":"Network Traffic (server,status)","text":"<p>This panel shows the amount of data sent and received over the network by the operating system on the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-network-usage-hourly-service","title":"MariaDB Network Usage Hourly (service)","text":"<p>This panel shows the amount of data sent and received over the network per hour by the database servers on all ES nodes over the past 24 hours.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-network-usage-hourly-server","title":"MariaDB Network Usage Hourly (server)","text":"<p>This panel shows the amount of data sent and received over the network per hour by the database server on the ES node over the past 24 hours.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#network-errors-service","title":"Network Errors (service)","text":"<p>This panel shows the number of network errors encountered by all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#network-errors-server","title":"Network Errors (server)","text":"<p>This panel shows the number of network errors encountered by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#network-packets-dropped-service","title":"Network Packets Dropped (service)","text":"<p>This panel shows the number of network packets dropped by all ES nodes during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#network-packets-dropped-server","title":"Network Packets Dropped (server)","text":"<p>This panel shows the number of network packets dropped by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#cpu-serverstatusgauge","title":"CPU (server,status,gauge)","text":"<p>This panel shows the current CPU usage for the ES or Xpand node.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#ram-serverstatus","title":"RAM (server,status)","text":"<p>This panel shows the current memory usage details for the ES or Xpand node.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#ram-serverstatusgraph","title":"RAM (server,status,graph)","text":"<p>This panel shows memory usage details for the ES or Xpand node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#buffer-pool-size-of-total-ram","title":"Buffer Pool Size of Total RAM","text":"<p>This panel shows the current size of the InnoDB buffer pool for the ES node in two units: the absolute size and the percentage of the server's usable memory.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#used-connections","title":"Used Connections","text":"<p>This panel shows the current number of client connections as a percentage of the ES node's max_connections value.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#innodb-data-sec-serverstatus","title":"InnoDB Data / sec (server,status)","text":"<p>This panel shows the number of bytes per second read and written by InnoDB during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#rows-sec","title":"Rows / sec","text":"<p>This panel shows the total number of rows written and read per second by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-connections","title":"MariaDB Connections","text":"<p>This panel shows the number of client connections to the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-opened-files-sec","title":"MariaDB Opened Files / sec","text":"<p>This panel shows the number of files opened per second by the database server on the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-open-files","title":"MariaDB Open Files","text":"<p>This panel shows the number of files opened by the database server on the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-transaction-handlers-sec","title":"MariaDB Transaction Handlers / sec","text":"<p>This panel shows the number of transaction-related handlers created by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#temporary-objects-created","title":"Temporary Objects Created","text":"<p>This panel shows the number of temporary tables created by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-thread-cache","title":"MariaDB Thread Cache","text":"<p>This panel shows the number of threads created and cached for re-use on the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-table-open-cache-status","title":"MariaDB Table Open Cache Status","text":"<p>This panel shows the activity of the table open cache on the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-table-definition-cache","title":"MariaDB Table Definition Cache","text":"<p>This panel shows how many table definitions were cached by the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#memory-distribution","title":"Memory Distribution","text":"<p>This panel shows memory usage details for the ES node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#mariadb-memory-overview","title":"MariaDB Memory Overview","text":"<p>This panel shows how much memory the ES node used for the InnoDB buffer pool, InnoDB log buffer, MyISAM key buffer, and query cache during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#memory-serverperformance","title":"Memory (server,performance)","text":"<p>This panel shows memory usage details for the MaxScale node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#rwsec-servercluster","title":"RW/sec (server,cluster)","text":"<p>This panel shows the number of read and write operations per second that were handled by the threads on the MaxScale node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#threads","title":"Threads","text":"<p>This panel shows the number of threads currently used by the MaxScale node.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#maxscale-modules","title":"MaxScale Modules","text":"<p>This panel lists the modules installed on the MaxScale node.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#maxscale-hangups-serverperformance","title":"MaxScale Hangups (server,performance)","text":"<p>This panel shows the number of client connections closed by the MaxScale node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#errors-serverperformance","title":"Errors (server,performance)","text":"<p>This panel shows the number of errors encountered by threads on the MaxScale node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#event-queue-length-serverperformance","title":"Event Queue Length (server,performance)","text":"<p>This panel shows the total event queue length for all threads on the MaxScale node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#maxscale-descriptors-servercluster","title":"MaxScale Descriptors (server,cluster)","text":"<p>This panel shows the number of descriptors used by the MaxScale node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#max-time-in-queue-servercluster","title":"Max Time in Queue (server,cluster)","text":"<p>This panel shows the longest time the MaxScale node waited for an I/O event during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#maxscale-connections","title":"MaxScale Connections","text":"<p>This panel shows the number of clients connected to the MaxScale node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#database-server-connections","title":"Database Server Connections","text":"<p>This panel shows the number of database server connections open between the MaxScale node and each ES or Xpand node during the selected time interval.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#resident-servercluster","title":"Resident (server,cluster)","text":"<p>This panel shows the current resident set size (RSS) of the MaxScale process.</p>"},{"location":"Portal%20features/Service%20Monitoring%20Panels/#stack-size-servercluster","title":"Stack size (server,cluster)","text":"<p>This panel shows the current stack size of the MaxScale node.</p>"},{"location":"Quickstart/","title":"Quickstart","text":"<p>The SkySQL database deployment time varies based on your preferences: a Serverless standalone instance can be ready in a few seconds, whereas a Provisioned standalone or clustered database may take a few minutes. Users can select from approximately 50 global regions and deploy on either AWS, GCP and Azure.</p> <p>You have three choices to provision a DB on SkySQL :</p> <p>This Quickstart explains how to launch database services and manage the lifecycle of database services using the\u00a0Portal\u00a0in a web browser.</p> <p>For users who prefer other interfaces, SkySQL offers the following alternatives:</p> <ul> <li>Use the SkySQL web Portal. Make your choices with a few clicks and hit Launch.</li> <li>Use the\u00a0DBaaS API\u00a0with a REST client</li> <li>Use the\u00a0Terraform provider</li> </ul>"},{"location":"Quickstart/#step-1-register-for-skysql","title":"Step 1: Register for SkySQL","text":"<p>Goto app.skysql.com to sign up. You can sign up using your Google, Github or LinkedIn credentials. Or, just use your Email address to sign up. </p> <p></p>"},{"location":"Quickstart/#step-2-launch-a-service","title":"Step 2: Launch a Service","text":"<ol> <li> <p>Log in to the SkySQL Portal\u00a0and from the Dashboard, click the + Launch New Service button.</p> </li> <li> <p>From the launch interface, select the choices detailed below.</p> </li> <li> <p>Choose between <code>Provisioned</code> or <code>Serverless</code>: Options include <code>MariaDB Server with Replicas</code>, <code>MariaDB Server Single Node</code>, or <code>MariaDB Serverless Single Node</code>.</p> </li> <li> <p>Select your cloud provider and region:</p> <ul> <li><code>AWS</code> with <code>Ohio, USA (us-east-2)</code></li> <li><code>Google Cloud</code> with <code>Iowa, USA (us-central1)</code></li> <li>Or choose a region of your preference.</li> </ul> </li> <li> <p>Service Naming: Name the service \"<code>quickstart-1</code>\" or retain the suggested service name.</p> </li> <li> <p>Click the <code>Launch Service</code> button.</p> <p></p> <p>For additional information on available selections, see \"Service Launch\".</p> </li> <li> <p>You will then be redirected to the Dashboard. If you choose a Serverless deployment, your service will be in a 'Healthy' state and ready for use. For other deployment types, the service will initially be in a 'Creating' state. Please wait until it transitions to a 'Healthy' state before proceeding to the next step. Typically, launching a new Provisioned database takes about 5 minutes or less.</p> </li> </ol>"},{"location":"Quickstart/#step-3-observe-scale","title":"Step 3: Observe, Scale","text":""},{"location":"Quickstart/#monitoring","title":"Monitoring","text":"<p>You can monitor all the important database and OS metrics from the dashboard. The monitoring UI also allows you to view,download any/all logs - error, info or Audit logs. </p> <p>Basic status is shown on the Dashboard.</p> <p>To see expanded status and metrics information:</p> <ol> <li>From the Dashboard, click on the service name. (This is \"quickstart-1\" if you used the suggested name.)</li> <li>From the Monitoring Dashboard, you can choose to view service (<code>Service Overview</code>) or server details from the navigation tabs.</li> <li> <p>Specific views are provided for different sets of metrics. These views can be accessed using the buttons in the upper-right corner. From the service overview, views include <code>Status</code>, <code>Lags</code>, <code>Queries</code>, <code>Database</code> and <code>System</code>.</p> <p></p> <p>Monitoring Dashboard</p> </li> </ol>"},{"location":"Quickstart/#scaling","title":"Scaling","text":"<p>SkySQL features automatic rule-based scaling (Autonomous) and manual on-demand scaling.</p> <p>Note: Scaling is not applicable to Serverless deployments.</p> <p>With automatic scaling, node count (horizontal) and node size (vertical) changes can be triggered based on load. Additionally, storage capacity expansion can be triggered based on usage. These Autonomous features are opt-in. For additional information, see \"Autonomous\".</p> <p></p> <p>Autonomous</p> <p>With manual scaling, you can perform horizontal scaling (In/Out), vertical scaling (Up/Down), and storage expansion on-demand using Self-Service Operations. For additional information, see \"Self-Service Operations\".</p> <p></p> <p>Self-Service Scaling of Nodes</p>"},{"location":"Quickstart/#step-4-tear-down","title":"Step 4: Tear-down","text":"<p>When you are done with your testing session, you can stop the service. When a service is stopped, storage charges continue to accrue, but compute charges pause until the service is started again.</p> <p>When you are done with testing, you can delete the service.</p> <p>Stopping, starting, and deleting a service are examples of Self-Service Operations that you can perform through the Portal.</p> <p>For additional information, see \"Self-Service Operations\".</p> <p>Launch DB using the REST API</p> <p>Launch DB using the Terraform Provider</p>"},{"location":"Quickstart/Launch%20DB%20using%20Python/","title":"Launch DB using Python","text":"<p> --&gt; Easy Launch on Google Colab</p> <p>The Python example below shows how to launch a DB service and connect to it using the SkySQL DBaaS API. </p> <p>You need to configure the following environment variables:     * <code>API_KEY</code>     * <code>SKYSQL_CLIENT_IP</code></p>"},{"location":"Quickstart/Launch%20DB%20using%20Python/#step-1-generate-api-key","title":"Step 1: Generate API Key","text":"<ol> <li> <p>Go to SkySQL API Key management page and generate an API key.</p> </li> <li> <p>Export the value from the token field to an environment variable API_KEY:</p> <pre><code>export API_KEY='... key data ...'\n</code></pre> <p>The\u00a0<code>API_KEY</code>\u00a0environment variable will be used in the subsequent steps.</p> </li> </ol> <p>Check any existing services: <pre><code> curl --request GET 'https://api.skysql.com/provisioning/v1/services' \\\n    --header \"X-API-Key: $API_KEY\"\n</code></pre></p>"},{"location":"Quickstart/Launch%20DB%20using%20Python/#step-2-determine-the-client-ip-address","title":"Step 2: Determine the Client IP Address","text":"<p>When your new service is created, your client can only connect through the service's firewall if the client IP address is in the service's IP allowlist.</p> <p>Before creating the new service, determine the public IP address of your client host and save it to the\u00a0<code>SKYSQL_CLIENT_IP</code>\u00a0environment variable.</p> <p>If you are not sure of your public IP address, you can use a lookup service, such as\u00a0<code>checkip.amazonaws.com</code>:</p> <pre><code>export SKYSQL_CLIENT_IP=`curl -sS checkip.amazonaws.com`\n</code></pre>"},{"location":"Quickstart/Launch%20DB%20using%20Python/#step-3-create-the-service-using-python","title":"Step 3: Create the Service using Python","text":"<p>The following Python script has been tested with Python 3.11</p> <pre><code>import os\nimport time\nimport requests\nimport json\nimport sys\nimport argparse\nimport mysql.connector\nfrom mysql.connector import Error\n\n# Set your API key and client IP\nAPI_KEY = os.getenv('API_KEY')\nCLIENT_IP = os.getenv('SKYSQL_CLIENT_IP')\n## Name of the service to be created\nSKYDB_SERVICE_NAME = 'my-first-skysql-db'\n\n# Headers for the API requests\nheaders = {\n    'Content-Type': 'application/json',\n    'X-API-Key': API_KEY\n}\n\n# Function to launch a SkySQL DB service\ndef launch_skysql_db():\n    url = \"https://api.skysql.com/provisioning/v1/services\"\n    payload = {\n        \"service_type\": \"transactional\",\n        \"topology\": \"es-single\",\n        \"provider\": \"gcp\",\n        \"region\": \"us-central1\",\n        \"architecture\": \"amd64\",\n        \"size\": \"sky-2x8\",\n        \"storage\": 100,\n        \"nodes\": 1,\n        \"name\": f\"{SKYDB_SERVICE_NAME}\",\n        \"ssl_enabled\": True,\n        \"allow_list\": [\n            {\n                \"comment\": \"Describe the IP address\",\n                \"ip\": f\"{CLIENT_IP}/32\"\n            }\n        ]\n    }\n    try:\n        response = requests.post(url, headers=headers, data=json.dumps(payload))\n        response.raise_for_status()\n        return response\n    except requests.exceptions.RequestException as e:\n        print(f\"Failed to launch SkySQL DB service: {e}\")\n        return None\n\n\n# Function to monitor the status of the service\ndef monitor_status(service_id):\n    url = f\"https://api.skysql.com/provisioning/v1/services/{service_id}\"\n    while True:\n        response = requests.get(url, headers=headers)\n        status = response.json().get('status')\n        if status == 'ready':\n            print(\"Service is ready.. \")\n            print(response.json())\n            return response.json()\n        print(\"Service launch started .. will wait for 30 secs and check again...\")\n        time.sleep(30)\n\n# Function to test the connection to the service\ndef test_connection(connection_properties):\n    try:\n        connection = mysql.connector.connect(\n            host=connection_properties['host'],\n            user=connection_properties['user'],\n            password=connection_properties['password'],\n        )\n        if connection.is_connected():\n            print(\"Connection successful\")\n            connection.close()\n    except Error as e:\n        print(f\"Error: {e}\")\n\n\n# Function to fetch security credentials for the service\ndef fetch_credentials(service_id):\n    url = f\"https://api.skysql.com/provisioning/v1/services/{service_id}/security/credentials\"\n    try:\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        return response.json()\n    except requests.exceptions.RequestException as e:\n        print(f\"Failed to fetch credentials: {e}\")\n        return None\n\n\n# Main function to execute the steps\ndef main():\n    # Step 0: Parse command-line arguments\n    parser = argparse.ArgumentParser(description=\"Launch SkySQL DB or use an existing service\")\n    parser.add_argument('--service_id', type=str, help=\"Optional service ID to skip launching a new service\")\n    args = parser.parse_args()\n\n    # Step 1: Either use the provided service_id or launch a new SkySQL DB\n    if args.service_id:\n        print(f\"Using provided service ID: {args.service_id}\")\n        service_id = args.service_id\n    else:\n        service_response = launch_skysql_db()\n\n        # Check if the response status code is within the 2xx range (success)\n        if not (200 &lt;= service_response.status_code &lt; 300):\n            print(\"Failed to launch SkySQL DB service\")\n            print(service_response.json())  # Print detailed error message\n            return\n\n        service_json = service_response.json()\n        service_id = service_json.get('id')\n\n        if not service_id:\n            print(\"Service launched, but could not retrieve service ID\")\n            return\n\n    # Step 2: Monitor the status until 'ready'\n    service_details = monitor_status(service_id)\n    if not service_details:\n        print(\"Service did not become ready\")\n        return\n\n    # Step 3: Obtain the connection properties (FQDN and port)\n    fqdn = service_details.get('fqdn')\n    ports = service_details['endpoints'][0]['ports']\n\n    # Find the port where name is 'readwrite'\n    readwrite_port = next((port['port'] for port in ports if port['name'] == 'readwrite'), None)\n\n    if not fqdn or not readwrite_port:\n        print(\"Failed to retrieve FQDN or port information.\")\n        return\n\n    # Step 4: Obtain the default credentials (username and password)\n    credentials = fetch_credentials(service_id)\n\n    if not credentials:\n        print(\"Failed to retrieve credentials\")\n        return\n\n    connection_properties = {\n        'host': fqdn,\n        'port': readwrite_port,\n        'user': credentials.get('username'),\n        'password': credentials.get('password'),\n    }\n\n    # Step 5: Test the connection to the DB\n    test_connection(connection_properties)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"Quickstart/Launch%20DB%20using%20the%20REST%20API/","title":"Launch DB using the REST API","text":"<p>This walkthrough explains how to launch database services and manage the lifecycle of database services using the SkySQL DBaaS REST API.</p>"},{"location":"Quickstart/Launch%20DB%20using%20the%20REST%20API/#launch-a-service","title":"Launch a Service","text":""},{"location":"Quickstart/Launch%20DB%20using%20the%20REST%20API/#step-1-generate-api-key","title":"Step 1: Generate API Key","text":"<ol> <li> <p>Go to SkySQL API Key management page and generate an API key</p> </li> <li> <p>Export the value from the token field to an environment variable $API_KEY</p> <pre><code>export API_KEY='... key data ...'\n</code></pre> <p>The\u00a0<code>API_KEY</code>\u00a0environment variable will be used in the subsequent steps.</p> </li> </ol> <p>Use it on subsequent request, e.g: <pre><code> curl --request GET 'https://api.skysql.com/provisioning/v1/services' \\\n    --header \"X-API-Key: $API_KEY\"\n</code></pre></p> <p>Note</p> <p>You can use the Swagger docs site we host we try out the API OR  Follow the instructions below to try the API using your command Shell    </p>"},{"location":"Quickstart/Launch%20DB%20using%20the%20REST%20API/#step-2-use-swagger-docs-to-try-out-the-apis","title":"Step 2: Use Swagger docs to try out the APIs","text":"<p>You can use the API Documentation here and directly try out the APIs in your browser. </p> <p>All you need is to click \u2018Authorize\u2019 and type in <code>&lt;supply your API key here&gt;</code></p> <p>Note</p> <p>** Pre-requisites for code below **</p> <p>The examples below use\u00a0curl\u00a0as the REST client.\u00a0curl\u00a0is available for Linux, macOS, and MS Windows. Of course, you can use any language client that supports invoking REST over HTTP. Examples below also use jq, a JSON parsing utility.\u00a0jq\u00a0is available for Linux, macOS, and MS Windows. Install jq then proceed.</p> <p>The examples also make use of\u00a0tee\u00a0to save the response JSON data to a file while also allowing it to be piped to\u00a0jq\u00a0for output. Both Linux and macOS support\u00a0tee\u00a0as described in the examples. On MS Windows, Powershell has a\u00a0tee\u00a0command that requires the\u00a0-filepath\u00a0option to be inserted prior to the filename.</p> <p>The\u00a0chmod\u00a0command is used to make a file private to the current user. If your environment doesn't support\u00a0chmod, you can set the file's permissions using other means.</p> <p>The examples also make use of exported variables and\u00a0${VARIABLE_NAME}\u00a0variable references that are compatible with Bourne-like shells (such as\u00a0sh,\u00a0bash, and\u00a0zsh). On MS Windows, you will need to adapt these instructions if you are not using a Bourne-like shell. For example, you can copy just the\u00a0jq\u00a0part of an export command (from inside the backticks), run that on its own, and then copy/paste the resulting string into a variable assignment for your shell.</p> <p>Finally, the examples use a backslash at the end of some of the lines to indicate to the shell that a command spans multiple lines. If your shell doesn't allow this, remove each trailing backslash character and join the following line to the end of the current line.</p>"},{"location":"Quickstart/Launch%20DB%20using%20the%20REST%20API/#step-2-determine-the-client-ip-address","title":"Step 2: Determine the Client IP Address","text":"<p>When your new service is created, your client can only connect through the service's firewall if the client IP address is in the service's IP allowlist.</p> <p>Before creating the new service, determine the public IP address of your client host and save it to the\u00a0<code>SKYSQL_CLIENT_IP</code>\u00a0environment variable.</p> <p>If you are not sure of your public IP address, you can use a lookup service, such as\u00a0<code>checkip.amazonaws.com</code>:</p> <pre><code>export SKYSQL_CLIENT_IP=`curl -sS checkip.amazonaws.com`\n</code></pre>"},{"location":"Quickstart/Launch%20DB%20using%20the%20REST%20API/#step-3-launch-a-service","title":"Step 3: Launch a Service","text":"<p>To launch a service:</p> <ol> <li>Prepare a request body containing the desired service options in a file called\u00a0<code>request-service.json</code>:</li> </ol> <pre><code>cat &gt; request-service.json &lt;&lt;EOF\n{\n  \"service_type\": \"transactional\",\n  \"topology\": \"es-single\",\n  \"provider\": \"gcp\",\n  \"region\": \"us-central1\",\n  \"architecture\": \"amd64\",\n  \"size\": \"sky-2x8\",\n  \"storage\": 100,\n  \"nodes\": 1,\n  \"name\": \"skysql-quickstart\",\n  \"ssl_enabled\": true,\n  \"allow_list\": [\n     {\n        \"comment\": \"Describe the IP address\",\n        \"ip\": \"${SKYSQL_CLIENT_IP}/32\"\n     }\n  ]\n}\nEOF\n</code></pre> <p>This configuration is suitable for a quick test, but a more customized configuration should be selected for performance testing or for alignment to the needs of production workloads:</p> <ul> <li>For\u00a0<code>service_type</code>, choose a\u00a0Service Type Selection</li> <li>For\u00a0<code>topology</code>, choose a\u00a0Topology Selection</li> <li>For\u00a0<code>provider</code>, choose a\u00a0Cloud Provider Selection\u00a0(<code>aws</code>,<code>gcp</code> or <code>azure</code>)</li> <li>For\u00a0<code>region</code>, choose a\u00a0Region Selection</li> <li>For\u00a0<code>architecture</code>, choose a\u00a0Hardware Architecture Selection</li> <li>For\u00a0<code>size</code>, choose an\u00a0Instance Size Selection</li> <li>For\u00a0<code>storage</code>, choose a\u00a0Transactional Storage Size Selection</li> <li>For\u00a0<code>nodes</code>, choose a node count</li> <li>For\u00a0<code>version</code>, choose the\u00a0Software Version Selection</li> <li>For\u00a0<code>name</code>, choose a name between 4-24 characters for the new service</li> <li> <p>For\u00a0<code>allow_list</code>, set the client IP address using CIDR notation, so that the client can connect through the\u00a0firewall</p> </li> <li> <p>Provide the request to the\u00a0<code>/provisioning/v1/services</code>\u00a0API endpoint\u00a0to create (launch) a new database service and save the response to the\u00a0<code>response-service.json</code>\u00a0file:</p> </li> </ul> <pre><code>curl -sS --location --request POST \\\n   --header \"X-API-Key: ${API_KEY}\" \\\n   --header \"Accept: application/json\" \\\n   --header \"Content-type: application/json\" \\\n   --data '@request-service.json' \\\n   https://api.skysql.com/provisioning/v1/services \\\n   | tee response-service.json | jq .\n</code></pre> <p>Upon success, the command will return JSON with details about the new service.</p> <ol> <li> <p>Read the service ID for the new service and save the value in the\u00a0<code>SKYSQL_SERVICE</code>\u00a0environment variable:</p> <pre><code>$ export SKYSQL_SERVICE=`jq -r .id response-service.json`\n</code></pre> </li> </ol>"},{"location":"Quickstart/Launch%20DB%20using%20the%20REST%20API/#step-4-check-service-state","title":"Step 4: Check Service State","text":"<p>Before advancing, check the service state using the\u00a0<code>/provisioning/v1/services/${SKYSQL_SERVICE}</code> API endpoint:</p> <pre><code>curl -sS --location --request GET \\\n   --header \"X-API-Key: ${API_KEY}\" \\\n   --header \"Accept: application/json\" \\\n   https://api.skysql.com/provisioning/v1/services/${SKYSQL_SERVICE} \\\n   | tee response-state.json | jq .status\n</code></pre> <p>When the service is still being launched, the JSON payload will contain\u00a0<code>\"pending_create\"</code>\u00a0or\u00a0<code>\"pending_modifying\"</code>\u00a0as the service status.</p> <p>When the service has been launched, the JSON payload contains\u00a0<code>\"ready\"</code>, and you can continue with the next steps. Keep in mind that some of the following values will not be populated in the JSON data until this ready status has been achieved.</p>"},{"location":"Quickstart/Launch%20DB%20using%20the%20REST%20API/#step-5-obtain-connection-details","title":"Step 5: Obtain Connection Details","text":"<p>Obtain the connection credentials for the new SkySQL service by executing the following commands:</p> <ol> <li> <p>Obtain the hostname and port of the service and save them to the\u00a0<code>SKYSQL_FQDN</code>\u00a0and\u00a0<code>SKYSQL_PORT</code>\u00a0environment variables:</p> <ul> <li> <p>The hostname is specified with the\u00a0<code>\"fqdn\"</code>\u00a0key.</p> <pre><code>export SKYSQL_FQDN=`jq -r .fqdn response-state.json`\n</code></pre> </li> <li> <p>Available TCP ports are specified in the\u00a0<code>\"endpoints\"</code>\u00a0array. For this test, connect to the\u00a0<code>\"port\"</code>\u00a0where\u00a0<code>\"name\"</code>\u00a0is\u00a0<code>\"readwrite\"</code>.</p> <pre><code>export SKYSQL_PORT=`jq '.endpoints[0].ports[] | select(.name==\"readwrite\") | .port' response-state.json`\n</code></pre> </li> </ul> </li> <li> <p>Obtain the default username and password for the service using the\u00a0<code>/provisioning/v1/services/${SKYSQL_SERVICE}/security/credentials</code> API endpoint\u00a0and save the response to the\u00a0<code>response-credentials.json</code>\u00a0file:</p> </li> </ol> <pre><code>curl -sS --location --request GET \\\n   --header \"X-API-Key: ${API_KEY}\" \\\n   --header \"Accept: application/json\" \\\n   --header \"Content-type: application/json\" \\\n   https://api.skysql.com/provisioning/v1/services/${SKYSQL_SERVICE}/security/credentials \\\n   | tee response-credentials.json | jq .\n</code></pre> <p>The default username and password will not be available until the service state is\u00a0<code>\"ready\"</code>.</p> <ol> <li> <p>Set the file's mode to only allow the current user to read its contents:</p> <pre><code>$ chmod 600 response-credentials.json\n</code></pre> </li> <li> <p>Read the username and password from\u00a0<code>response-credentials.json</code>\u00a0and save them to the\u00a0<code>SKYSQL_USERNAME</code>\u00a0and\u00a0<code>SKYSQL_PASSWORD</code>\u00a0environment variables:</p> <pre><code>$ export SKYSQL_USERNAME=`jq -r .username response-credentials.json`\n$ export SKYSQL_PASSWORD=`jq -r .password response-credentials.json`\n</code></pre> </li> </ol>"},{"location":"Quickstart/Launch%20DB%20using%20the%20REST%20API/#step-6-connect","title":"Step 6: Connect","text":"<p>Connect to the database using the host, port, and default credentials using the\u00a0mariadb\u00a0client:</p> <pre><code>mariadb --host ${SKYSQL_FQDN} --port ${SKYSQL_PORT} \\\n   --user ${SKYSQL_USERNAME} --password=\"${SKYSQL_PASSWORD}\" \\\n   --ssl-verify-server-cert \n</code></pre> <p>If you don't want the password to appear on the command-line, specify the\u00a0<code>--password</code>\u00a0command-line option\u00a0without an argument to be prompted for a password.</p>"},{"location":"Quickstart/Launch%20DB%20using%20the%20REST%20API/#step-7-save-connection-information-optional","title":"Step 7: Save Connection Information (Optional)","text":"<p>To connect to your SkySQL service easily, it is possible to create a\u00a0<code>.my.cnf</code>\u00a0file in your home directory that contains all the details of your connection.</p> <ol> <li>Use the following command to create a new\u00a0<code>.my.cnf</code>\u00a0file or overwrite an existing one and populates it with the connection information that was collected in the previous steps:</li> </ol> <pre><code>cat &gt; ~/.my.cnf &lt;&lt;EOF\n[client]\nhost=${SKYSQL_FQDN}\nport=${SKYSQL_PORT}\nuser=${SKYSQL_USERNAME}\npassword=\"${SKYSQL_PASSWORD}\"\nEOF\n</code></pre> <ol> <li> <p>Set the file system permissions for the\u00a0<code>.my.cnf</code>\u00a0file to ensure that other users can't read it:</p> <pre><code>$ chmod 600 ~/.my.cnf\n</code></pre> </li> <li> <p>When all the connection parameters are in your\u00a0<code>~/.my.cnf</code>\u00a0file, the\u00a0mariadb\u00a0client\u00a0can connect without specifying any command-line options:</p> <pre><code>$ mariadb\n</code></pre> </li> </ol>"},{"location":"Quickstart/Launch%20DB%20using%20the%20REST%20API/#resources","title":"Resources","text":"<ul> <li>API Documentation</li> <li>API Reference Documentation</li> </ul>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/","title":"Launch DB using the Terraform Provider","text":"<p>This walkthrough explains how to launch database services and manage the lifecycle of database services using the Terraform provider.</p> <p>For users who prefer other interfaces, SkySQL offers the following alternatives:</p> <ul> <li>Use the\u00a0Portal\u00a0in a web browser</li> <li>Use the\u00a0DBaaS API\u00a0with a REST client</li> </ul> <p>This walkthrough demonstrates a service configuration that is suitable for a quick test. A more customized configuration should be selected for performance testing or for alignment to the needs of production workloads.</p> <p>Note</p> <p>This procedure uses Terraform. HashiCorp officially supports Terraform on several Linux distributions, but HashiCorp also provides binaries for Microsoft Windows, macOS, and other operating systems.</p> <p>For a list of operating systems that are officially supported for Terraform, see \"HashiCorp Terraform Documentation: Supported Operating Systems\".</p> <p>For a list of operating systems that have binaries available for Terraform, see \"HashiCorp Terraform Documentation: Install Terraform\".</p>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#dependencies","title":"Dependencies","text":"<ul> <li>This procedure requires Terraform to be installed. For information about how to install Terraform, see \"HashiCorp Terraform Documentation: Install Terraform\".</li> <li>The examples in this procedure also use\u00a0<code>jq</code>, a JSON parsing utility.\u00a0jq\u00a0is available for Linux, macOS, and MS Windows. Install\u00a0<code>jq</code>\u00a0then proceed.</li> <li>The examples in this procedure also use\u00a0<code>curl</code>, a data transfer utility.\u00a0curl\u00a0is available for Linux, macOS, and MS Windows. Install\u00a0<code>curl</code>\u00a0then proceed.</li> <li>The examples in this procedure also use\u00a0<code>wget</code>, a file download utility.\u00a0GNU Wget\u00a0is available for Linux, macOS, and MS Windows. Install\u00a0<code>wget</code>\u00a0then proceed.</li> <li>The examples in this procedure also use exported environment variables that are compatible with Bourne-like shells (such as\u00a0<code>sh</code>,\u00a0<code>bash</code>, and\u00a0<code>zsh</code>).</li> </ul>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#launch-a-service","title":"Launch a Service","text":""},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-1-generate-api-key","title":"Step 1: Generate API Key","text":"<ol> <li>Go to the\u00a0Generate API Key\u00a0page.</li> <li>Fill out a name for the API key</li> <li>Click the \"Create\" button.</li> <li>Click the copy button to copy the API key.</li> <li>Store the API key somewhere safe as it is shown only once during the creation. The SkySQL platform does not store it anywhere.</li> </ol>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-2-create-terraform-project-directory","title":"Step 2: Create Terraform Project Directory","text":"<p>Create a directory for your Terraform project and change to the directory:</p> <pre><code>mkdir -p ~/skysql-nr-tf\ncd ~/skysql-nr-tf\n</code></pre>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-3-create-maintf","title":"Step 3: Create\u00a0<code>main.tf</code>","text":"<p>In the Terraform project directory, create a\u00a0<code>main.tf</code>\u00a0file that contains the following:</p> <ul> <li>Provider Requirements</li> <li>Provider Configuration</li> <li>Resources</li> <li>Data Sources</li> </ul> <pre><code># ---------------------\n# Provider Requirements\n# ---------------------\n# TF Documentation: https://developer.hashicorp.com/terraform/language/providers/requirements\n\nterraform {\n  required_providers {\n    skysql = {\n      source          = \"registry.terraform.io/skysqlinc/skysql\"\n    }\n  }\n}\n\n# ----------------------\n# Provider Configuration\n# ----------------------\n# TF Documentation: https://developer.hashicorp.com/terraform/language/providers/configuration\n\nprovider \"skysql\" {\n   access_token       = var.api_key\n}\n\n# ---------\n# Resources\n# ---------\n# TF Documentation: https://developer.hashicorp.com/terraform/language/resources/syntax\n\n# Create a service\nresource \"skysql_service\" \"default\" {\n  service_type        = var.service_type\n  topology            = var.topology\n  cloud_provider      = var.cloud_provider\n  region              = var.region\n  availability_zone   = coalesce(var.availability_zones, data.skysql_availability_zones.default.zones[0].name)\n  architecture        = var.architecture\n  size                = var.size\n  storage             = var.storage\n  nodes               = var.nodes\n  version             = coalesce(var.sw_version, data.skysql_versions.default.versions[0].name)\n  name                = var.name\n  ssl_enabled         = var.ssl_enabled\n  deletion_protection = var.deletion_protection\n  wait_for_creation   = true\n  wait_for_deletion   = true\n  wait_for_update     = true\n  is_active           = true\n  allow_list          = [\n     {\n        \"ip\"          : var.ip_address,\n        \"comment\"     : var.ip_address_comment\n     }\n  ]\n}\n\n# ------------\n# Data Sources\n# ------------\n# TF Documentation: https://developer.hashicorp.com/terraform/language/data-sources\n\n# Retrieve the list of projects. Projects are a way to group services.\ndata \"skysql_projects\" \"default\" {}\n\n# Retrieve the list of available versions for a specific topology\ndata \"skysql_versions\" \"default\" {\n  topology            = var.topology\n}\n\n# Retrieve the service details\ndata \"skysql_service\" \"default\" {\n  service_id          = skysql_service.default.id\n}\n\n# Retrieve the service default credentials.\n# When the service is created please change the default credentials\ndata \"skysql_credentials\" \"default\" {\n  service_id          = skysql_service.default.id\n}\n\ndata \"skysql_availability_zones\" \"default\" {\n  region              = var.region\n  filter_by_provider  = var.cloud_provider\n}\n</code></pre>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-4-create-outputstf","title":"Step 4: Create\u00a0<code>outputs.tf</code>","text":"<p>In the Terraform project directory, create an\u00a0<code>outputs.tf</code>\u00a0file that contains the\u00a0output values\u00a0used to display metadata about the SkySQL service:</p> <pre><code># -------------\n# Output Values\n# -------------\n# TF Documentation: https://developer.hashicorp.com/terraform/language/values/outputs\n\noutput \"skysql_projects\" {\n  value = data.skysql_projects.default\n}\n\n# Show the service details\noutput \"skysql_service\" {\n  value = data.skysql_service.default\n}\n\n# Show the service credentials\noutput \"skysql_credentials\" {\n  value     = data.skysql_credentials.default\n  sensitive = true\n}\n\n# Example how you can generate a command line for the database connection\noutput \"skysql_cmd\" {\n  value = \"mariadb --host ${data.skysql_service.default.fqdn} --port 3306 --user ${data.skysql_service.default.service_id} -p --ssl-verify-server-cert\"\n}\n\noutput \"availability_zones\" {\n  value = data.skysql_availability_zones.default\n}\n</code></pre>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-5-create-variablestf","title":"Step 5: Create\u00a0<code>variables.tf</code>","text":"<p>In the Terraform project directory, create a\u00a0<code>variables.tf</code>\u00a0file that contains the\u00a0input variables\u00a0used to configure the SkySQL service:</p> <pre><code># ---------------\n# Input Variables\n# ---------------\n# TF Documentation: https://developer.hashicorp.com/terraform/language/values/variables\n\nvariable \"api_key\" {\n   type                 = string\n   sensitive            = true\n   description          = \"The SkySQL API Key generated at: https://app.skysql.com/user-profile/api-keys\"\n}\n\nvariable \"service_type\" {\n   type                 = string\n   default              = \"transactional\"\n   description          = \"Specify \\\"transactional\\\" or \\\"analytical\\\". For additional information, See https://apidocs.skysql.com/#/Offering/get_provisioning_v1_service_types\"\n}\n\nvariable \"topology\" {\n   type                 = string\n   default              = \"es-single\"\n   description          = \"Specify a topology. For additional information, see: https://apidocs.skysql.com/#/Offering/get_provisioning_v1_topologies\"\n}\n\nvariable \"cloud_provider\" {\n    type                 = string\n    default              = \"gcp\"\n    description          = \"Specify the cloud provider. For additional information, see: https://apidocs.skysql.com/#/Offering/get_provisioning_v1_providers\"\n}\n\nvariable \"region\" {\n   type                 = string\n   default              = \"us-central1\"\n   description          = \"Specify the region. For additional information, see: https://apidocs.skysql.com/#/Offering/get_provisioning_v1_regions\"\n}\n\nvariable \"availability_zone\" {\n   type                 = string\n   default              = null\n   description          = \"Specify the availability zone for the cloud provider and region. For additional information, see: https://apidocs.skysql.com/#/Offering/get_provisioning_v1_providers__provider_name__zones\"\n}\n\nvariable \"architecture\" {\n   type                 = string\n   default              = \"amd64\"\n   description          = \"Specify a hardware architecture. For additional information, see: https://apidocs.skysql.com/#/CPU-Architectures/get_provisioning_v1_cpu_architectures\"\n}\n\nvariable \"size\" {\n   type                 = string\n   default              = \"sky-2x8\"\n   description          = \"Specify the database node instance size. For additional information, see: https://apidocs.skysql.com/#/Offering/get_provisioning_v1_sizes\"\n}\n\nvariable \"storage\" {\n   type                 = number\n   default              = 100\n   description          = \"Specify a transactional storage size. For additional information, see: https://apidocs.skysql.com/#/Offering/get_provisioning_v1_topologies__topology_name__storage_sizes\"\n}\n\nvariable \"nodes\" {\n   type                 = number\n   default              = 1\n   description          = \"Specify a node count. For additional information, see: https://apidocs.skysql.com/#/Offering/get_provisioning_v1_topologies__topology_name__nodes\"\n}\n\nvariable \"sw_version\" {\n   type                 = string\n   default              = null\n   description          = \"Specify a software version. For additional information, see: https://apidocs.skysql.com/#/Offering/get_provisioning_v1_versions\"\n}\n\nvariable \"name\" {\n   type                 = string\n   default              = \"skysql-quickstart\"\n   description          = \"Specify a name for the service 4-24 characters in length.\"\n}\n\nvariable \"ssl_enabled\" {\n   type                 = bool\n   default              = true\n   description          = \"Specify whether TLS should be enabled for the service.\"\n}\n\nvariable \"deletion_protection\" {\n   type                 = bool\n   default              = true\n   description          = \"Specify whether the service can be deleted via Terraform (false) or whether trying to do so raises an error (true)\"\n}\n\nvariable \"ip_address\" {\n   type                 = string\n   description          = \"Specify an IP address in CIDR format to add to the service's IP allowlist.\"\n}\n\nvariable \"ip_address_comment\" {\n   type                 = string\n   description          = \"Specify a comment describing the IP address.\"\n}\n</code></pre> <p>The variables are configured in the next step.</p>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-6-configure-service-in-a-tfvars-file","title":"Step 6: Configure Service in a\u00a0<code>.tfvars</code>\u00a0File","text":"<p>A\u00a0<code>.tfvars</code>\u00a0file\u00a0can be used to configure the service using the input variables.</p> <p>For example:</p> <pre><code>api_key             = \"... key data ...\"\nservice_type        = \"transactional\"\ntopology            = \"es-single\"\ncloud_provider      = \"gcp\"\nregion              = \"us-central1\"\navailability_zone   = null\narchitecture        = \"amd64\"\nsize                = \"sky-2x8\"\nstorage             = 100\nnodes               = 1\nsw_version          = null\nname                = \"skysql-nr-quickstart\"\nssl_enabled         = true\ndeletion_protection = true\nip_address          = \"192.0.2.10/32\"\nip_address_comment  = \"Describe the IP address\"\n</code></pre> <p>The input variables should be customized for your own needs:</p> <ul> <li>For\u00a0<code>api_key</code>, set it to the API key previously created in \"Step 1: Generate API Key\"</li> <li>For\u00a0<code>service_type</code>, choose a\u00a0Service Type Selection</li> <li>For\u00a0<code>topology</code>, choose a\u00a0Topology Selection</li> <li>For\u00a0<code>cloud_provider</code>, choose a\u00a0Cloud Provider Selection</li> <li>For\u00a0<code>region</code>, choose a\u00a0Region Selection</li> <li>For\u00a0<code>availability_zone</code>, choose a\u00a0Availability Zone Selection\u00a0or leave it\u00a0<code>null</code>\u00a0to use the default availability zone for the cloud provider and region</li> <li>For\u00a0<code>architecture</code>, choose a\u00a0Hardware Architecture Selection</li> <li>For\u00a0<code>size</code>, choose an\u00a0Instance Size Selection</li> <li>For\u00a0<code>storage</code>, choose a\u00a0Transactional Storage Size Selection</li> <li>For\u00a0<code>nodes</code>, choose a node count</li> <li>For\u00a0<code>sw_version</code>, choose the\u00a0Software Version Selection\u00a0or leave it\u00a0<code>null</code>\u00a0to use the default version for the topology</li> <li>For\u00a0<code>name</code>, choose a\u00a0name between 4-24 characters\u00a0for the new service</li> <li>For\u00a0<code>deletion_protection</code>, choose whether the service can be deleted via Terraform (<code>false</code>) or whether trying to do so raises an error (<code>true</code>)</li> <li>For\u00a0<code>ip_address</code>, choose an IP address to allow through the\u00a0firewall</li> <li>For\u00a0<code>ip_address_comment</code>, provide a description for the IP address</li> </ul> <p>The following steps assume that the file is called\u00a0<code>skysql-nr-quickstart.tfvars</code>.</p>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-7-run-terraform-init","title":"Step 7: Run\u00a0<code>terraform\u00a0init</code>","text":"<p>Initialize the Terraform project directory and download the Terraform provider from the\u00a0Terraform Registry\u00a0by executing the\u00a0<code>terraform\u00a0init</code>\u00a0command:</p> <pre><code>terraform init\n</code></pre> <p>If you need to download the provider manually, see \"Manually Install Provider from Binary Distribution\".</p>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-8-run-terraform-plan","title":"Step 8: Run\u00a0<code>terraform\u00a0plan</code>","text":"<p>Create a Terraform execution plan by executing the\u00a0<code>terraform\u00a0plan</code>\u00a0command\u00a0and specifying the path to the\u00a0<code>.tfvars</code>\u00a0file:</p> <pre><code>terraform plan -var-file=\"skysql-nr-quickstart.tfvars\"\n</code></pre>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-9-run-terraform-apply","title":"Step 9: Run\u00a0<code>terraform\u00a0apply</code>","text":"<p>Execute the Terraform execution plan and create the SkySQL service by executing the\u00a0<code>terraform\u00a0apply</code>\u00a0command\u00a0and specifying the path to the\u00a0<code>.tfvars</code>\u00a0file:</p> <pre><code>terraform apply -var-file=\"skysql-nr-quickstart.tfvars\"\n</code></pre> <p>Terraform prints the plan from the previous step again and prompts the user to confirm that the plan should be applied:</p> <pre><code>Do you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only 'yes' will be accepted to approve.\n\n  Enter a value: yes\n</code></pre> <p>Then Terraform creates the objects and prints status messages:</p> <pre><code>skysql_service.default: Creating...\nskysql_service.default: Still creating... [10s elapsed]\nskysql_service.default: Still creating... [20s elapsed]\nskysql_service.default: Still creating... [30s elapsed]\nskysql_service.default: Still creating... [40s elapsed]\nskysql_service.default: Still creating... [50s elapsed]\nskysql_service.default: Still creating... [1m0s elapsed]\nskysql_service.default: Still creating... [1m10s elapsed]\nskysql_service.default: Still creating... [1m20s elapsed]\nskysql_service.default: Still creating... [1m30s elapsed]\nskysql_service.default: Still creating... [1m40s elapsed]\nskysql_service.default: Still creating... [1m50s elapsed]\nskysql_service.default: Still creating... [2m0s elapsed]\nskysql_service.default: Still creating... [2m10s elapsed]\nskysql_service.default: Still creating... [2m20s elapsed]\nskysql_service.default: Still creating... [2m30s elapsed]\nskysql_service.default: Still creating... [2m40s elapsed]\nskysql_service.default: Still creating... [2m50s elapsed]\nskysql_service.default: Still creating... [3m0s elapsed]\nskysql_service.default: Still creating... [3m10s elapsed]\nskysql_service.default: Still creating... [3m20s elapsed]\nskysql_service.default: Still creating... [3m30s elapsed]\nskysql_service.default: Creation complete after 3m40s [id=dbpgf00000001]\ndata.skysql_credentials.default: Reading...\ndata.skysql_service.default: Reading...\ndata.skysql_service.default: Read complete after 0s [name=skysql-nr-quickstart]\ndata.skysql_credentials.default: Read complete after 0s\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n</code></pre> <p>Then Terraform prints the outputs.</p>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-10-obtain-connection-credentials","title":"Step 10: Obtain Connection Credentials","text":"<p>Obtain the connection credentials for the new SkySQL service by executing the following commands:</p> <ol> <li>Obtain the connection command from the\u00a0<code>terraform.tfstate</code>\u00a0file:</li> </ol> <pre><code> jq \".outputs.skysql_cmd\" terraform.tfstate\n</code></pre> <pre><code>mariadb --host dbpgf00000001.sysp0000.db.skysql.net --port 3306 \\\n   --user dbpgf00000001 -p --ssl-verify-server-cert\n</code></pre> <ol> <li>Obtain the user password from the\u00a0<code>terraform.tfstate</code>\u00a0file:</li> </ol> <pre><code>jq \".outputs.skysql_credentials.value.password\" terraform.tfstate \\\n      \"..password string..\"\n</code></pre>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-11-connect","title":"Step 11: Connect","text":"<p>Connect to the SkySQL service by executing the connection command from the previous step:</p> <pre><code>mariadb --host dbpgf00000001.sysp0000.db.skysql.net --port 3306 \\\n   --user dbpgf00000001 -p --ssl-verify-server-cert\n</code></pre> <p>When prompted, type the password and press enter to connect:</p> <pre><code>Enter password:\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 11691\nServer version: 10.11.6-MariaDB-log MariaDB Server\n\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nMariaDB [(none)]&gt;\n</code></pre>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#step-12-run-terraform-destroy","title":"Step 12: Run\u00a0<code>terraform\u00a0destroy</code>","text":"<p>Delete the service by executing the\u00a0<code>terraform\u00a0destroy</code>\u00a0command\u00a0and specifying the path to the\u00a0<code>.tfvars</code>\u00a0file:</p> <pre><code>terraform destroy -var-file=\"skysql-nr-quickstart.tfvars\"\n</code></pre> <p>Terraform prints the plan to delete the service and prompts the user to confirm that the plan should be applied:</p> <pre><code>Do you really want to destroy all resources?\nTerraform will destroy all your managed infrastructure, as shown above.\nThere is no undo. Only 'yes' will be accepted to confirm.\n\nEnter a value: yes\n</code></pre> <p>If deletion protection is enabled for the resources, the operation raises an error:</p> <pre><code>\u2502 Error: Can not delete service\n\u2502\n\u2502 Deletion protection is enabled\n\u2575\n</code></pre> <p>If deletion protection is not enabled for the resources, Terraform deletes the resources and prints status messages:</p> <pre><code>skysql_service.default: Destroying... [id=dbpgf00000001]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 10s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 20s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 30s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 40s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 50s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 1m0s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 1m10s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 1m20s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 1m30s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 1m40s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 1m50s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 2m0s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 2m10s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 2m20s elapsed]\nskysql_service.default: Still destroying... [id=dbpgf00000001, 2m30s elapsed]\nskysql_service.default: Destruction complete after 2m38s\n\nDestroy complete! Resources: 1 destroyed.\n</code></pre>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#manually-install-provider-from-binary-distribution","title":"Manually Install Provider from Binary Distribution","text":"<p>The SkySQL New Release Terraform provider can be downloaded from the\u00a0GitHub releases page\u00a0as a binary distribution and manually installed.</p>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#manually-install-provider-on-linux","title":"Manually Install Provider on Linux","text":"<p>With\u00a0Linux, manually install the provider on the target system by performing the following steps in the same Bash terminal:</p> <ol> <li> <p>Set some environment variables to configure your provider version, OS, and architecture:</p> <pre><code>export TF_PROVIDER_RELEASE=3.0.0\nexport TF_PROVIDER_OS=linux\nexport TF_PROVIDER_ARCH=amd64\n</code></pre> <p>For\u00a0<code>TF_PROVIDER_ARCH</code>, the following architectures are supported on Linux:</p> <ul> <li><code>386</code></li> <li><code>amd64</code></li> <li><code>arm</code></li> <li><code>arm64</code></li> <li>Download the provider from GitHub using\u00a0<code>wget</code>:</li> </ul> <pre><code>wget -q https://github.com/skysqlinc/terraform-provider-skysql/releases/download/v3.0.0/terraform-provider-skysql_3.0.0_linux_amd64.zip\n</code></pre> </li> <li> <p>Create a Terraform plugin directory:</p> <pre><code>mkdir -p ~/.terraform.d/plugins/registry.terraform.io/skysqlinc/skysql\n</code></pre> </li> <li> <p>Move the provider's binary distribution to the Terraform plugin directory:</p> <pre><code>mv terraform-provider-skysql_${TF_PROVIDER_RELEASE}_${TF_PROVIDER_OS}_${TF_PROVIDER_ARCH}.zip ~/.terraform.d/plugins/registry.terraform.io/skysqlinc/skysql/\n</code></pre> </li> <li> <p>Verify that the provider's binary distribution is present in the Terraform plugin directory:</p> <pre><code>ls -l ~/.terraform.d/plugins/registry.terraform.io/skysqlinc/skysql/\n</code></pre> </li> </ol>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#manually-install-provider-on-macos","title":"Manually Install Provider on macOS","text":"<p>With\u00a0macOS, manually install the provider on the target system by performing the following steps in the same macOS Terminal:</p> <ol> <li> <p>If\u00a0Homebrew\u00a0is not installed, install it:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre> </li> <li> <p>Install\u00a0<code>wget</code>\u00a0using Homebrew:</p> <pre><code>brew install wget\n</code></pre> </li> <li> <p>Set some environment variables to configure your provider version, OS, and architecture:</p> <pre><code>export TF_PROVIDER_RELEASE=1.1.0\nexport TF_PROVIDER_OS=darwin\nexport TF_PROVIDER_ARCH=arm64\n</code></pre> <p>For\u00a0<code>TF_PROVIDER_ARCH</code>, the following architectures are supported on macOS:   - <code>amd64</code>   - <code>arm64</code></p> </li> <li> <p>Download the provider from GitHub using\u00a0<code>wget</code>:</p> <pre><code>wget -q https://github.com/skysqlinc/terraform-provider-skysql/releases/download/v3.0.0/terraform-provider-skysql_3.0.0_darwin_arm64.zip\n</code></pre> </li> <li> <p>Create a Terraform plugin directory:</p> <pre><code>mkdir -p ~/.terraform.d/plugins/registry.terraform.io/skysqlinc/skysql\n</code></pre> </li> <li> <p>Move the provider's binary distribution to the Terraform plugin directory:</p> <pre><code>mv terraform-provider-skysql_${TF_PROVIDER_RELEASE}_${TF_PROVIDER_OS}_${TF_PROVIDER_ARCH}.zip ~/.terraform.d/plugins/registry.terraform.io/skysqlinc/skysql/\n</code></pre> </li> <li> <p>Verify that the provider's binary distribution is present in the Terraform plugin directory:</p> <pre><code>ls -l ~/.terraform.d/plugins/registry.terraform.io/skysqlinc/skysql/\n</code></pre> </li> </ol>"},{"location":"Quickstart/Launch%20DB%20using%20the%20Terraform%20Provider/#resources","title":"Resources","text":"<ul> <li>GitHub Project</li> <li>Example Terraform Configuration Files</li> <li>Terraform Registry</li> <li>API Documentation</li> <li>API Reference Documentation</li> </ul>"},{"location":"Reference%20Guide/","title":"Reference Guides","text":""},{"location":"Reference%20Guide/#skysql-rest-api-guide","title":"SkySQL REST API Guide","text":""},{"location":"Reference%20Guide/#configurable-mariadb-server-variables","title":"Configurable MariaDB Server variables:","text":"<ul> <li> <p>MariaDB Server Single Node</p> </li> <li> <p>MariaDB Server With Replica(s)</p> </li> <li> <p>SkySQL Intelligent Proxy Configuration</p> </li> </ul>"},{"location":"Reference%20Guide/#skysql-supported-instance-sizes","title":"SkySQL supported Instance sizes","text":""},{"location":"Reference%20Guide/#skysql-supported-cloud-regions","title":"SkySQL supported Cloud regions","text":""},{"location":"Reference%20Guide/#skysql-supported-backup-types","title":"SkySQL supported Backup types","text":""},{"location":"Reference%20Guide/#sky-stored-procedures","title":"Sky Stored Procedures","text":""},{"location":"Reference%20Guide/#skysql-monitoring-metrics-reference","title":"SkySQL Monitoring Metrics Reference","text":""},{"location":"Reference%20Guide/#mariadb-server-reference-guide","title":"MariaDB Server Reference Guide","text":""},{"location":"Reference%20Guide/#maxscale-reference-guide","title":"MaxScale Reference Guide","text":""},{"location":"Reference%20Guide/#setting-up-mariadb-server-colstore-maxscale-in-your-env","title":"Setting up MariaDB Server, ColStore, MaxScale in your Env","text":""},{"location":"Reference%20Guide/Backup%20Support/","title":"SkySQL Supported Backup Types","text":""},{"location":"Reference%20Guide/Backup%20Support/#mariadb-server-versions-and-backup-support","title":"MariaDB Server Versions and Backup Support","text":"Server Version Full Backup Incremental Backup Dump(mariadb-dump) Backup Snapshot Backup 11.4.x \u2713 \u2713 \u2713 \u2713 10.11.x \u2713 \u2713 \u2713 \u2713 10.6.x \u2713 \u2713 \u2713 \u2713 10.5.x \u2713 \u2713 \u2713 \u2713 11.6.2 (Vector Preview) \u2717 \u2717 \u2717 \u2713 11.7.1 (Release Candidate) \u2717 \u2717 \u2717 \u2713"},{"location":"Reference%20Guide/Backup%20Support/#notes","title":"Notes:","text":"<ul> <li>Versions 11.6.2 and 11.7.1 support only snapshot backups</li> <li>All other versions support all backup types: Full, Incremental, Dump, and Snapshot</li> </ul> <p>Please contact us if you have any questions about backup support for specific MariaDB versions. </p>"},{"location":"Reference%20Guide/Instance%20Size%20Choices/","title":"SkySQL Instance Sizes","text":""},{"location":"Reference%20Guide/Instance%20Size%20Choices/#serverless-instance-sizes","title":"Serverless Instance Sizes","text":"<p>SkySQL users are not required to specify any instance sizes when launching a serverless database.  The Serverless deployment continuously estimates workload requirements and dynamically resizes the database instance to the appropriate size to ensure optimal workload execution.</p> <p>During the \"Tech Preview\" phase, all Serverless instances will utilize between 1 and 2 SCUs (Sky Compute Units) during script execution time. Each SCU is equivalent to 0.5 vCPU and 2GB of memory.</p>"},{"location":"Reference%20Guide/Instance%20Size%20Choices/#provisioned-instances-size-choices","title":"Provisioned Instances Size Choices","text":"<p>Instance size choices are specific to the\u00a0cloud provider,\u00a0topology,\u00a0region, and\u00a0hardware architecture.</p>  \ud83d\udca1 the list below provides available sizes as of Sept 2024. Likely to evolve over time. The SkySQL portal is the best place for accurate information."},{"location":"Reference%20Guide/Instance%20Size%20Choices/#mariadb-server","title":"MariaDB Server","text":"<p>For Foundation tier:</p> Instance Size Cloud Provider CPU Memory sky-2x4 aws 2 vCPU 4 GB sky-2x8 aws, gcp, azure 2 vCPU 8 GB sky-4x16 aws, gcp, azure 4 vCPU 16 GB sky-4x32 aws, gcp, azure 4 vCPU 32 GB sky-8x32 aws, gcp, azure 8 vCPU 32 GB sky-8x64 aws, gcp, azure 8 vCPU 64 GB sky-16x64 aws, gcp, azure 16 vCPU 64 GB sky-16x128 aws, gcp, azure 16 vCPU 128 GB <p>For Power tier:</p> Instance Size Cloud Provider CPU Memory sky-2x4 aws 2 vCPU 4 GB sky-2x8 aws, gcp, azure 2 vCPU 8 GB sky-4x16 aws, gcp, azure 4 vCPU 16 GB sky-4x32 aws, gcp, azure 4 vCPU 32 GB sky-8x32 aws, gcp, azure 8 vCPU 32 GB sky-8x64 aws, gcp, azure 8 vCPU 64 GB sky-16x64 aws, gcp, azure 16 vCPU 64 GB sky-16x128 aws, gcp, azure 16 vCPU 128 GB sky-32x128 aws, gcp, azure 32 vCPU 128 GB sky-32x256 aws, gcp, azure 32 vCPU 256 GB sky-64x256 aws, gcp, azure 64 vCPU 256 GB sky-64x512 aws, gcp, azure 64 vCPU 512 GB sky-96x384 aws 96 vCPU 384 GB sky-96x768 aws 96 vCPU 768 GB sky-128x512 aws 128 vCPU 512 GB sky-128x1024 aws 128 vCPU 1024 GB"},{"location":"Reference%20Guide/Instance%20Size%20Choices/#maxscale","title":"MaxScale","text":"<p>With Power tier, the following instance sizes can be selected for MaxScale nodes:</p> Instance Size Cloud Provider CPU Memory sky-2x4 aws 2 vCPU 4 GB sky-2x8 aws, gcp, azure 2 vCPU 8 GB sky-4x16 aws, gcp, azure 4 vCPU 16 GB sky-8x32 aws, gcp, azure 8 vCPU 32 GB sky-16x64 aws, gcp, azure 16 vCPU 64 GB sky-32x128 aws, gcp, azure 32 vCPU 128 GB sky-64x256 aws, gcp, azure 64 vCPU 256 GB"},{"location":"Reference%20Guide/Instance%20Size%20Choices/#rest-client","title":"REST Client","text":"<p>A REST client can use the SkySQL DBaaS API to query instance size selections and choose an instance size for a new service.</p>"},{"location":"Reference%20Guide/Instance%20Size%20Choices/#query-database-node-options-with-rest-client","title":"Query Database Node Options with REST Client","text":"<p>A REST client can query the SkySQL DBaaS API for the database node instance size selections for a specific cloud provider, architecture, and topology.</p> <p>To see the available database node instance sizes for a topology, use\u00a0<code>curl</code>\u00a0to call the\u00a0<code>/provisioning/v1/sizes</code>\u00a0API endpoint\u00a0with\u00a0<code>type=server</code>\u00a0set:</p> <pre><code>curl -sS --location \\\n   --header \"X-API-Key: ${API_KEY}\" \\\n   'https://api.skysql.com/provisioning/v1/sizes?architecture=amd64&amp;service_type=transactional&amp;provider=gcp&amp;topology=es-replica&amp;type=server' \\\n   | jq .\n</code></pre> <pre><code>[\n  {\n    \"id\": \"37629543-65d2-11ed-8da6-2228d0ae81af\",\n    \"name\": \"sky-2x8\",\n    \"display_name\": \"Sky-2x8\",\n    \"service_type\": \"transactional\",\n    \"provider\": \"gcp\",\n    \"tier\": \"foundation\",\n    \"architecture\": \"amd64\",\n    \"cpu\": \"2 vCPU\",\n    \"ram\": \"8 GB\",\n    \"type\": \"server\",\n    \"default_maxscale_size_name\": \"sky-2x8\",\n    \"updated_on\": \"2022-11-16T17:15:06Z\",\n    \"created_on\": \"2022-11-16T17:15:06Z\",\n    \"is_active\": true,\n    \"topology\": \"es-replica\"\n  },\n  {\n    \"id\": \"37629489-65d2-11ed-8da6-2228d0ae81af\",\n    \"name\": \"sky-4x16\",\n    \"display_name\": \"Sky-4x16\",\n    \"service_type\": \"transactional\",\n    \"provider\": \"gcp\",\n    \"tier\": \"foundation\",\n    \"architecture\": \"amd64\",\n    \"cpu\": \"4 vCPU\",\n    \"ram\": \"16 GB\",\n    \"type\": \"server\",\n    \"default_maxscale_size_name\": \"sky-2x8\",\n    \"updated_on\": \"2022-11-16T17:15:06Z\",\n    \"created_on\": \"2022-11-16T17:15:06Z\",\n    \"is_active\": true,\n    \"topology\": \"es-replica\"\n  },\n....\n\n]\n</code></pre>"},{"location":"Reference%20Guide/Instance%20Size%20Choices/#query-maxscale-node-options-with-rest-client","title":"Query MaxScale Node Options with REST Client","text":"<p>A REST client can query the SkySQL DBaaS API for the MaxScale node instance size selections for a specific cloud provider, architecture, and topology.</p> <p>To see the default MaxScale instance size for a topology, cloud, and architecture, use\u00a0<code>curl</code>\u00a0to call the\u00a0<code>/provisioning/v1/sizes</code>\u00a0API endpoint:</p> <pre><code>curl -sS --location \\\n   --header \"X-API-Key: ${API_KEY}\" \\\n   'https://api.skysql.com/provisioning/v1/sizes?provider=gcp&amp;architecture=amd64&amp;topology=es-replica' \\\n   | jq .\n</code></pre> <pre><code>[\n   {\n     \"id\": \"c0666ab8-4a3b-11ed-8853-b278760e6ab5\",\n     \"name\": \"sky-2x8\",\n     \"display_name\": \"Sky-2x8\",\n     \"service_type\": \"transactional\",\n     \"provider\": \"gcp\",\n     \"tier\": \"foundation\",\n     \"architecture\": \"amd64\",\n     \"cpu\": \"2 vCPU\",\n     \"ram\": \"8 GB\",\n     \"type\": \"server\",\n     \"default_maxscale_size_name\": \"sky-2x8\",\n     \"updated_on\": \"2022-10-12T14:40:00Z\",\n     \"created_on\": \"2022-10-12T14:40:00Z\",\n     \"is_active\": true,\n     \"topology\": \"es-replica\"\n   }\n]\n</code></pre> <p>The\u00a0<code>default_maxscale_size_name</code>\u00a0attribute shows the default MaxScale instance size.</p> <p>To see the available MaxScale node instance sizes for a topology, use\u00a0<code>curl</code>\u00a0to call the\u00a0<code>/provisioning/v1/sizes</code>\u00a0API endpoint\u00a0with\u00a0<code>type=proxy</code>\u00a0set:</p> <pre><code>curl -sS --location \\\n   --header \"X-API-Key: ${API_KEY}\" \\\n   'https://api.skysql.com/provisioning/v1/sizes?architecture=amd64&amp;service_type=transactional&amp;provider=gcp&amp;topology=es-replica&amp;type=proxy' \\\n   | jq .\n</code></pre> <p>The output can show different instance sizes, depending on whether your SkySQL account is Foundation tier or Power tier.</p>"},{"location":"Reference%20Guide/MariaDB%20Server%20Versions/","title":"MariaDB Server Versions Support","text":"Version Documentation Link 11.4.5 MariaDB 11.4 Documentation 10.11.11 MariaDB 10.11 Documentation 10.6.20 MariaDB 10.6 Documentation 10.5.25 MariaDB 10.5 Documentation 11.6.2 (Vector Preview) MariaDB 11.6 Documentation 11.7.1 (Release Candidate) MariaDB 11.7 Documentation"},{"location":"Reference%20Guide/MariaDB%20Server%20Versions/#notes","title":"Notes:","text":"<ul> <li>11.6.2 is a Vector Preview  release version</li> <li>11.7.1 is a Release Candidate release version</li> <li>All other MariaDB Server versions are stable releases</li> </ul> <p>For more information about specific features and capabilities of each version, please refer to the respective documentation links above. </p>"},{"location":"Reference%20Guide/Monitoring%20Metrics%20Reference/","title":"SkySQL Monitoring Metrics Reference","text":"Panel Name UI Tab Scope Panel Type Description Connections status service table This panel shows the number of used and aborted connections for each ES node along with the\u00a0max_connections\u00a0value CPU Load status service graph This panel shows the CPU usage for each ES node during the selected time interval Current SQL Commands status service pie-chart This panel shows the ratio between the types of SQL statements executed by the service during the selected time interval Disk Size of Data status service table \"This panel shows the amount of storage space used (as the usage percentage QPS status service graph This panel shows the queries per second (QPS) executed by the ES node during the selected time interval Replicas lags status service table This panel shows average values for certain replication-related metadata to help determine if the replica ES nodes are currently lagging behind the primary ES node Replicas status status service table This panel shows summarized values for certain replication-related metadata to help determine if any replica ES nodes encountered replication issues during the selected time interval GTID Replication Position lags service graph This panel shows the Global Transaction ID (GTID) for each ES node during the selected time interval Seconds Behind Primary lags service graph This panel shows the lag in seconds behind the primary in terms of the time of the transaction being replicated. Exec Primary Log Position lags service graph This panel shows the position up to which the primary has processed in the current primary binary log file. Read Primary Log Position lags service graph This panel shows the position up to which the I/O thread has read in the current primary binary log file. MariaDB Client Thread Activity queries service graph This panel shows the number of client threads running on all ES nodes during the selected time interval MariaDB QPS queries service graph This panel shows the number of queries per second (QPS) executed by all ES nodes during the selected time interval MariaDB Slow Queries queries service graph This panel shows the number of slow queries executed by all ES nodes during the selected time interval MariaDB Slow Queries queries service graph This panel shows the number of slow queries executed by all ES nodes during the selected time interval Top Command Counters queries service graph This panel shows the top 30 statement types that were most frequently executed by all ES nodes during the selected time interval Top Command Counters Hourly queries service graph This panel shows the top 30 statement types that were most frequently executed by all ES nodes in 1 hour intervals over the past 24 hours MariaDB Aborted Connections database service graph This panel shows the number of connections aborted by the ES node during the selected time interval MariaDB Open Tables database service graph This panel shows the number of tables opened by the database servers on all ES nodes during the selected time interval MariaDB Service Connections database service graph This panel shows the number of clients connected to the ES node during the selected time interval MariaDB Table Locks database service graph This panel shows the number of table locks requested by all ES nodes during the selected time interval MariaDB Table Opened database service graph This panel shows the number of tables that have been opened by all ES nodes during the selected time interval MaxScale Server Connections database service graph This panel shows the number of client connections open between the MaxScale node and each ES node during the selected time interval MaxScale Service Connections database service graph This panel shows the number of clients connected to all MaxScale nodes during the selected time interval CPU Load system service graph This panel shows the CPU usage for each ES node during the selected time interval Disk Size of Data system service graph This panel shows the amount of storage space used by all ES nodes during the selected time interval I/OActivity - Page In system service graph This panel shows the total number of bytes read from the ES node's file system during the selected time interval I/O Activity - Page Out system service graph This panel shows the total number of bytes written to the ES node's file system during the selected time interval IOPS - Page In system service graph This panel shows the total number of reads performed from the ES node's file system during the selected time interval IOPS - Page Out system service graph This panel shows the total number of writes performed from the ES node's file system during the selected time interval MariaDB Network Traffic system service graph This panel shows the amount of data sent and received over the network by the database servers on all ES nodes during the selected time interval MariaDB Network Usage Hourly system service graph This panel shows the amount of data sent and received over the network per hour by the database servers on all ES nodes over the past 24 hours Memory Usage system service graph This panel shows memory usage details for all ES nodes during the selected time interval Network Errors system service graph This panel shows the number of network errors encountered by all ES nodes during the selected time interval Network Packets Dropped system service graph This panel shows the number of network packets dropped by all ES nodes during the selected time interval Network Traffic - Inbound system service graph This panel shows the amount of data received over the network by the operating systems on all ES nodes during the selected time interval Network Traffic - Outbound system service graph This panel shows the amount of data sent over the network by the operating systems on all ES nodes during the selected time interval Aborted Connections status server singlestat This panel shows the number of aborted connections for the ES node during the selected time interval Buffer Pool Size of Total RAM status server pie-chart This panel shows the current size of the InnoDB buffer pool for the ES node in two units: the absolute size and the percentage of the server's usable memory Connections status server stat This panel shows the number of clients connected to the MaxScale node CPU Load status server gauge This panel shows the current CPU usage for the ES node CPU Usage / Load status server graph This panel shows the CPU usage for the ES node during the selected time interval QPS/ status server singlestat This panel shows the number of queries per second (QPS) processed by the ES node during the selected time interval Current SQL Commands status server pie-chart This panel shows the ratio between the types of SQL statements executed by the ES node during the selected time interval I/O Activity status server graph This panel shows the total number of bytes written to or read from the ES node's file system during the selected time interval InnoDB Data/sec status server graph This panel shows the number of bytes per second read and written by InnoDB during the selected time interval Max Connections status server graph This panel shows the highest number of clients that were concurrently connected to the MaxScale node during the selected time interval Max Connections status server stat This panel shows the highest number of clients that have ever been concurrently connected to the MaxScale node Max Time in Queue status server graph This panel shows the longest time the MaxScale node waited for an I/O event during the selected time interval Network Traffic status server graph This panel shows the amount of data sent and received over the network by the operating system on the ES node during the selected time interval Memory Usage status server gauge This panel shows the current memory usage details for the ES node Resident (RSS) memory status server gauge This panel shows the current resident set size (RSS) of the MaxScale process RO Service Connections status server singlestat This panel shows the number of clients currently connected to the MaxScale node's read-only listener Rows / sec status server graph This panel shows the total number of rows written and read per second by the ES node during the selected time interval RW Service Connections status server singlestat This panel shows the number of clients currently connected to the MaxScale node's read-write listener RW / sec status server graph This panel shows the number of read and write operations per second that were handled by the threads on the MaxScale node during the selected time interval Database Server Connections status server graph This panel shows the number of client connections open between the MaxScale node and each ES node during the selected time interval MaxScale Connections status server graph This panel shows the number of clients connected to the MaxScale node's listeners during the selected time interval Stack size status server gauge This panel shows the current stack size of the MaxScale node Threads status server singlestat This panel shows the number of threads currently used by the MaxScale node RW/sec status server graph This panel shows the total number of queries that were actively being executed by the MaxScale node during the selected time interval MaxScale Connections status server graph This panel shows the total number of connections created by the MaxScale node since the MaxScale node was started Used Connections status server pie-chart This panel shows the current number of client connections as a percentage of the ES node's\u00a0max_connections\u00a0value MariaDB Aborted Connections database server graph This panel shows the number of connections aborted by the ES node during the selected time interval MariaDB Client Thread Activity database server graph This panel shows the number of client threads connected and running on the ES node during the selected time interval MariaDB Connections database server graph This panel shows the number of client connections to the ES node during the selected time interval MariaDB Open Files database server graph This panel shows the number of files opened by the database server on the ES node during the selected time interval MariaDB Open Tables database server graph This panel shows the number of tables opened by the database server on the ES node during the selected time interval MariaDB Opened Files / sec database server graph This panel shows the number of files opened per second by the database server on the ES node during the selected time interval MariaDB Table Locks database server graph This panel shows the number of table locks requested by the ES node during the selected time interval Temporary Objects Created database server graph This panel shows the number of temporary tables created by the ES node during the selected time interval MariaDB Table Definition Cache caches server graph This panel shows how many table definitions were cached by the ES node during the selected time interval MariaDB Table Open Cache Status caches server graph This panel shows the activity of the table open cache on the ES node during the selected time interval MariaDB Thread Cache caches server graph This panel shows the number of threads created and cached for re-use on the ES node during the selected time interval MariaDB Handlers / sec queries server graph This panel shows how many internal query handlers per second have been created by the ES node during the selected time interval MariaDB QPS and Questions queries server graph This panel shows the number of queries and questions per second executed by the ES node during the selected time interval MariaDB Slow Queries queries server graph This panel shows the number of slow queries executed by the ES node during the selected time interval MariaDB Sorts queries server graph This panel shows the number of times the ES node has used certain algorithms to sort data during the selected time interval MariaDB Handlers / sec queries server graph This panel shows the number of transaction-related handlers created by the ES node during the selected time interval Top Command Counters queries server graph This panel shows the top 30 statement types that were most frequently executed by the ES node during the selected time interval Top Command Counters Hourly queries server graph This panel shows the top 30 statement types that were most frequently executed by the ES node in 1 hour intervals over the past 24 hours CPU Usage / Load system server graph This panel shows the CPU usage for the ES node during the selected time interval Disk Size of Data system server graph This panel shows the amount of storage space used by the ES node during the selected time interval Disk Size of Logs system server graph This panel shows the amount of storage space used by the server error logs during the selected time interval I/O Activity system server graph This panel shows the total number of bytes written to or read from the ES node's file system during the selected time interval InnoDB Data / sec system server graph This panel shows the number of bytes per second read and written by InnoDB during the selected time interval IOPS system server graph This panel shows the number of input/output operations per second performed by the ES node during the selected time interval MariaDB Memory Overview system server graph \"This panel shows how much memory the ES node used for the InnoDB buffer pool MariaDB Network Traffic system server graph This panel shows the amount of data sent and received over the network by the database server on the ES node during the selected time interval MariaDB Network Usage Hourly system server graph This panel shows the amount of data sent and received over the network per hour by the database server on the ES node over the past 24 hours Memory Distribution system server graph This panel shows memory usage details for the ES node during the selected time interval Network Errors system server graph This panel shows the number of network errors encountered by the ES node during the selected time interval Network Packets Dropped system server graph This panel shows the number of network packets dropped by the ES node during the selected time interval Network Traffic system server graph This panel shows the amount of data sent and received over the network by the operating system on the ES node during the selected time interval Errors performance server graph This panel shows the number of errors encountered by threads on the MaxScale node during the selected time interval MaxScale Descriptors performance server graph This panel shows the number of descriptors used by the MaxScale node during the selected time interval MaxScale Hangups performance server graph This panel shows the number of client connections closed by the MaxScale node during the selected time interval Memory Usage performance server graph This panel shows memory usage details for the MaxScale node during the selected time interval MaxScale Modules modules server table This panel lists the modules installed on the MaxScale node"},{"location":"Reference%20Guide/REST%20API%20Reference/","title":"SkySQL REST API Reference","text":"<p>The easiest way to get started with the API is to use this swagger Docs. Just generate your API key , Click <code>Authorize</code> and enter <code>&lt;yourAPI Key&gt;</code> and try out any of the APIs.</p> <p>You can use the REST API to Provision, get pricing and billing information, fetch/change service or MariaDB configuration, Manage users and their roles, schedule backups or restores, scale, stop and Delete services. </p> <p>Please refer to the API docs for examples and a complete list of all the APIs. </p> <p>The Backup Service API is available here</p>"},{"location":"Reference%20Guide/Region%20Choices/","title":"SkySQL Region Choices","text":""},{"location":"Reference%20Guide/Region%20Choices/#aws-regions","title":"AWS Regions","text":"Region Location Available Service Type ap-northeast-1 Tokyo, Japan Provisioned ap-northeast-2 Seoul, South Korea Provisioned ap-southeast-1 Jurong West, Singapore Provisioned ap-southeast-2 Sydney, Australia Provisioned ca-central-1 Montr\u00e9al, Qu\u00e9bec, Canada Provisioned eu-central-1 Frankfurt, Germany Provisioned eu-north-1 Stockholm, Sweden Provisioned eu-west-1 Dublin, Ireland Provisioned eu-west-2 London, England, UK Provisioned, Serverless eu-west-3 Paris, France Provisioned sa-east-1 S\u00e3o Paulo, Brazil Provisioned us-east-1 Northern Virginia, USA Provisioned us-east-2 Ohio, USA Provisioned, Serverless us-west-2 Oregon, USA Provisioned"},{"location":"Reference%20Guide/Region%20Choices/#gcp-regions","title":"GCP Regions","text":"Region Location Available Service Type asia-northeast1 Tokyo, Japan Provisioned asia-south1 Mumbai, India Provisioned asia-southeast1 Jurong West, Singapore Provisioned asia-southeast2 Jakarta, Indonesia Provisioned australia-southeast1 Sydney, Australia Provisioned europe-north1 Hamina, Finland Provisioned europe-west1 St. Ghislain, Belgium Provisioned europe-west2 London, England, UK Provisioned , Serverless europe-west3 Frankfurt, Germany Provisioned europe-west4 Eemshaven, Netherlands Provisioned europe-west9 Paris, France Provisioned northamerica-northeast1 Montr\u00e9al, Qu\u00e9bec, Canada Provisioned us-central1 Council Bluffs, Iowa, USA Provisioned, Serverless gcp-us-east1 Moncks Corner, South Carolina, USA Provisioned us-east4 Ashburn (Loudoun County), Virginia, USA Provisioned us-west1 The Dalles, Oregon, USA Provisioned us-west2 Los Angeles, California, USA Provisioned us-west4 Las Vegas, Nevada, USA Provisioned"},{"location":"Reference%20Guide/Region%20Choices/#azure-regions","title":"Azure Regions","text":"Region Location Available Service Type eastus Richmond, Virginia, USA Provisioned, Serverless eastus2 Virginia, USA Provisioned westus2 Seattle, Washington, USA Provisioned uksouth London, England, UK Provisioned francecentral Paris, France Provisioned northeurope Dublin, Ireland Provisioned, Serverless germanywestcentral Frankfurt, Germany Provisioned southeastasia Jurong West, Singapore Provisioned <p>Please\u00a0contact us\u00a0if any aspect of service does not align to your intended use case.</p>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/","title":"SkySQL Stored Procedures","text":""},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#change_external_primary","title":"change_external_primary","text":"<p>Executes the\u00a0CHANGE\u00a0MASTER\u00a0TO\u00a0statement to configure inbound replication from an external primary server based on binary log file and position.</p> <pre><code>CALL sky.change_external_primary(\n   host VARCHAR(255),\n   port INT,\n   logfile TEXT,\n   logpos LONG ,\n   use_ssl_encryption BOOLEAN\n);\n</code></pre> <pre><code>-- Run_this_grant_on_your_external_primary                                                                      |\nGRANT REPLICATION SLAVE ON *.* TO 'skysql_replication'@'%' IDENTIFIED BY '&lt;password_hash&gt;';                  |\n</code></pre>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#change_connect_retry","title":"change_connect_retry","text":"<p>Sets the connection retry interval for the external replication master.</p> <pre><code>CALL change_connect_retry(connect_retry INT);\n</code></pre> <p>If the value is NULL, a default retry interval of 60 seconds will be used.</p>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#change_external_primary_gtid","title":"change_external_primary_gtid","text":"<p>Executes the\u00a0CHANGE\u00a0MASTER\u00a0TO\u00a0statement to configure inbound replication from an external primary server based on the provided GTID.</p> <pre><code>CALL sky.change_external_primary_gtid(\n   host VARCHAR(255),\n   port INT,\n   gtid VARCHAR(60),\n   use_ssl_encryption BOOLEAN\n);\n</code></pre> <pre><code>-- Run_this_grant_on_your_external_primary\nGRANT REPLICATION SLAVE ON *.* TO 'skysql_replication'@'%' IDENTIFIED BY '&lt;password_hash&gt;';\n</code></pre>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#change_heartbeat_period","title":"change_heartbeat_period","text":"<p>Sets the heartbeat period for the external replication master.</p> <pre><code>CALL change_heartbeat_period(heartbeat_period DECIMAL(10,3));\n</code></pre> <p>If the value is NULL, a default heartbeat period of 5 seconds will be used.</p>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#change_replica_delay","title":"change_replica_delay","text":"<p>Sets the replication delay for the external replication master.</p> <pre><code>CALL change_replica_delay(replica_delay INT);\n</code></pre> <p>If the value is NULL, a default delay of 1 second will be used.</p>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#change_use_ssl_encryption","title":"change_use_ssl_encryption","text":"<p>Toggles the SSL encryption setting for the external replication master.</p> <pre><code>CALL change_use_ssl_encryption(use_ssl_encryption BOOLEAN);\n</code></pre> <p>If the value is NULL, SSL encryption will be enabled by default.</p>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#gtid_status","title":"gtid_status","text":"<p>Provides a list of GTID-related\u00a0system variables.</p> <pre><code>CALL sky.gtid_status();\n</code></pre> <pre><code>+-------------------+---------------------------+\n| Variable_name     | Value                     |\n+-------------------+---------------------------+\n| gtid_binlog_pos   | 435700-435700-122         |\n| gtid_binlog_state | 435700-435700-122         |\n| gtid_current_pos  | 0-100-1,435700-435700-122 |\n| gtid_slave_pos    | 0-100-1                   |\n+-------------------+---------------------------+\n</code></pre>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#kill_session","title":"kill_session","text":"<p>Kills any non-root or non-SkySQL threads, similar to the\u00a0KILL\u00a0statement.</p> <pre><code>CALL sky.kill_session(IN thread BIGINT);\n</code></pre>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#replication_grants","title":"replication_grants","text":"<p>Provides a\u00a0GRANT\u00a0statement to run on an external primary server when configuring inbound replication.</p> <pre><code>CALL sky.replication_grants();\n</code></pre> <pre><code>-- Run_this_grant_on_your_external_primary\nGRANT REPLICATION SLAVE ON *.* TO 'skysql_replication'@'%' IDENTIFIED BY '&lt;password_hash&gt;';\n</code></pre>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#replication_status","title":"replication_status","text":"<p>Executes the\u00a0SHOW\u00a0REPLICA\u00a0STATUS\u00a0statement to obtain the status of inbound replication.</p> <pre><code>CALL sky.replication_status()\\G\n</code></pre> <ul> <li> <pre><code>*************************** 1. row ***************************\n                Slave_IO_State: Waiting for master to send event\n                   Master_Host: mariadb1.example.com\n                   Master_User: skysql_replication\n                   Master_Port: 3306\n                 Connect_Retry: 60\n               Master_Log_File: mariadb-bin.000001\n           Read_Master_Log_Pos: 558\n                Relay_Log_File: mariadb-relay-bin.000002\n                 Relay_Log_Pos: 674\n         Relay_Master_Log_File: mariadb-bin.000001\n              Slave_IO_Running: Yes\n             Slave_SQL_Running: Yes\n               Replicate_Do_DB:\n           Replicate_Ignore_DB:\n            Replicate_Do_Table:\n        Replicate_Ignore_Table:\n       Replicate_Wild_Do_Table:\n   Replicate_Wild_Ignore_Table:\n                    Last_Errno: 0\n                    Last_Error:\n                  Skip_Counter: 0\n           Exec_Master_Log_Pos: 558\n               Relay_Log_Space: 985\n               Until_Condition: None\n                Until_Log_File:\n                 Until_Log_Pos: 0\n            Master_SSL_Allowed: No\n            Master_SSL_CA_File:\n            Master_SSL_CA_Path:\n               Master_SSL_Cert:\n             Master_SSL_Cipher:\n                Master_SSL_Key:\n         Seconds_Behind_Master: 0\n Master_SSL_Verify_Server_Cert: No\n                 Last_IO_Errno: 0\n                 Last_IO_Error:\n                Last_SQL_Errno: 0\n                Last_SQL_Error:\n   Replicate_Ignore_Server_Ids:\n              Master_Server_Id: 100\n                Master_SSL_Crl:\n            Master_SSL_Crlpath:\n                    Using_Gtid: Slave_Pos\n                   Gtid_IO_Pos: 0-100-1\n       Replicate_Do_Domain_Ids:\n   Replicate_Ignore_Domain_Ids:\n                 Parallel_Mode: conservative\n                     SQL_Delay: 0\n           SQL_Remaining_Delay: NULL\n       Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates\n              Slave_DDL_Groups: 0\nSlave_Non_Transactional_Groups: 0\n    Slave_Transactional_Groups: 0\n</code></pre> </li> </ul>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#reset_replication","title":"reset_replication","text":"<p>Executes the\u00a0RESET\u00a0REPLICA\u00a0statement to clear inbound replication configuration.</p> <pre><code>CALL sky.reset_replication();\n</code></pre> <pre><code>+------------------------+\n| Message                |\n+------------------------+\n| Replica has been reset |\n+------------------------+\n</code></pre>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#set_master_ssl","title":"set_master_ssl","text":"<p>Toggles the\u00a0<code>MASTER_SSL</code>\u00a0replication option using the\u00a0CHANGE\u00a0MASTER\u00a0TO\u00a0statement.</p> <pre><code>CALL sky.set_master_ssl();\n</code></pre>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#skip_repl_error","title":"skip_repl_error","text":"<p>This stored procedure can be used to ignore a transaction that is causing a replication error.</p> <p>Executes the\u00a0STOP\u00a0REPLICA\u00a0statement, then sets the\u00a0sql_slave_skip_counter\u00a0system variable, and then executes the\u00a0START\u00a0REPLICA\u00a0statement to skip a single transaction. Does not currently work with GTID.</p> <pre><code>CALL sky.skip_repl_error();\n</code></pre>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#start_replication","title":"start_replication","text":"<p>Executes the\u00a0START\u00a0REPLICA\u00a0statement to start inbound replication from an external primary.</p> <pre><code>CALL sky.start_replication();\n</code></pre> <pre><code>+----------------------------------------+\n| Message                                |\n+----------------------------------------+\n| External replication running normally. |\n+----------------------------------------+\n</code></pre>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#start_replication_until","title":"start_replication_until","text":"<p>Start the external replication until a specified relay log file and position. It checks if the replication threads are running and starts the replication if they are not. It also provides feedback on the replication status.</p> <pre><code>CALL start_replication_until(relay_log_file TEXT, relay_log_pos LONG);\n</code></pre>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#start_replication_until_gtid","title":"start_replication_until_gtid","text":"<p>Starts the external replication until the specified GTID position. It checks if the replication threads are running and starts the replication if they are not. It also provides feedback on the replication status.</p> <pre><code>CALL start_replication_until_gtid(master_gtid_pos TEXT);\n</code></pre>"},{"location":"Reference%20Guide/Sky%20Stored%20Procedures/#stop_replication","title":"stop_replication","text":"<p>Executes the\u00a0STOP\u00a0REPLICA\u00a0statement to stop inbound replication from an external primary.</p> <pre><code>CALL sky.stop_replication();\n</code></pre> <pre><code>+---------------------------------+\n| Message                         |\n+---------------------------------+\n| Replication is down or disabled |\n+---------------------------------+\n</code></pre>"},{"location":"Security/","title":"Security","text":"<p>SkySQL takes security very seriously and provides security at all levels - encryption on-the-wire, encrypted storage, guarded compute, multiple levels of authentication and Authorization. </p> <p>It complies with several security standards like SOC2, GDPR and ISO-27000. </p> <p>For details, see the specific topics listed below.</p> <p>Managing Portal Users</p> <p>Configuring Firewall</p> <p>Encryption</p> <p>Managing API keys</p> <p>Private VPC connections</p> <p>Portal Single Sign-On </p>"},{"location":"Security/Configuring%20Firewall/","title":"Configuring Firewall","text":"<p>SkySQL services are firewall-protected.</p> <p>Access to SkySQL services is managed on a per-service basis.</p> <p>IPv4 addresses and IPv4 netblocks can be added to the allowlist to enable service access. Access from other addresses will be blocked.</p>"},{"location":"Security/Configuring%20Firewall/#default","title":"Default","text":"<p>By default, when a service is launched its allowlist is empty. All external traffic to the service is blocked.</p>"},{"location":"Security/Configuring%20Firewall/#secure-access-configuration","title":"Secure Access Configuration","text":"<p>To modify Secure Access settings:</p> <ol> <li>Log in to the Portal.</li> <li>Click the \"Settings\" link in the main menu (left navigation in the Portal).</li> <li>Click the \"Secure Access\" button.</li> </ol> <p></p> <p>Secure Access Settings</p> <p>Alternatively, you can access firewall settings for a specific service by clicking on the \"MANAGE\" button for the desired service, then choose \"Manage allowlist\" from the menu.</p> <p></p> <p>Allowlist dialog</p>"},{"location":"Security/Configuring%20Firewall/#add-to-the-allowlist","title":"Add to the Allowlist","text":"<p>IP addresses can be added to the allowlist from the Firewall settings interface or a service's Security Access interface:</p> <ol> <li>Enter an IPv4 address or IPv4 netblock.</li> <li>Optionally enter an alias for this address. An alias provides a way to remember why an address was added to the allowlist.</li> <li>Click the \"Save\" button.</li> </ol> <p>After saving the change, a notification will be provided when the change has been applied.</p>"},{"location":"Security/Configuring%20Firewall/#remove-from-the-allowlist","title":"Remove from the Allowlist","text":"<p>IP addresses can be removed from the allowlist from the Firewall settings interface or a service's Security Access interface:</p> <ol> <li>Click the \"X\" button to the right of the entry to remove.</li> <li>Click the \"Save\" button.</li> </ol> <p>After saving the change, a notification will be provided when the change has been applied.</p>"},{"location":"Security/Configuring%20Firewall/#edit-an-allowlist-entry","title":"Edit an Allowlist Entry","text":"<p>An allowlist entry can be edited from the Firewall settings interface or a service's Security Access interface:</p> <ol> <li>Modify the IP address or alias of the desired allowlist entry.</li> <li>Click the \"Save\" button.</li> </ol> <p>After saving the change, a notification will be provided when the change has been applied.</p>"},{"location":"Security/Configuring%20Firewall/#ip-allowlist-limitations","title":"IP Allowlist Limitations","text":"<p>AWS/Azure Services: - Allowlists exceeding 30 IP addresses are not permitted.</p> <p>GCP Services: - Same workflow as AWS/Azure, but with a limit of 200 IP addresses.</p> <p>For allowlists requiring more than 30 IP addresses, please contact support@skysql.com.</p>"},{"location":"Security/Encryption/","title":"Encryption","text":""},{"location":"Security/Encryption/#data-in-transit-encryption","title":"Data-in-Transit Encryption","text":"<p>SkySQL features data-in-transit encryption by default.</p>"},{"location":"Security/Encryption/#client-to-server","title":"Client-to-Server","text":"<p>By default, SkySQL services feature data-in-transit encryption for client connections: -TLS 1.2 and TLS 1.3 are supported. SSL/TLS certificates and encryption settings are not customer-configurable.</p> <p>For information on how to connect with TLS, see \"Connect and Query\".</p> <p>The \"Disable SSL/TLS\" option may be appropriate for some customers when also using AWS PrivateLink or GCP VPC Peering.</p>"},{"location":"Security/Encryption/#server-to-server","title":"Server-to-Server","text":"<p>SkySQL services perform server-to-server communication between MariaDB MaxScale, MariaDB Server, and SkySQL infrastructure.</p> <p>By default, these server-to-server communications are protected with data-in-transit encryption:</p> <p>For SkySQL Services on AWS, see \"Encryption in transit(AWS)\". SkySQL uses configurations which feature automatic in-transit encryption.</p> <p>For SkySQL Services on GCP, see \"Encryption in transit (GCP)\". SkySQL uses encryption by default.</p> <p>For SkySQL Services on Azure, see \"Encryption in transit (Azure)\". SkySQL uses encryption by default.</p>"},{"location":"Security/Encryption/#data-at-rest-encryption","title":"Data-at-Rest Encryption","text":"<p>SkySQL features transparent data-at-rest encryption.</p> <p>SkySQL Services on AWS use Amazon EBS encryption.</p> <p>SkySQL Services on GCP benefits from encryption by default.</p> <p>SkySQL Services on Azure use Azure Disk Encryption.</p>"},{"location":"Security/Managing%20API%20keys/","title":"Managing API keys","text":""},{"location":"Security/Managing%20API%20keys/#getting-started-with-api-keys","title":"Getting Started with API Keys","text":"<ol> <li> <p>Go to SkySQL API Key management page: https://app.skysql.com/user-profile/api-keys and generate an API key</p> </li> <li> <p>Export the value from the token field to an environment variable $API_KEY</p> </li> <li> <p>Use it on subsequent request, e.g: <pre><code> curl --request GET 'https://api.skysql.com/provisioning/v1/services' \\\n --header \"X-API-Key: $API_KEY\"\n</code></pre></p> </li> </ol>"},{"location":"Security/Managing%20API%20keys/#managing-api-keys_1","title":"Managing API Keys","text":"<p>Use the Portal to create new, revoke or permanently delete these Keys.  </p> <p>OR</p> <p>You can use the swagger API portal to manage the keys.</p> <ol> <li> <p>Fetch all keys</p> </li> <li> <p>Create a new API Key</p> </li> <li> <p>Delete a user specific Key</p> </li> <li> <p>Update a user specific key </p> </li> </ol>"},{"location":"Security/Managing%20Portal%20Users/","title":"Managing Portal Users","text":"<p>By default, SkySQL services are launched and managed in the\u00a0Portal.</p> <p>For multiple SkySQL ID accounts to jointly manage a set of SkySQL services, these accounts can be added to a Team.</p> <p>The User Management interface in the\u00a0Portal\u00a0is a self-service tool to manage your Team.</p> <p>A Team can be managed by the initial user on the Team or by any Administrator added to the Team.</p> <p>An email address can belong to only one SkySQL Team. If an email address is already in a Team, it cannot be added to another Team.</p>"},{"location":"Security/Managing%20Portal%20Users/#access-to-user-management","title":"Access to User Management","text":"<p>To access the User Management interface:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Click the \"Settings\" link in the main menu (left navigation in the Portal).</li> <li>Click the User Management button.</li> </ol> <p></p> <p>User Management</p>"},{"location":"Security/Managing%20Portal%20Users/#roles","title":"Roles","text":"<p>Each Team member has one of the following roles:</p> <ul> <li>Administrator</li> <li>Member</li> <li>Viewer</li> <li>Billing</li> </ul>"},{"location":"Security/Managing%20Portal%20Users/#add-a-team-member","title":"Add a Team Member","text":"<p>User Management - Invite</p> <p>From the User Management interface, an Administrator can invite someone to join a team:</p> <ol> <li>Click the \"Invite\" button in the upper right corner of the User Management interface.</li> <li>Enter the email address of the person to invite to the team.</li> <li>Choose the desired role for this user.</li> <li>Click the \"Add User\" button.</li> </ol> <p>Once a user has been invited, they will appear in the Team member list in an \"Invited\" status until the invitation is accepted.</p> <p>An invitation is delivered by email. The user will be prompted to complete account setup when accepting the invitation.</p> <p>You can withdraw the invitation before it is accepted by clicking on the \"Cancel Invitation\" link in the Team member list.</p>"},{"location":"Security/Managing%20Portal%20Users/#remove-a-team-member","title":"Remove a Team Member","text":"<p>From the User Management interface, an Administrator can remove a team member:</p> <ol> <li>Identify the team member to remove.</li> <li>Click the ellipsis icon (\"...\") on the right side of that user's row.</li> <li>Select the \"Deactivate\" menu item.</li> <li>Read the displayed warning.</li> <li>Click the \"Deactivate\" button to complete deactivation.</li> </ol>"},{"location":"Security/Managing%20Portal%20Users/#edit-a-role","title":"Edit a Role","text":"<p>From the User Management interface, an Administrator can change a team member's role:</p> <ol> <li>Identify the team member to modify.</li> <li>Click the ellipsis icon (\"...\") on the right side of that user's row.</li> <li>Select the \"Edit\" menu item.</li> <li>Choose the desired Role for the user.</li> <li>Click the \"Save\" button to complete the change.</li> </ol>"},{"location":"Security/Portal%20Single%20Sign-On/","title":"Portal Single Sign-On","text":"<p>By default, authentication to the SkySQL Portal is performed with SkySQL ID credentials.</p> <p>Users with personal accounts with Google, GitHub LinkedIn or business Google G Suite accounts can authenticate via social login. This ability does not depend on enterprise authentication configuration.</p>"},{"location":"Security/Private%20VPC%20connections/","title":"Private VPC connections","text":"<p>Some customers may have regulatory requirements or information security policies which prohibit the default database connections over the public internet.</p> <p>SkySQL services can optionally be configured for private connections using cloud provider-specific features - See Using Private VPC Connections for details on how to set this up. </p> <p>By default, client traffic to SkySQL services may transit the public internet and is protected with TLS/SSL and a firewall configured by IP allowlist.</p>"},{"location":"Serverless/","title":"Serverless","text":"<p>SkySQL Serverless is the first true serverless database solution for the MySQL and MariaDB ecosystem, uniquely built to meet the dynamic demands of modern applications. SkySQL Serverless combines instant scalability with cost efficiency, scaling down to zero when idle\u2014saving you from paying for unused capacity. When workloads resume, Serverless service is ready in milliseconds, ensuring a seamless, uninterrupted experience for applications and users.</p>"},{"location":"Serverless/#true-serverless-experience","title":"True Serverless Experience","text":"<ul> <li>Instant Launch: Databases ready in milliseconds using pre-fabricated micro databases</li> <li>Scale to Zero: Complete resource deallocation during idle periods</li> <li>Immediate Cold Start: No delays during initialization</li> </ul>"},{"location":"Serverless/#cloud-native-architecture","title":"Cloud-Native Architecture","text":"<ul> <li>No Forking: Built on proven open-source MariaDB/MySQL without modifications</li> <li>Kubernetes-Native: Leverages custom controllers for fine-grained resource control</li> <li>Multi-Cloud: Deploy across AWS, Azure, and Google Cloud Platform</li> </ul>"},{"location":"Serverless/#intelligent-scaling","title":"Intelligent Scaling","text":"<ul> <li>Vertical Auto-Scaling: CPU and memory adjustments in real-time</li> <li>Horizontal Scaling: Transparent live migrations for unlimited growth</li> <li>Storage Auto-Scaling: Dynamic storage expansion based on usage patterns</li> </ul>"},{"location":"Serverless/#free-developer-tier","title":"Free Developer Tier","text":"<p>Every SkySQL account includes a perpetually free serverless database perfect for: - Development and testing environments - Learning and experimentation - Proof-of-concept projects - Small applications with intermittent usage</p> <p>Specifications: - 0.5 vCPU baseline - 2GB memory baseline - Auto-scaling up to 2 SCUs (SkySQL Compute Units) - No time limits or restrictions</p>"},{"location":"Serverless/#architecture-highlights","title":"Architecture Highlights","text":""},{"location":"Serverless/#compute-storage-approach","title":"Compute-Storage Approach","text":"<p>SkySQL takes a different approach from services like AWS Aurora: - Preserves Open Source: No modifications to the mature InnoDB storage engine - Native Kubernetes: Uses standard Kubernetes volume management - No Hidden Costs: Transparent pricing without surprise IOPS charges</p>"},{"location":"Serverless/#intelligent-proxy-system","title":"Intelligent Proxy System","text":"<ul> <li>Always-On Connections: Applications stay connected even when database scales to zero</li> <li>Session State Management: Preserves variables, prepared statements, and transaction state</li> <li>Transparent Failover: Automatic recovery from failures without application impact</li> </ul>"},{"location":"Serverless/#buffer-pool-management","title":"Buffer Pool Management","text":"<ul> <li>Performance Consistency: Maintains cache hit ratios during scaling operations</li> <li>Automatic Hydration: Reloads frequently accessed data after scaling events</li> <li>SSD Offloading: Temporarily stores hot pages during scale-down operations</li> </ul>"},{"location":"Serverless/#supported-workloads","title":"Supported Workloads","text":"<p>SkySQL Serverless is designed to handle diverse workload types:</p>"},{"location":"Serverless/#transactional-workloads-oltp","title":"Transactional Workloads (OLTP)","text":"<ul> <li>High-frequency, low-latency operations</li> <li>ACID compliance and data consistency</li> <li>Connection pooling and session management</li> </ul>"},{"location":"Serverless/#analytical-workloads-olap","title":"Analytical Workloads (OLAP)","text":"<ul> <li>Complex queries and reporting</li> <li>Integration with MariaDB ColumnStore</li> <li>On-demand analytics processing</li> </ul>"},{"location":"Serverless/#semantic-search","title":"Semantic Search","text":"<ul> <li>Vector database capabilities</li> <li>AI/ML application support</li> <li>Natural language query processing</li> </ul>"},{"location":"Serverless/#getting-started","title":"Getting Started","text":"<ol> <li>Create Account - Sign up for your free SkySQL account</li> <li>Launch Service - Follow our quickstart guide</li> <li>Connect Application - Integrate with your applications</li> <li>Monitor Performance - Use built-in monitoring tools</li> </ol>"},{"location":"Serverless/Architecture/","title":"Serverless Architecture","text":"<p>This document provides a comprehensive technical overview of SkySQL Serverless architecture, explaining how it achieves true serverless capabilities while maintaining full compatibility with MySQL and MariaDB.</p>"},{"location":"Serverless/Architecture/#design-philosophy","title":"Design Philosophy","text":"<p>SkySQL Serverless is built on the principle: \"Don't change what works\". Instead of re-architecting the database engine like other cloud providers, SkySQL leverages cloud-native techniques to achieve serverless capabilities while preserving the mature, open-source database engine.</p>"},{"location":"Serverless/Architecture/#core-principles","title":"Core Principles","text":"<ol> <li>Preserve Open Source: Keep the proven InnoDB storage engine intact</li> <li>Cloud-Native Approach: Use Kubernetes and containers for orchestration</li> <li>No Forking: Maintain full compatibility with existing applications</li> <li>Transparent Operations: Scaling and management should be invisible to applications</li> </ol>"},{"location":"Serverless/Architecture/#high-level-architecture","title":"High-Level Architecture","text":""},{"location":"Serverless/Architecture/#core-components","title":"Core Components","text":""},{"location":"Serverless/Architecture/#1-intelligent-proxy","title":"1. Intelligent Proxy","text":"<p>The multi-tenant proxy is the cornerstone of SkySQL Serverless, providing:</p>"},{"location":"Serverless/Architecture/#connection-management","title":"Connection Management","text":"<ul> <li>Always-On Connections: Maintains application connections even when database scales to zero</li> <li>Connection Pooling: Efficiently manages database connections behind the scenes</li> <li>Load Balancing: Distributes requests across available database instances</li> </ul>"},{"location":"Serverless/Architecture/#session-state-management","title":"Session State Management","text":"<p>The proxy tracks and preserves: - System variables: <code>SET @@session.sort_buffer_size = X</code> - User variables: <code>SET @myvar = 'value'</code> - Prepared statements and their definitions - Transaction isolation levels and other session settings</p>"},{"location":"Serverless/Architecture/#failover-and-recovery","title":"Failover and Recovery","text":"<ul> <li>Transparent Failover: Automatically handles database failures</li> <li>Transaction Replay: Replays partial transactions to ensure data integrity</li> <li>State Recreation: Re-establishes session state on new connections</li> </ul>"},{"location":"Serverless/Architecture/#2-kubernetes-orchestration","title":"2. Kubernetes Orchestration","text":"<p>SkySQL extends Kubernetes with custom controllers for database-specific operations:</p>"},{"location":"Serverless/Architecture/#custom-resource-definitions-crds","title":"Custom Resource Definitions (CRDs)","text":"<ul> <li>DatabaseService: Defines serverless database configurations</li> <li>ScalingPolicy: Controls auto-scaling behavior and limits</li> <li>BackupSchedule: Manages automated backup operations</li> </ul>"},{"location":"Serverless/Architecture/#custom-controllers","title":"Custom Controllers","text":"<ul> <li>Resource Monitor Controller: Tracks CPU, memory, and connection metrics</li> <li>Scaling Controller: Implements vertical and horizontal scaling decisions</li> <li>Migration Controller: Handles transparent live migrations</li> <li>Pool Controller: Manages pre-fabricated database pools</li> </ul>"},{"location":"Serverless/Architecture/#3-pre-fabricated-database-pools","title":"3. Pre-Fabricated Database Pools","text":"<p>To achieve millisecond launch times, SkySQL maintains pools of ready-to-use databases:</p>"},{"location":"Serverless/Architecture/#pool-management","title":"Pool Management","text":"<ul> <li>Regional Distribution: Pools maintained in all supported regions</li> <li>Dynamic Replenishment: Pools refilled based on demand patterns</li> <li>Resource Optimization: Minimal resource allocation for pool databases</li> </ul>"},{"location":"Serverless/Architecture/#database-initialization","title":"Database Initialization","text":"<p>When a user requests a database: 1. Check out a database from the appropriate pool 2. Resize according to service configuration 3. Execute security procedures (user creation, endpoint configuration) 4. Update control plane tracking 5. Database ready for use</p>"},{"location":"Serverless/Architecture/#4-auto-scaling-engine","title":"4. Auto-Scaling Engine","text":"<p>SkySQL implements sophisticated auto-scaling across multiple dimensions:</p>"},{"location":"Serverless/Architecture/#vertical-scaling-algorithm","title":"Vertical Scaling Algorithm","text":"<pre><code>Every 200ms:\n  - Sample CPU usage (UsageCoreNanoSeconds)\n  - Update 30-second sliding window\n\nScale-up decision (1-second window):\n  - If CPU usage \u2265 90% of allocated budget \u2192 Scale up\n\nScale-down decision (30-second window):\n  - If average CPU usage \u2264 20% \u2192 Scale down\n  - If no active connections for 10s \u2192 Scale to 0\n</code></pre>"},{"location":"Serverless/Architecture/#resource-allocation","title":"Resource Allocation","text":"<ul> <li>Granular Scaling: 0.5 vCPU and 2GB memory increments</li> <li>Dynamic Limits: Free tier limited to 2 SCUs, paid tiers scale based on configuration</li> <li>Linux cgroups: Uses cgroupsv2 for precise resource control</li> </ul>"},{"location":"Serverless/Architecture/#database-states-and-lifecycle","title":"Database States and Lifecycle","text":""},{"location":"Serverless/Architecture/#active-state","title":"Active State","text":"<ul> <li>Full Resources: CPU, memory, and connections allocated based on demand</li> <li>Optimized Cache: Buffer pool sized and hydrated for current workload</li> <li>Real-time Monitoring: Continuous performance and resource tracking</li> </ul>"},{"location":"Serverless/Architecture/#suspended-state","title":"Suspended State","text":"<p>When activity drops to zero: 1. Scale Down Resources: Remove active threads, reduce memory allocation 2. Minimize Buffer Pool: Reduce to minimum required by InnoDB 3. Maintain Connections: Proxy keeps application connections alive 4. Quick Reactivation: Instant scale-up when activity resumes</p>"},{"location":"Serverless/Architecture/#parked-state","title":"Parked State","text":"<p>After extended inactivity (several hours): 1. Terminate Pod: Database pod completely removed 2. Preserve Storage: Volume remains attached to service 3. Proxy Management: Proxy tracks parked state 4. Automatic Recreation: Pod recreated when activity resumes</p>"},{"location":"Serverless/Architecture/#buffer-pool-management","title":"Buffer Pool Management","text":"<p>The database buffer pool is critical for performance. SkySQL implements intelligent buffer pool management:</p>"},{"location":"Serverless/Architecture/#dynamic-sizing","title":"Dynamic Sizing","text":"<ul> <li>Proportional Scaling: Buffer pool size adjusted with resource allocation</li> <li>Performance Monitoring: Track cache hit ratios during scaling operations</li> </ul>"},{"location":"Serverless/Architecture/#cache-hydration","title":"Cache Hydration","text":"<p>When scaling up after a scale-down: 1. Page Tracking: Most frequently used pages identified during scale-down 2. SSD Storage: Page IDs stored on high-speed SSD storage 3. Background Loading: Frequently used pages reloaded into memory 4. Performance Consistency: Maintains cache hit ratios across scaling events</p>"},{"location":"Serverless/Architecture/#implementation-details","title":"Implementation Details","text":"<pre><code>-- Buffer pool hydration process\n1. Before scale-down: SHOW ENGINE INNODB STATUS \u2192 identify hot pages\n2. Store page IDs to fast SSD storage\n3. During scale-up: Background process fetches pages from disk\n4. Asynchronous hydration maintains query performance\n</code></pre>"},{"location":"Serverless/Architecture/#live-migration-system","title":"Live Migration System","text":"<p>For horizontal scaling, SkySQL implements transparent live migrations:</p>"},{"location":"Serverless/Architecture/#migration-triggers","title":"Migration Triggers","text":"<ul> <li>High Watermark: Migration initiated at ~70% memory utilization</li> <li>Automatic Provisioning: New instances created if needed</li> <li>Workload Analysis: Least-used databases migrated first</li> </ul>"},{"location":"Serverless/Architecture/#migration-process","title":"Migration Process","text":"<ol> <li>Snapshot Creation: Create database snapshot on target instance</li> <li>Replication Setup: Establish replication channel to source</li> <li>Synchronization: Wait for replica to catch up</li> <li>Proxy Redirection: Transparently redirect connections</li> <li>Source Cleanup: Decommission source database</li> </ol>"},{"location":"Serverless/Architecture/#zero-downtime-guarantees","title":"Zero-Downtime Guarantees","text":"<ul> <li>Differential Snapshots: Only changes copied after initial snapshot</li> <li>Connection Preservation: No application connection drops</li> <li>Session Continuity: All session state preserved during migration</li> </ul>"},{"location":"Serverless/Architecture/#storage-management","title":"Storage Management","text":""},{"location":"Serverless/Architecture/#auto-scaling-storage","title":"Auto-Scaling Storage","text":"<p>SkySQL monitors and scales storage automatically:</p>"},{"location":"Serverless/Architecture/#scaling-thresholds","title":"Scaling Thresholds","text":"<ul> <li>Small Volumes (&lt; 100GB): Scale at 60% capacity</li> <li>Medium Volumes (100-500GB): Scale at 80% capacity  </li> <li>Large Volumes (&gt; 500GB): Scale at 95% capacity</li> </ul>"},{"location":"Serverless/Architecture/#implementation","title":"Implementation","text":"<ul> <li>Continuous Monitoring: PersistentVolumeClaim usage tracked</li> <li>Proactive Scaling: Scaling initiated before capacity exhausted</li> <li>Block Storage Integration: Currently uses cloud provider block storage (AWS EBS, Azure Disk, Google Persistent Disk)</li> </ul>"},{"location":"Serverless/Architecture/#future-storage-innovations","title":"Future Storage Innovations","text":"<p>SkySQL is evaluating distributed storage solutions: - Ceph/Rook Integration: Self-managed distributed storage - Multi-Cloud Storage: Storage spanning multiple cloud providers - Performance Optimization: Custom storage optimizations for database workloads</p>"},{"location":"Serverless/Architecture/#security-architecture","title":"Security Architecture","text":""},{"location":"Serverless/Architecture/#network-security","title":"Network Security","text":"<ul> <li>Private Networking: Database pods run in private subnets</li> <li>Encryption in Transit: TLS/SSL for all connections</li> <li>Firewall Integration: Cloud-native security group integration</li> </ul>"},{"location":"Serverless/Architecture/#data-protection","title":"Data Protection","text":"<ul> <li>Encryption at Rest: All storage volumes encrypted</li> <li>Key Management: Integration with cloud provider key management services</li> <li>Access Controls: Role-based access control (RBAC)</li> </ul>"},{"location":"Serverless/Architecture/#isolation","title":"Isolation","text":"<ul> <li>Pod-Level Isolation: Each database runs in isolated Kubernetes pod</li> <li>Network Policies: Kubernetes network policies for traffic control</li> <li>Resource Isolation: cgroups ensure resource isolation between databases</li> </ul>"},{"location":"Serverless/Architecture/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"Serverless/Architecture/#real-time-metrics","title":"Real-Time Metrics","text":"<ul> <li>Resource Utilization: CPU, memory, storage, and network metrics</li> <li>Database Performance: Query performance, connection counts, cache hit ratios</li> <li>Scaling Events: Auto-scaling decisions and their impact</li> </ul>"},{"location":"Serverless/Architecture/#alerting-system","title":"Alerting System","text":"<ul> <li>Proactive Alerts: Performance degradation warnings</li> <li>Scaling Notifications: Automatic scaling event notifications</li> <li>Failure Detection: Immediate alerts for database failures</li> </ul>"},{"location":"Serverless/Architecture/#integration","title":"Integration","text":"<ul> <li>Prometheus: Metrics collection and storage</li> <li>Grafana: Visualization and dashboards</li> <li>Custom Metrics: Database-specific performance indicators</li> </ul>"},{"location":"Serverless/Architecture/#other-considerations","title":"Other Considerations","text":"<ul> <li>Vendor Lock-in: SkySQL maintains portability</li> <li>Cost Transparency: No hidden charges or surprise costs</li> <li>Performance: Better performance due to no compute-storage disaggregation</li> <li>Compatibility: Full compatibility with existing applications</li> </ul>"},{"location":"Serverless/Architecture/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"Serverless/Architecture/#scaling-performance","title":"Scaling Performance","text":"<ul> <li>Vertical Scaling: Typically completes in &lt; 5 seconds</li> <li>Horizontal Scaling: Live migration in &lt; 30 seconds</li> <li>Cold Start: Database ready in &lt; 100 milliseconds</li> </ul>"},{"location":"Serverless/Architecture/#query-performance","title":"Query Performance","text":"<ul> <li>OLTP Workloads: Equivalent to provisioned instances</li> <li>Cache Performance: Maintained through buffer pool hydration</li> <li>Connection Overhead: Minimal proxy overhead (&lt; 1ms latency)</li> </ul>"},{"location":"Serverless/Architecture/#scalability-limits","title":"Scalability Limits","text":"<ul> <li>Vertical Scaling: Up to cloud provider instance limits</li> <li>Horizontal Scaling: Unlimited through live migration</li> <li>Storage Scaling: Up to cloud provider storage limits</li> </ul>"},{"location":"Serverless/Architecture/#future-enhancements","title":"Future Enhancements","text":""},{"location":"Serverless/Architecture/#planned-features","title":"Planned Features","text":"<ol> <li>Analytics Integration: On-demand OLAP with DuckDB integration</li> <li>Global Distribution: Multi-region database deployment</li> <li>Advanced AI: Machine learning-driven optimization</li> <li>Edge Computing: Edge database deployments</li> </ol>"},{"location":"Serverless/Architecture/#research-areas","title":"Research Areas","text":"<ul> <li>Quantum-Ready Encryption: Future-proof security</li> <li>Advanced Caching: Intelligent cache management algorithms</li> <li>Distributed Consensus: Enhanced distributed database capabilities</li> </ul>"},{"location":"Serverless/Architecture/#best-practices","title":"Best Practices","text":""},{"location":"Serverless/Architecture/#application-design","title":"Application Design","text":"<ol> <li>Connection Pooling: Use connection pooling in applications</li> <li>Graceful Degradation: Handle temporary scaling events</li> <li>Monitoring Integration: Implement application-level monitoring</li> </ol>"},{"location":"Serverless/Architecture/#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Query Optimization: Optimize queries for scaling environments</li> <li>Index Strategy: Maintain appropriate indexes for workload</li> <li>Connection Management: Minimize connection overhead</li> </ol>"},{"location":"Serverless/Architecture/#cost-optimization","title":"Cost Optimization","text":"<ol> <li>Workload Analysis: Understand application usage patterns</li> <li>Scaling Limits: Set appropriate scaling limits</li> <li>Resource Right-Sizing: Monitor and adjust resource allocation</li> </ol> <p>This architecture enables SkySQL Serverless to provide true serverless capabilities while maintaining the performance, reliability, and compatibility that enterprises require. </p>"},{"location":"Service%20Tiers/","title":"Service Tiers","text":"<p>Power Tier is a premium service offering who have the most critical requirements for uptime, availability, performance, and support.</p>"},{"location":"Service%20Tiers/#upgrade-to-power-tier","title":"Upgrade to Power Tier","text":"<p>By default, any new signed up users are in the \u201cFoundation Tier\u201d. To upgrade to Power Tier,\u00a0simply click the \u2018Upgrade\u2019 button - SkySQL support will contact you and start the upgrade process. You can also directly reach out to SkySQL Support.</p>"},{"location":"Service%20Tiers/#features","title":"Features","text":"<p>Features available to SkySQL Power Tier customers include:</p> <ul> <li>Enhanced Service Level Agreement (SLA)</li> <li>Extended Range of Instance Sizes</li> <li>Choice of Maintenance Window</li> <li>MaxScale Redundancy</li> <li>Choice of Support Plans</li> <li>Point-in-time recovery</li> <li>See all\u00a0Options\u00a0which augment the default SkySQL service experience</li> </ul>"},{"location":"Service%20Tiers/Maintenance%20Windows/","title":"Maintenance Windows","text":"<p>Maintenance windows are a scheduled period of time when hardware, network, software, or configuration changes can be applied, and processes can be restarted.</p> <p>For Foundation Tier customers, maintenance windows are predefined by region.</p> <p>For Power Tier customers, maintenance windows are customer-selected.</p> <p>Notice is provided to customers in advance of maintenance. SkyDBA customers are asked to confirm maintenance prior to scheduled start.</p>"},{"location":"Service%20Tiers/Maintenance%20Windows/#view-current-maintenance-window","title":"View Current Maintenance Window","text":"<p>For Foundation Tier, to view the maintenance widown, Go to \"Your services\" and then \"Details\".</p> <p>On Power Tier, to show the current maintenance window for a service:</p> <ol> <li> <p>Go to \"Your services\" page (top choice in left navigation).</p> </li> <li> <p>Click the \"&gt;\" to the left of the desired service.</p> </li> <li> <p>The current maintenance window is shown in the \"Customization\" section.</p> </li> </ol>"},{"location":"Service%20Tiers/Maintenance%20Windows/#choose-maintenance-window","title":"Choose Maintenance Window","text":"<p>A maintenance window selection applies to all services within a region.</p> <p>For Power Tier customers, maintenance windows are customer-selected:</p> <ul> <li> <p>A menu of supported maintenance windows is presented at time of service launch.</p> </li> <li> <p>Maintenance windows may be changed after service launch, once a service reaches \"Healthy\" state.</p> </li> </ul> <p>Maintenance windows can be updated at time of service launch, or on-demand:</p> <ol> <li> <p>Go to \"Your services\" page (top choice in left navigation).</p> </li> <li> <p>Click the \"&gt;\" to the left of the desired service.</p> </li> <li> <p>The current maintenance window is shown in the \"Customization\" section.</p> </li> <li> <p>Click on the triangle at the right of the \"Maintenance window\" to see a drop down display of available maintenance windows.</p> </li> <li> <p>Select the desired maintenance window and click on the \"Save\" button. This change will be applied to all services in the region.</p> </li> </ol>"},{"location":"Service%20Tiers/Maxscale%20Redundancy/","title":"MaxScale Redundancy","text":"<p>MariaDB MaxScale serves as the load balancer in certain SkySQL topologies.</p> <p>SkySQL supports MaxScale Redundancy as an option at time of launch:</p> <ul> <li> <p>This feature is not enabled by default. By default, topologies that use MaxScale contain only one MaxScale node.</p> </li> <li> <p>When MaxScale Redundancy is selected, MaxScale nodes are deployed in a highly available (HA) active-active configuration behind round robin load balancing.</p> </li> <li> <p>When MaxScale Redundancy is enabled, MaxScale instance size can be selected.</p> </li> <li> <p>MaxScale Redundancy is available to Power Tier customers.</p> </li> </ul>"},{"location":"Service%20Tiers/Maxscale%20Redundancy/#compatibility","title":"Compatibility","text":"<ul> <li>Replicated Transactions</li> </ul>"},{"location":"Service%20Tiers/Maxscale%20Redundancy/#enable-maxscale-redundancy","title":"Enable MaxScale Redundancy","text":"<ol> <li> <p>Launch a SkySQL service:</p> </li> <li> <p>Check the \"Enable MaxScale Redundancy\" checkbox.</p> </li> <li> <p>Choose the MaxScale instance size</p> </li> </ol>"},{"location":"Service%20Tiers/Pricing/","title":"Pricing","text":"<p>SkySQL pricing information is shown at time of service launch.</p> <p>Pricing shown within the SkySQL interface is an estimate of the cost of using SkySQL services based on your specified usage parameters. Pricing information is shown at time of service launch and subsequently as estimated charges.</p> <p>The cost shown is not a quote and does not guarantee the cost for your actual use of SkySQL services.</p>"},{"location":"Service%20Tiers/Pricing/#estimated-pricing","title":"Estimated Pricing","text":"<p>The cost estimate may vary from your actual costs for several reasons, including:</p> <ul> <li> <p>Actual usage: Your actual cost will be based on your actual use of the services, not the estimate.</p> </li> <li> <p>Region: The prices for SkySQL services may vary between regions. Using a different region than the one selected may affect the results.</p> </li> <li> <p>Price changes: On-demand pricing for most services may change over time. If you buy services on-demand, your bill may be less or more than estimated based on the current on-demand rates.</p> </li> <li> <p>Taxes: The estimate does not include any taxes that may be applied to your purchase of the services.</p> </li> <li> <p>Time frame assumptions: On-demand monthly pricing assumes that your instance or node runs for a 730 hour month. The estimate does not account for leap years, which add one additional day (24 hours).</p> </li> <li> <p>Promotional credits and discounts: The estimate does not account for promotional credits or other discounts.</p> </li> <li> <p>Monthly billing period: MariaDB bills on a monthly basis. If your utilization starts mid-month, you will only see a portion of an actual month's full costs on your invoice.</p> </li> <li> <p>Rounding: Estimated fees include mathematical rounding of pricing data.</p> </li> <li> <p>Scale fabric: Scale fabric costs represent the additional network, host, and backup infrastructure needed to support multi-node topologies.</p> </li> <li> <p>Previous services: The estimate is only for the service being launched and does not account for other current or previous charges to the SkySQL account.</p> </li> <li> <p>Cross-Region Replicas: The estimate does not include cross-region replicas.</p> </li> <li> <p>Currency: Estimates are provided in either US dollars or Euros depending on your account address country. Your actual cost will be based on US dollar pricing with a conversion to Euros depending on your account address country.</p> </li> </ul>"},{"location":"SkyCopilot%20Guide/","title":"SkyAI Agents User Guide (Tech Preview)","text":"<p>Note</p> <ul> <li>This capability is currently in Tech Preview.</li> <li>Currently it is free to use. </li> <li>We provide upto a million tokens of free usage per month per account.</li> <li>Our \"free usage\" policy is subject to change as we finalize the product.</li> </ul> <p>We appreciate your feedback and suggestions. You can reach us at info@skysql.com or support@skysql.com</p> <p>SkySQL offers two types of SkyAI Agents:</p> <ul> <li>Built-in Agents: These are preconfigured agents designed to help developers and DBAs maximize the value of SkySQL. Currently, we have two agents: Developer Copilot and DBA Copilot. The Developer Copilot assists users in answering questions about MySQL, MariaDB, and SkySQL, in general. The DBA Copilot enables DBA tasks like performance tuning or debugging errors. They are tailored to enhance developer/DBA productivity.</li> <li>User-Created Custom DB Agents: These are agents on your schemas/datasets permitting natural language queries over complex databases with high accuracy, consistency, and ease. The databases these agents operate on can be managed within SkySQL or external MySQL or MariaDB DBs.</li> </ul>"},{"location":"SkyCopilot%20Guide/#why-skyai-agents","title":"Why SkyAI Agents?","text":"<p>Traditional solutions fall short because of:</p> <ul> <li>Complex database schemas with multiple layers and relationships.</li> <li>Ambiguous terminology and hidden business rules.</li> <li>Inconsistent data that makes standard AI models inaccurate.</li> </ul> <p>A common approach, Agentic Retrieval-Augmented Generation (RAG), requires extensive data integration and maintenance, making it resource-intensive.</p> <p>However, automation alone isn't enough. Real-world databases often contain hundreds of tables with cryptic naming conventions, impure data, and hidden rules. This is where the human-in-the-loop design becomes essential. SkySQL engages the user interactively through a wizard-like interface that:</p> <ul> <li>Proposes relevant tables and dimensions based on the Agent's intent.</li> <li>Analyzes data to compute initial semantic descriptions for columns and tables.</li> <li>Allows the user to iteratively refine these semantics.</li> </ul> <p>Users validate and train the Agent by asking questions, inspecting the generated SQL, and tagging \"golden SQL\" queries that serve as the ground truth. This iterative process ensures the Agent's outputs are both accurate and contextually relevant.</p>"},{"location":"SkyCopilot%20Guide/#sky-semantic-agents-architecture","title":"Sky Semantic Agents Architecture","text":"<p>Under the hood, SkySQL handles:</p> <ul> <li>Vector Indexing of DB metadata, high-cardinality text columns, and golden SQL to enable efficient semantic searches.</li> <li>Automatic Orchestration of the RAG pipeline, reducing the need for external integrations and securing all AI interactions.</li> <li>Online Evaluation of the results for accuracy - when dealing with complexity, incomplete guidance or semantics, the responses can be inaccurate. It is important for users or a consuming application to know the quality of the response. We use a \"LLM as Judge\" approach to provide a confidence and correctness score that is biased against providing false positives. The evaluator is designed to assign lower confidence for uncertain responses rather than risk assigning high confidence to incorrect ones. This approach ensures trustworthy results.</li> </ul> <p>Once trained, the Agent can be consumed via a simple REST API that supports:</p> <ul> <li>Stateful Chat Sessions.</li> <li>On-demand Natural Language Queries.</li> <li>Advanced Semantic Searches (coming in the near future).</li> </ul>"},{"location":"SkyCopilot%20Guide/#built-in-agents","title":"Built-in Agents","text":""},{"location":"SkyCopilot%20Guide/#1-developer-copilot-agent-for-sql-developers","title":"1) Developer Copilot Agent for SQL Developers","text":"<p>This agent functions much like modern copilot tools but is specifically tailored for SkySQL and MariaDB. It allows developers to interact with the database using natural language queries, enabling them to quickly find solutions without needing to dive deep into documentation or use SQL editing tools.</p> <p>You can ask a wide range of questions, such as:</p> <p>General MariaDB Queries:</p> <ul> <li>\"What is the default storage engine in SkySQL?\"</li> </ul> <p>SkySQL-Specific Queries:</p> <ul> <li>\"Show me a SkySQL program to connect from Java.\"</li> <li>\"In SkySQL, how can I configure my DB properties?\"</li> </ul> <p>Additionally, the agent can generate complex SQL queries spanning multiple tables, create schemas, write integration code, and even assist with tasks like generating stored procedures or loading data. This agent is trained using the SkySQL documentation and leverages the OpenAI LLM's prior knowledge to provide accurate, context-aware responses.</p> <p>Example of the Developer Copilot in action: </p>"},{"location":"SkyCopilot%20Guide/#2-dba-copilot-agent","title":"2) DBA Copilot Agent","text":"<p>The DBA Copilot is a specialized agent that helps DBAs with system information, tuning, and diagnostics. It taps directly into SkySQL's built-in system tables and metadata to answer queries about the database's internal state.</p> <p>When a user asks a question, it breaks the query down into discrete steps, each of which typically gets translated into a SQL statement targeting system tables such as those in <code>information_schema</code>, <code>mysql</code>, or <code>performance_schema</code>. These steps are executed to fetch relevant data and provide actionable insights, making it easier for DBAs to monitor and optimize database performance.</p> <p>Example of the DBA Copilot in action: </p>"},{"location":"SkyCopilot%20Guide/#important-information","title":"Important information","text":"<p>The simplest way to get started is by using our Demo DB in the \"DataSource\" drop down. It features a standalone MariaDB server preloaded with sample data and includes logged slow queries for testing.</p> <p>You can begin by exploring some of the sample questions provided below. Alternatively, connect to any MariaDB server running on SkySQL or another platform to experiment with your own workloads.</p> <p>Note: The default DB user created in SkySQL (eg. \u201cdbpgf12345678\u201d) already has the required privileges pre-created. </p> <p>Steps to follow when using a non-SkySQL Datasource:</p> <ul> <li>First, add a Datasource and test the connectivity.</li> <li>We recommend testing with a Development/Test DB first.</li> <li>The DB user specified in this Datasource needs the privileges as noted below.</li> </ul> <p>Grant the privileges as shown below. Please note, Copilot doesn\u2019t require write privileges to your schema. Remember to replace \u201cyour_datasource_username\u201d with the username you specified during the Copilot Datasource creation.</p> <pre><code>GRANT SELECT, PROCESS, SHOW VIEW, SHOW DATABASES ON *.* TO `your_datasource_username`@`%`;\nGRANT CREATE, DROP, CREATE VIEW ON `sky_sys_catalog`.* TO `your_datasource_username`@`%`;\n</code></pre>"},{"location":"SkyCopilot%20Guide/#slow-query-analysis","title":"Slow Query Analysis","text":"<p>To analyze slow queries, you need to turn on 'Slow query' logging. The <code>slow_query_log</code> overhead is proportional to the amount of queries logged.</p> <p>It is recommended you start with a high <code>slow_query_time</code>, implement a <code>log_slow_rate_limit</code>, and disable logging when not in use.</p> <p>If using SkySQL, go to Config Manager to see all the current configuration templates. If you are using the default config (\"SkySQL Default - Mariadb Server...\"), click the 'Create New' button, and change the following settings:</p> <ul> <li>Change 'slow_query_log' to <code>ON</code>. Change 'log_output' to <code>TABLE</code> (defaults to <code>FILE</code>).</li> <li>Adjust the 'long_query_time' if required (Defaults to 10 secs). Caution: If 'long_query_time' is set too low, you could substantially increase the load. You can check the global status variable <code>slow_queries</code> to tune the <code>long_query_time</code>.</li> </ul>"},{"location":"SkyCopilot%20Guide/#performance-schema","title":"Performance Schema","text":"<p>It is also useful to turn ON 'Performance_schema' (Note that this option will restart your DB service and does introduce some additional overhead so implementation should be tested/tuned for best practice).</p>"},{"location":"SkyCopilot%20Guide/#semi-autonomous-no-code-semantic-skyai-agents","title":"Semi-Autonomous, No-Code Semantic SkyAI Agents","text":"<p>SkySQL includes a No-Code SkyAI Agent Builder. This tool empowers domain experts to define the missing semantics critical for accurate responses without requiring programming expertise. The system then leverages the database's metadata\u2014such as table definitions, constraints, and relationships\u2014and learns from historical queries to train the Agent.</p>"},{"location":"SkyCopilot%20Guide/#step-1-define-the-datasource","title":"Step 1: Define the DataSource","text":"<p>Ensure you have a clearly defined data source.</p> <p>The first step in creating an agent is to define the data source it will operate on. Click the \"Add\" button to open the data source configuration window. If you have an existing database in SkySQL, it will appear under the \"QuickConnect\" section. Simply click on the database name to auto-fill the connection details.</p> <p>You can also connect to any MySQL or MariaDB server that is accessible over the internet. Be sure to whitelist the IP address shown in the connection window to allow access.</p> <p>In this guide, we will connect to the default datasource \"Demo DB\" and use the Northwind database, which contains information on customers, orders, products, suppliers, employees, and shipping details\u2014a classic dataset designed to model a small trading company's operations.</p>"},{"location":"SkyCopilot%20Guide/#step-2-define-the-agents-intent","title":"Step 2: Define the Agent's Intent","text":"<p>Clearly outline the intent for your agent and its purpose. Provide enough details in the description to guide the agent creation process.</p> <p>Example intent:</p> <p>\"The Northwind AI Agent enables users to explore complex queries about customers, orders, products, employees, and suppliers with precision and ease. Designed to generate accurate SQL queries, it provides insights into sales performance, customer order history, product trends, supplier relationships, and employee activity.\"\"</p> <p>This ensures the agent is created with enough context to respond within its designated scope.</p> <p>Best Practices</p> <p>Tip #1: In-scope and Out-of-scope</p> <p>In large schemas with unclear or non-descriptive table names, it's a good idea to explicitly list which tables are relevant (in-scope) or irrelevant (out-of-scope) for the agent. This helps the agent focus on the right parts of the schema and avoid incorrect joins or irrelevant results.</p> <p>You need to clearly define what data, tables, and tasks your AI agent is allowed or expected to handle. For example, if you are creating a \"customer support agent\" and want only customer data to be part of this agent definition, you should explicitly say that:</p> <ul> <li>\"This agent handles customer support data (tickets, users, responses).\"</li> </ul> <p>You must also define what the agent should ignore, even if that data exists in the database. From the above example, you could say:</p> <ul> <li>\"This agent should not touch or interpret invoice or payment tables.\"</li> </ul> <p>Tip #2: Add any general rules that are applicable to the data in the database:</p> <p>Ex.</p> <ul> <li>\"When using filters on string or text in the SQL always default to using LIKE. e.g. where name like '%Steve%'.</li> </ul> <p>Tip #3: Explicitly define relationships</p> <p>If your database schema doesn't explicitly define key relationships (like foreign keys), you should manually specify them. This is especially important when building AI agents that need to understand how tables relate to one another in order to generate accurate SQL or reason effectively over the data.</p> <p>Suppose your schema looks like this:</p> <pre><code>##customers table\nCREATE TABLE customers (\n  id INT,\n  name VARCHAR(100),\n  email VARCHAR(100)\n);\n\n##orders table\nCREATE TABLE orders (\n  id INT,\n  customer_id INT,\n  total DECIMAL(10,2),\n  created_at DATETIME\n);\n</code></pre> <p>There's no foreign key constraint in the DDL, but logically: <code>orders.customer_id</code> refers to <code>customers.id</code></p> <p>If you don't tell your AI agent this, it might:</p> <ul> <li>Fail to join these tables</li> <li>Join them incorrectly</li> <li>Miss important connections in the data</li> </ul> <p>In the description you could provide a hint like this:</p> <pre><code>Table Relationships\n- orders.customer_id \u2192 customers.id\n[RELATIONSHIP]: Employees.EmployeeID -&gt; EmployeeTerritories.EmployeeID (1:1)\n[RELATIONSHIP]: Customers.CustomerID -&gt; Orders.CustomerID (1:M)\n</code></pre>"},{"location":"SkyCopilot%20Guide/#step-3-selecting-relevant-tables-and-overcoming-schema-complexities","title":"Step 3: Selecting Relevant Tables and overcoming schema complexities","text":"<p>As a general rule, avoid including more than 10 tables in a single AI agent's context. Large numbers of tables increase complexity, reduce accuracy, and make it harder for the agent to reason clearly about relationships. Instead, split responsibilities across multiple specialized agents, each focused on a specific domain or task. This improves performance, maintainability, and reliability.</p> <p>Why It Matters</p> <p>When an AI agent has to interpret too many tables:</p> <ul> <li>It struggles to understand which ones are relevant for a given question.</li> <li>It may generate incorrect joins or irrelevant results.</li> <li>Prompt size and model attention limits get exceeded, especially with large schemas.</li> </ul> <p>Keeping each agent focused improves SQL generation much more effective.</p> <p>Example</p> <p>Suppose your SaaS product has a database with 30+ tables, covering:</p> <ul> <li>User Management: <code>users</code>, <code>roles</code>, <code>sessions</code>, <code>login_attempts</code></li> <li>Billing: <code>customers</code>, <code>invoices</code>, <code>payments</code>, <code>plans</code>, <code>credits</code></li> <li>Support: <code>tickets</code>, <code>responses</code>, <code>agents</code>, <code>chat_logs</code></li> <li>Product Usage: <code>events</code>, <code>features_used</code>, <code>usage_metrics</code>, <code>api_calls</code></li> </ul> <p>Don't try to incorporate all of this into one agent.</p> <p>Recommended Approach</p> <ul> <li>Agent 1: UserAgent<ul> <li>Tables: <code>users</code>, <code>roles</code>, <code>sessions</code>, <code>login_attempts</code></li> <li>Tasks: \"Show last login per user\", \"Which roles had failed logins?\"</li> </ul> </li> <li>Agent 2: BillingAgent<ul> <li>Tables: <code>customers</code>, <code>invoices</code>, <code>payments</code>, <code>plans</code></li> <li>Tasks: \"What are the unpaid invoices?\", \"How much has customer X paid?\"</li> </ul> </li> <li>Agent 3: SupportAgent<ul> <li>Tables: <code>tickets</code>, <code>responses</code>, <code>agents</code></li> <li>Tasks: \"Average resolution time\", \"Top support agents last month\"</li> </ul> </li> <li>Agent 4: UsageAgent<ul> <li>Tables: <code>events</code>, <code>api_calls</code>, <code>features_used</code></li> <li>Tasks: \"Which features are most used?\", \"Track API call volume\"</li> </ul> </li> </ul> <p>Each agent has \\&lt;10 tables, well-defined scope, and avoids overloading the model.</p>"},{"location":"SkyCopilot%20Guide/#step-4-pruning-unnecessary-columns","title":"Step 4: Pruning Unnecessary Columns","text":"<p>Always limit (prune) the columns included in an AI agent's context to only those that are truly required. This is especially important for wide tables \u2014 those with dozens or hundreds of columns \u2014 as including too many can overwhelm the model, dilute context, and reduce accuracy.</p> <p>Why Pruning Columns is Important</p> <ul> <li>Reduces data processing overhead: The fewer columns included in queries, the less data the system needs to process, leading to faster execution times and reduced computational load.</li> <li>Optimizes LLM token usage: Large language models (LLMs) have token limits. Including unnecessary columns increases token consumption, which can degrade performance and inflate costs.</li> <li>Focuses the agent on essential attributes: Keeping only the necessary columns ensures the agent provides accurate results while avoiding irrelevant data that could introduce noise or inaccuracies in query generation.</li> </ul> <p>How to Prune Unnecessary Columns</p> <ol> <li>Identify Core Columns \u2013 Determine which columns contain critical information for answering relevant queries. These may include primary keys, foreign keys, and commonly queried attributes (e.g., <code>movie_title</code>, <code>release_year</code>, <code>rating</code>).</li> <li>Eliminate Redundant Data \u2013 Remove columns with repeated or derived data that can be computed from other fields (e.g., if <code>full_name</code> is stored separately as <code>first_name</code> and <code>last_name</code>, one format may be redundant).</li> <li>Exclude Irrelevant Fields \u2013 Drop columns that do not contribute to the agent's core intent. For example, if the goal is to generate movie-related SQL queries, fields like <code>internal_notes</code> or <code>marketing_campaign_id</code> may not be necessary.</li> <li>Optimize for Query Performance \u2013 Retaining only essential columns improves database indexing and query execution speeds, particularly for large datasets.</li> </ol> <p>By following this structured pruning approach, we ensure the agent remains efficient, cost-effective, and highly accurate in generating SQL queries.</p> <p>Example</p> <p>Let's say you have a table called <code>users</code> with 85 columns, including:</p> <ul> <li>Important: <code>id</code>, <code>email</code>, <code>created_at</code>, <code>is_active</code></li> <li>Noise: <code>last_password_hash</code>, <code>signup_source</code>, <code>email_verification_code</code>, <code>user_agent</code>, <code>device_id</code>, <code>feature_flags</code>, <code>marketing_opt_out</code>, <code>time_zone</code>, <code>session_data</code>, etc.</li> </ul> <p>You're building an agent that answers:</p> <p>\"How many new users signed up this week?\"</p> <p>Don't include all 85 columns.</p> <p>Only include:</p> <ul> <li><code>users.id</code></li> <li><code>users.email</code></li> <li><code>users.created_at</code></li> </ul> <p>That's all the model needs to answer the question accurately.</p>"},{"location":"SkyCopilot%20Guide/#step-5-ensuring-essential-categorical-columns-are-selected","title":"Step 5: Ensuring Essential Categorical Columns are Selected","text":"<p>Categorical columns provide structured context, making it easier for the agent to generate accurate queries by filtering and grouping data efficiently. These columns contain distinct, non-numeric values representing different categories or labels.</p> <p>Why Categorical Columns Matter</p> <ul> <li>Enable accurate filtering and segmentation     Queries often require filtering by categories, such as listing all orders from a specific region or finding customers in a particular industry.</li> <li>Improve query performance     When categorical columns are indexed properly, queries run significantly faster since the system can quickly locate relevant data.</li> <li>Ensure context-aware SQL generation     By retaining key categorical columns, the agent can correctly interpret and structure SQL queries based on user input.</li> </ul> <p>Examples of Categorical Columns in a complex business dataset:</p> <ul> <li>Country \u2013 (e.g., Germany, USA, Brazil)     Useful for queries like: \"List all customers based in Germany.\"</li> <li>Product Category \u2013 (e.g., Beverages, Condiments, Produce)     Helps answer: \"Show all products in the 'Beverages' category that are currently in stock.\"</li> <li>Employee Title \u2013 (e.g., Sales Representative, Manager, Vice President)     Enables queries such as: \"Find all orders handled by employees with the title 'Sales Representative'.\"</li> <li>ShipVia (Shipping Method) \u2013 (e.g., Federal Shipping, Speedy Express, United Package)     Useful for queries like: \"How many orders were shipped using 'Speedy Express' last month?\"</li> <li>Customer Region \u2013 (e.g., Western Europe, North America, Latin America)     Assists in questions such as: \"What are the total sales by region for the past quarter?\"</li> </ul> <p>How the Agent Uses Categorical Columns</p> <ul> <li>Indexing for Efficient Queries     The agent sets up auto-indexing for categorical columns to optimize filtering and sorting.</li> <li>Semantic Search for Relevance     When a user query includes a category (e.g., \"List all orders shipped via Federal Shipping to customers in Brazil\"), the agent automatically matches relevant indexed values and structures the SQL accordingly.</li> <li>Dynamic Filtering &amp; Grouping     The agent can refine search results based on selected categories (e.g., region, product type), ensuring accurate and structured responses.</li> </ul> <p>By ensuring categorical columns are selected and indexed properly, the agent can efficiently process natural language queries and return meaningful results \u2014 even across complex business datasets.</p>"},{"location":"SkyCopilot%20Guide/#step-6-establishing-golden-sql-benchmarks","title":"Step 6: Establishing 'Golden SQL' Benchmarks","text":"<p>Golden SQL queries serve as accuracy benchmarks for evaluating and guiding agent behavior. To be effective, these prompt/SQL pairs should closely reflect real-world questions users are likely to ask\u2014the more natural and representative the phrasing, the better. It's important to include a diverse set of questions that span the full functional scope of the agent to ensure comprehensive coverage. We recommend creating at least 10 Golden SQL queries to provide a robust foundation for evaluation, consistency, and future tuning.</p>"},{"location":"SkyCopilot%20Guide/#step-7-testing-and-refining-by-running-sample-queries","title":"Step 7: Testing and refining by running Sample Queries","text":"<p>Once schema refinement is complete, test the agent using structured queries:</p> <p>Simple Query:</p> <p>\"Find the customers with the highest total order value.\"</p> <p>Complex Query:</p> <p>\"Find the top 10 products in the 'Beverages' category, ranked by total quantity sold.\"</p> <p>Best Practices for Evaluating and Tuning Your SkyAI Agent</p> <p>To ensure your SkyAI agent delivers accurate, relevant, and trustworthy SQL outputs, it's important to continuously monitor and refine its configuration. Here's how to do that effectively:</p> <p>1. Monitor Outputs Using Your Business and Data Knowledge</p> <p>SkyAI-generated queries may be syntactically correct, but semantically off. Use your domain expertise and understanding of the data to:</p> <ul> <li>Validate if the results align with business logic</li> <li>Catch semantic mistakes, such as misused filters or joins</li> <li>Identify missing conditions that should've been applied</li> <li>Example: A query that returns top-selling products may technically run fine but forget to filter by date range, giving misleading results.</li> </ul> <p>2. Use the \"Evaluate\" Feature</p> <p>The SkyAI Builder platform includes a powerful built-in evaluation feature that leverages a large language model (LLM) as a judge to automatically assess the quality and accuracy of agent responses. This evaluation system is designed to simulate human judgment, allowing developers to measure how well their agents understand and respond to natural language prompts.</p> <p>Use this to measure:</p> <ul> <li>Conformance to Golden Query     Compare the generated SQL against your expected Golden Query to check for correctness and completeness.</li> <li>Accuracy of Results     Verify that the output data matches what you'd expect from a manual query</li> <li>Faithfulness     Ensure the query is logically faithful to the user's original intent \u2014 not just a best guess.</li> </ul> <p>Run test cases regularly to build confidence and detect regressions as you tweak the agent.</p> <p>3. Iteratively Fine-Tune the Agent Setup</p> <p>Tuning is not a one-time task \u2014 it's a cycle. Improve results over time by adjusting:</p> <ul> <li>Agent Description<ul> <li>Fine tune the purpose and scope of the agent as needed</li> <li>State what types of questions it should (and shouldn't) handle</li> <li>Add business context, like \"this agent only works with customer order data from the last 5 years\" or \"this agent can access only a specified office id\".</li> </ul> </li> <li>Table and Column Context<ul> <li>Add as needed, descriptive metadata to help the agent understand the meaning of each column (e.g., \"order_date is the date the customer placed the order\")</li> <li>Remove columns that are unused or misleading</li> </ul> </li> <li>Add/Remove Tables and Columns<ul> <li>Remove irrelevant tables that introduce confusion</li> <li>Add related tables only when necessary for common join paths</li> <li>Focus on simplifying the schema presented to the agent</li> </ul> </li> <li>Include/Exclude Categorical Columns<ul> <li>Include important categorical fields (e.g., region, category, status) that help with filtering and grouping</li> <li>Exclude categorical columns that are noisy, deprecated, or business-irrelevant</li> </ul> </li> </ul> <p>Repeat Until the Agent Meets Your Needs</p> <p>Every dataset and use case is different. The path to optimal performance is iterative:</p> <ol> <li>Run test queries</li> <li>Review outputs</li> <li>Adjust schema context</li> <li>Re-evaluate</li> <li>Repeat</li> </ol> <p>Over time, you'll get a well-tuned agent that produces accurate, efficient, and context-aware SQL aligned with your business goals.</p>"},{"location":"SkyCopilot%20Guide/#deploying-and-using-the-agent","title":"Deploying and Using the Agent","text":"<p>Your trained agent is now ready for deployment\u2014capable of transforming natural language queries into efficient SQL with high accuracy.</p> <p>In the Edit agent window, select the radio box \"Published\" to deploy the agent and make it available through the SkyAI Agent APIs.</p>"},{"location":"SkyCopilot%20Guide/MCP%20Server/","title":"SkySQL MCP Server","text":"<p>The SkySQL Model Context Protocol (MCP) Server offers a powerful interface for managing your SkySQL database instances and interacting with SkyAI Agents. It bridges the gap between your databases and AI-powered development tools.</p>"},{"location":"SkyCopilot%20Guide/MCP%20Server/#what-is-skysql-mcp-server","title":"What is SkySQL MCP Server?","text":"<p>The SkySQL MCP Server acts as an intermediary, allowing AI applications like Cursor, Claude Desktop, and Visual Studio Code Copilot to securely and efficiently interact with your SkySQL databases. It exposes your data in a structured way that AI tools can query, transforming complex database interactions into intuitive, real-time conversations.</p>"},{"location":"SkyCopilot%20Guide/MCP%20Server/#key-features-and-capabilities","title":"Key Features and Capabilities","text":"<p>The SkySQL MCP Server provides a comprehensive set of features designed to boost developer productivity and streamline database management:</p> <ul> <li>Launch and Manage Serverless Database Instances: Programmatically launch and manage new serverless MariaDB database instances directly within SkySQL.</li> <li>Interact with AI-Powered Database Agents: Seamlessly connect and interact with SkyAI Agents (Developer Copilot, DBA Copilot and Custom agents) to use natural language queries for database operations.</li> <li>Execute SQL Queries Directly: Run SQL queries on your SkySQL  instances through a unified interface.</li> <li>Flexible Deployment: Can be installed and integrated with various MCP client tools and IDEs.</li> </ul>"},{"location":"SkyCopilot%20Guide/MCP%20Server/#benefits","title":"Benefits","text":"<ul> <li>Simplified Database Management: Transform complex database interactions into intuitive, natural language conversations.</li> <li>Accelerated AI App Development: Integrate natural language interfaces directly into your applications, extracting responses from your database without extensive coding.</li> <li>Enhanced Developer/DBA Productivity: Empower developers and DBAs with AI-powered assistance for general queries, performance tuning, and debugging.</li> <li>Accurate and Context-Aware Responses: AI Agents are designed to deeply understand your data, minimizing hallucinations and providing precise, context-aware insights.</li> <li>Reduced Security Risks: SkyAI Agents and the integrated vector store operate locally within SkySQL, reducing the need to move sensitive data outside your database.</li> <li>Cost-Effective Scalability: Leverage SkySQL's serverless architecture for instant scaling and zero waste during idle times, optimizing costs.</li> <li>Seamless Integration: Designed to integrate with popular AI-powered development tools that support the Model Context Protocol (MCP).</li> </ul>"},{"location":"SkyCopilot%20Guide/MCP%20Server/#target-audience","title":"Target Audience","text":"<p>The SkySQL MCP Server is perfect for:</p> <ul> <li>Developers: Who want to build AI-powered applications that interact with databases using natural language, simplify SQL query generation, and streamline development workflows.</li> <li>Data Engineers: Looking for a streamlined way to connect various models, agents, and data systems with reduced integration complexity.</li> <li>Organizations: Aiming to leverage AI for more efficient, accurate, and secure operational data management without significant data migration or infrastructure changes.</li> </ul>"},{"location":"SkyCopilot%20Guide/MCP%20Server/#getting-started-with-skysqls-mcp-server","title":"Getting Started with SkySQL's MCP Server","text":"<p>It's easy to get up and running with the SkySQL MCP Server. Follow these simple steps to begin your journey:</p> <ol> <li> <p>Sign Up for SkySQL:     First, you'll need a SkySQL account to get your API key. Visit app.skysql.com to sign up. It only takes a few seconds, and we offer a forever-free developer serverless tier that requires no credit card.</p> </li> <li> <p>Deploy the MCP Server:     You have two main options for deploying the MCP Server:</p> <ul> <li>Via Smithery.ai (Recommended for ease of use):     Access the SkySQL MCP Server directly on Smithery.ai. Follow the instructions provided there to connect the server with popular AI IDEs such as Claude, Cursor, Windsurf, and others, using your API key. Smithery.ai makes the setup process much smoother.</li> <li>Via Our GitHub Repository:     Alternatively, the SkySQL MCP Server is also available on our GitHub repository. If you prefer a more manual setup, you can clone the repository and follow the instructions in its README.</li> </ul> </li> </ol> <p>Once your MCP Server is set up, you can start using SkyAI Agents.</p> <p>Checking this demo video for further info: SkySQL MCP Server Demo</p>"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/","title":"SkyAI Agent  API \u2013 User Guide","text":""},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#overview","title":"Overview","text":"<p>The SkyAI Agent API lets developers interact with AI agents built and hosted on the SkySQL platform. This API is perfect for embedding conversational AI experiences in your applications, dashboards, or internal tools \u2013 all without the need for complex LLM infrastructure or MLOps.</p>"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#authentication","title":"Authentication","text":"<p>To make requests to the API, you must authenticate using an API key.</p> <p>Steps:</p> <ol> <li> <p>Get an API Key</p> <ul> <li>Go to: SkySQL API Key Management</li> <li>Generate a new API key.</li> </ul> </li> <li> <p>Include the key in your request headers:</p> <pre><code>X-API-Key: YOUR_API_KEY\n</code></pre> </li> </ol>"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#maintaining-chat-sessions","title":"Maintaining Chat Sessions","text":"<p>The SkyAI Agent Session API allows you to initiate and manage conversational sessions with your SkyAI agents. Sessions are crucial for maintaining context across multiple interactions, which leads to more natural and coherent conversations with the agent.</p>"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#creating-a-session","title":"Creating a Session","text":"<ul> <li> <p>Endpoint:</p> <pre><code>POST https://api.skysql.com/copilot/v1/session\n</code></pre> </li> <li> <p>Headers:</p> <pre><code>Content-Type: application/json\nX-API-Key: YOUR_API_KEY\n</code></pre> </li> <li> <p>Request Body:</p> <pre><code>{\n  \"agent_id\": \"your-agent-id\",\n  \"metadata\": {\n    \"user_id\": \"optional-user-id\",\n    \"conversation_topic\": \"optional-topic\"\n  }\n}\n</code></pre> <ul> <li><code>agent_id</code> (string): The identifier of the SkyAI agent you want to talk to.</li> <li><code>metadata</code> (object, optional): Any additional information to associate with the session, like user identifiers or conversation topics.</li> </ul> </li> </ul> <p>Example using <code>curl</code>:</p> <pre><code>curl -X POST https://api.skysql.com/copilot/v1/session \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-API-Key: YOUR_API_KEY\" \\\n  -d '{\n        \"agent_id\": \"agent-12345\",\n        \"metadata\": {\n          \"user_id\": \"user-67890\",\n          \"conversation_topic\": \"monthly sales report\"\n        }\n      }'\n</code></pre>"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#response-structure","title":"Response Structure","text":"<p>A successful response will return a JSON object containing:</p> <ul> <li><code>session_id</code> (string): A unique identifier for the session that was created.</li> <li><code>agent_id</code> (string): The identifier of the agent associated with this session.</li> <li><code>created_at</code> (string): A timestamp indicating when the session was created.</li> </ul> <p>Example Response:</p> <pre><code>{\n  \"session_id\": \"session-abcde12345\",\n  \"agent_id\": \"agent-12345\",\n  \"created_at\": \"2025-05-21T18:37:00Z\"\n}\n</code></pre>"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#using-the-session","title":"Using the Session","text":"<p>Once you have a <code>session_id</code>, include it in all subsequent interactions with the agent to maintain context:</p> <ul> <li> <p>Chat Endpoint:</p> <pre><code>POST https://api.skysql.com/copilot/v1/chat\n</code></pre> </li> <li> <p>Request Body:</p> <pre><code>{\n  \"prompt\": \"Your question here\",\n  \"session_id\": \"session-abcde12345\"\n}\n</code></pre> </li> </ul> <p>Maintaining the same <code>session_id</code> across multiple requests lets the agent remember previous interactions, leading to more coherent conversations.</p>"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#error-handling","title":"Error Handling","text":"<p>If your request is invalid or unauthorized, you might receive error responses such as:</p> <ul> <li>401 Unauthorized: Missing or invalid API key.</li> <li>400 Bad Request: Malformed request syntax or missing required fields.</li> <li>500 Internal Server Error: An error occurred on the server.</li> </ul> <p>Always ensure your API key is valid and your request body is correctly formatted.</p>"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#tips-for-effective-use-of-sessions","title":"Tips for Effective Use of Sessions","text":"<ul> <li>Session Management: Use the same <code>session_id</code> for a series of related interactions to keep the conversation flowing.</li> <li>Metadata Usage: Leverage the <code>metadata</code> field to store relevant information that can help the agent provide more personalized responses.</li> <li>Session Termination: Implement logic in your application to end sessions when they're no longer needed, which helps free up resources.</li> </ul>"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#making-a-chat-request","title":"Making a Chat  Request","text":"<p>The  Chat API allows you to send natural language prompts to a SkyAI agent and receive structured responses, including generated SQL and data results when applicable. It supports both stateless and multi-turn conversational use cases and lets you pass agent-specific configuration such as table filters to control the context of the response.</p> <p>The optional config object allows you to customize how the agent accesses and filters data during query generation. This is especially useful for enforcing data policies, scoping context, or running controlled experiments.</p> <p>IMPORTANT: You can use this API on its own for single interactions, or in conjunction with the Session API to maintain context across multi-turn conversations with the same agent.   * Endpoint:</p> <pre><code>```\nPOST https://api.skysql.com/copilot/v1/chat\n```\n</code></pre> <ul> <li> <p>Headers:</p> <pre><code>Content-Type: application/json\nX-API-Key: YOUR_API_KEY\n</code></pre> </li> <li> <p>Request Body:</p> <pre><code>{\n  \"prompt\": \"Your natural language question\",\n  \"agent_id\": \"your agent id\",\n  \"session_id\": \"optional-session-id\",\n  \"config\": {\n    \"table_filter\": {\n      \"table\":\"column=value\"\n    }\n  }\n}\n</code></pre> <ul> <li><code>prompt</code> (string): Your question to the SkyAI agent.</li> <li><code>agent_id</code> (string): The UUID of the SkyAI agent to query</li> <li><code>session_id</code> (string, optional): Use this to maintain    conversational context across turns.</li> <li><code>config</code> (object, optional): Configuration to pass contextual filters (e.g., row-level security, scope)</li> <li><code>table_filters</code> (object,optional): Key-value pairs where the key is a table name, and the value is a SQL WHERE clause to apply automatically</li> </ul> </li> </ul> <p>Example using <code>curl</code>:</p> <pre><code>curl -X POST https://api.skysql.com/copilot/v1/chat \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-API-Key: YOUR_API_KEY\" \\\n  -d '{\n        \"prompt\": \"What was the total revenue last quarter for the enterprise division?\",\n        \"session_id\": \"session-4567\",\n        \"agent_id\": \"your-agent-id\",\n        \"config\": {\n          \"table_filters\": {\n            \"sales\": \"division = '\\''enterprise'\\'' AND order_date &gt;= '\\''2024-10-01'\\'' AND order_date &lt;= '\\''2024-12-31'\\''\"\n          }\n        }\n      }'\n  ```\n\n-----\n\n## Response Format\n\nA successful response returns a structured JSON object:\n\n  * `response`: The agent's natural language reply.\n  * `sql`: (if applicable) The SQL generated by the agent to answer the question.\n  * `data`: Structured data returned (if relevant).\n  * `session_id`: Echoes your session ID, to help manage stateful interactions.\n\n**Example Response:**\n\n```json\n{\n  \"response\": \"Here are the top 5 products by revenue last month.\",\n  \"sql\": \"SELECT product_name, SUM(revenue) FROM sales WHERE date &gt;= '2024-04-01' AND date &lt;= '2024-04-30' GROUP BY product_name ORDER BY SUM(revenue) DESC LIMIT 5;\",\n  \"data\": [\n    { \"product_name\": \"Widget A\", \"revenue\": 124000 },\n    { \"product_name\": \"Widget B\", \"revenue\": 115000 }\n  ],\n  \"session_id\": \"session-4567\"\n}\n</code></pre>"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#error-handling_1","title":"Error Handling","text":"Code Meaning Explanation 401 Unauthorized Missing or invalid API key 400 Bad Request Malformed request syntax 500 Internal Server Error Something went wrong on the backend"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#best-practices","title":"Best Practices","text":"<ul> <li>Use <code>session_id</code> to maintain conversation context across multiple prompts.</li> <li>Check the <code>sql</code> output if you\u2019re debugging or want insight into how the agent is reasoning.</li> <li>Use clear, specific language in your prompts for optimal results.</li> <li>Validate <code>data</code> before injecting it into your UI or downstream services.</li> </ul>"},{"location":"SkyCopilot%20Guide/SkyAI%20API%20Guide/#useful-links","title":"Useful Links","text":"<ul> <li>API Reference: SkyAI Agent API Docs</li> <li>SkySQL Console: SkySQL Portal</li> </ul>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/","title":"Using AWS/Azure/GCP private VPC connections","text":"<p>By default, connections to SkySQL cloud databases occur with TLS/SSL encryption and can be initiated only from allowlisted IP addresses.</p> <p>Some customers have regulatory requirements or information security policies that prohibit database connections over the public internet, and result in a requirement for private connections.</p> <p>SkySQL cloud databases can optionally be configured for private connections between your VPC (virtual private clouds) and SkySQL cloud databases:</p> <ul> <li>AWS PrivateLink is supported for SkySQL cloud databases on AWS</li> <li>Azure PrivateLink is supported for SkySQL cloud databases on Azure</li> <li>Private Service Connect is supported for SkySQL cloud databases on GCP</li> </ul>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20AWS%20Private%20Link/","title":"Setting up AWS Private Link","text":"<p>AWS PrivateLink is an AWS service that enables secure and private connectivity between Virtual Private Clouds (VPCs) and third-party services. By using PrivateLink with SkySQL services, traffic does not traverse the public internet, which enhances security and reduces exposure to potential threats.</p> <p>For detailed information about AWS PrivateLink, see\u00a0\"AWS PrivateLink\" (Amazon documentation).</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20AWS%20Private%20Link/#considerations","title":"Considerations","text":"<ul> <li>AWS PrivateLink is used for private connections within the same AWS region.  The SkySQL service and the connection VPC must be in the same region.</li> <li>When using SkySQL with AWS PrivateLink, all connections occur through private endpoints.  If you need to connect to the service from outside your VPC, you will need to use a VPN or other mechanism to go through the connected VPC.  Alternatively, SkySQL can be configured to provide a second, public endpoint for an additional fee.</li> <li>A list of AWS Account IDs that will be allowed to connect to the SkySQL service must be provided when enabling AWS PrivateLink.  This list can be updated at any time.</li> <li>The SkySQL IP Allowlist is not used with AWS PrivateLink connections.  Access to the SkySQL service will be controlled by Security Groups in the connecting VPC. For detailed information, see\u00a0\"Control traffic to resources using security groups\"\u00a0(Amazon documentation).</li> <li>Connections to SkySQL services by features such as SkySQL backups, and monitoring do not depend on AWS PrivateLink.</li> <li>Query Editor is not supported when AWS PrivateLink is enabled.</li> </ul>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20AWS%20Private%20Link/#enable-aws-privatelink-on-service-launch","title":"Enable AWS PrivateLink on Service Launch","text":"Enable Privatelink via the SkySQL Portal   To enable AWS PrivateLink when launching a new service via the SkySQL Portal select the 'Enable Private link' option in the 'Security' section. After the service completes provisioning, you will see a new option to \"Set up Private Link\" in the service's context menu. Click this option to add one or more AWS account IDs to the allowlist.   Enable Privatelink via the SkySQL DBaaS API   To enable AWS PrivateLink when launching a new service via the SkySQL DBaaS API, add the\u00a0`endpoint_mechanism`\u00a0and\u00a0`endpoint_allowed_accounts`\u00a0attributes to service creation JSON payload.  <pre><code>{\n  \"name\": \"my-skysql-service\",\n  ...\n  \"endpoint_mechanism\": \"privateconnect\",\n  \"allowed_accounts\": [\n    \"AWS-ACCOUNT-ID-1\",\n    \"AWS-ACCOUNT-ID-2\"\n  ]\n}\n</code></pre> - The `endpoint_mechanism` field must be set to `privateconnect` - The `endpoint_allowed_accounts` field must be set to a JSON array of one or more customer account IDs in AWS that will be allowed to establish a private connection to the SkySQL service.  For more information on using the SkySQL DBaaS API, see\u00a0[\"SkySQL DBaaS API\"](https://apidocs.skysql.com/#/Services/post_provisioning_v1_services).  Enable Privatelink via the SkySQL Terraform Provider   To enable AWS PrivateLink when launching a new service via the SkySQL DBaaS API, set the\u00a0`endpoint_mechanism`\u00a0and\u00a0`endpoint_allowed_accounts` attributes on the `skysql_service` resource.  <pre><code>resource \"skysql_service\" \"example\" {\n  name                      = \"my-skysql-service\"\n  ...\n  endpoint_mechanism        = \"privateconnect\"\n  endpoint_allowed_accounts = [\"123456789012\"]\n}\n</code></pre>  - The `endpoint_mechanism` field must be set to `privateconnect` - The `endpoint_allowed_accounts` field must be set to a list of one or more customer account IDs in AWS that will be allowed to establish a private connection to the SkySQL service.  A complete example Terraform template that creates a new SkySQL service with AWS PrivateLink enabled can be found in the\u00a0[terraform provider examples](https://github.com/skysqlinc/terraform-provider-skysql/tree/main/examples/privateconnect).   For more information on using the SkySQL Terraform Provider, see\u00a0[\"SkySQL Terraform Provider\"](https://registry.terraform.io/providers/skysqlinc/skysql/latest/docs).   <p>For the next step, see the\u00a0AWS Endpoint Setup\u00a0section on this page.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20AWS%20Private%20Link/#enable-aws-privatelink-on-an-existing-skysql-service","title":"Enable AWS PrivateLink on an Existing SkySQL Service","text":"<p>[!CAUTION] Enabling PrivateLink on an existing service will cause all existing connections to be dropped.  The service will be unavailable for a short period of time while the public endpoint is replaced with the new PrivateLink endpoint.</p> Enable AWS PrivateLink on an existing service via the SkySQL Portal:   1. Log in to the\u00a0SkySQL Portal 2. Click the \"MANAGE\" button (on the right) for the desired service. 3. In the context menu, choose the \"Set up AWS PrivateLink\" menu item. 4. In the popup window, add one or more AWS account IDs. 5. Click the \"OK\" button to confirm this operation.   Enable AWS PrivateLink on an existing service via the SkySQL DBaaS API:   To enable AWS PrivateLink on an existing service, you will need to update the service endpoints with a payload similar to the following:  <pre><code>[\n  {\n    \"mechanism\": \"privateconnect\",\n    \"allowed_accounts\": [\n      \"AWS-ACCOUNT-ID-1\",\n      \"AWS-ACCOUNT-ID-2\"\n    ]\n  }\n]\n</code></pre>  This payload should then be sent to the API `PATCH` https://api.skysql.com/provisioning/v1/services/{SERVICE_ID}/endpoints where `{SERVICE_ID}` is the ID of the service you are updating. For more information on using the SkySQL DBaaS API, see\u00a0[\"SkySQL DBaaS API\"](https://apidocs.skysql.com/#/Services/patch_provisioning_v1_services__service_id__endpoints).   <p>For the next step, see the\u00a0AWS Endpoint Setup\u00a0section on this page.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20AWS%20Private%20Link/#aws-endpoint-setup","title":"AWS Endpoint Setup","text":"<p>To connect to a SkySQL service using AWS PrivateLink, you must create an endpoint in your VPC that connects to the SkySQL service. The endpoint will be used by clients in your VPC to connect to the SkySQL service.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20AWS%20Private%20Link/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>You must have a VPC in the same region as the SkySQL service.</li> <li>You must create a security group that will be used to control access to the SkySQL service endpoint.<ul> <li>This security group should contain rules to allow traffic from your client instances to the port of the SkySQL service (usually 3306).</li> <li>You must create a rule in your security group for each IP range or other security group that will be allowed to connect to the SkySQL service.</li> <li>The security group must be associated with the VPC that you will use to connect to the SkySQL service.</li> </ul> </li> <li>You will need to lookup the Endpoint Service ID that SkySQL provisioned for you when you created your SkySQL Service.<ul> <li>This ID can be found in the \"Connect\" window of the SkySQL portal.</li> <li>If using the SkySQL DBaaS API, the ID can be found in the response of the service details API call. <pre><code>curl https://api.skysql.com/provisioning/v1/services/{SERVICE_ID} | jq \".endpoints[0].endpoint_service\"\n</code></pre></li> </ul> </li> </ul>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20AWS%20Private%20Link/#vpc-endpoint-creation-steps","title":"VPC Endpoint Creation Steps","text":"<ol> <li>Log in to the AWS console.</li> <li>Confirm the correct region is selected.</li> <li>Navigate to the \"VPC\" page, then the \"Endpoints\" section.</li> <li>Click the \"Create Endpoint\" button.</li> <li>In the \"Name tag\" field, enter a name for the new endpoint. This name can be anything you like.</li> <li>Set the Service category to \"Other endpoint services\".</li> <li>The value for the \"Service name\" field must be set to the value of the\u00a0Endpoint Service ID provided to you by SkySQL. See Pre-requisites for more information on how to find this ID.</li> <li>Click \"Verify service\". AWS should find the service and auto-populate the rest of the form.</li> <li>In the VPC search field, find the VPC that you want to use for the interconnect between the clients and the SkySQL service.</li> <li>In the Subnets section, it is suggested that you select all the Availability Zones in the list, entering the proper subnet ID for each one. If you are unsure, view the details of your running instances to see the Subnet ID that they have configured.</li> <li>Select IPv4 for \"IP address type\".</li> <li>For the \"Security Groups\" section, assign the security groups that will allow your client instance to connect to your VPC endpoint.  See Pre-requisites for more information on setting up security groups.</li> <li>Press the \"Create endpoint\" button. Endpoint creation may take several minutes. When complete, status will change from \"Pending\" to \"Available\".</li> </ol> <p>After creation, the Endpoint will be in <code>Pending</code> status while AWS provisions the new endpoint.  Once the endpoint is <code>Available</code>, you can connect to your SkySQL service using the new endpoint. The newly created endpoint now authorizes the internal IPs or security groups that you specified in the Source values to access the SkySQL service's connection port. When testing a client connection, ensure that the client host is authorized by the security group's Source settings and that you're using the \"<code>readwrite</code>\" port plus the appropriate username and password (either the default values or the value for any user you have created).</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20AWS%20Private%20Link/#connecting-to-your-skysql-service","title":"Connecting to your SkySQL Service","text":"<p>After creating your VPC endpoint, AWS will create a number of DNS records that will resolve to the private IP addresses of your Privatelink Endpoint. - The first DNS name in the list can be used from any availability zone in your VPC and will resolve to the private IP address of the endpoint in the same availability zone. - The following DNS names provided are availability zone specific and rely on the user to match the correct DNS name to the availability zone of the client instance. - If connecting via these DNS names, we recommend using the first DNS name in the list to ensure that the connection is routed to the correct availability zone.</p> <p>[!NOTE] The DNS names provided by AWS will always be in the domain <code>amazonaws.com</code>.  If connecting to your SkySQL service using SSL/TLS, the database certificate will not match the VPC endpoint name.  Due to this, we recommend Enabling Private DNS for AWS PrivateLink.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20AWS%20Private%20Link/#enabling-private-dns-for-aws-privatelink","title":"Enabling Private DNS for AWS PrivateLink","text":"<p>In order to connect to your SkySQL service using the skysql.com service name provided in the SkySQL portal, you must enable Private DNS for the VPC endpoint.  This will allow the service name to resolve to the private IP address of the SkySQL service.</p> <p>The following requirements must be met to enable Private DNS for the VPC endpoint: - Private DNS must be enabled for the VPC. - Your client instances must use the default AWS DNS server provided by the VPC (this is usually turned on by default).</p> <p>To enable Private DNS for the VPC endpoint: 1. Log in to the AWS console. 2. Confirm the correct region is selected. 3. Navigate to the \"VPC\" page, then the \"Endpoints\" section. 4. Select the VPC endpoint that you created for your SkySQL service. 5. Click the \"Actions\" button, then select \"Modify Private DNS Name\". 6. In the popup window, select the checkbox to \"Enable Private DNS Name\". 7. Click the \"Save changes\" button.</p> <p>After a short period of time, the service name provided in the SkySQL portal should resolve to the private IP address of the SkySQL service via PrivateLink.  You can test this by connecting to the service using the service name provided in the portal.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20AWS%20Private%20Link/#disabling-aws-privatelink","title":"Disabling AWS PrivateLink","text":"<p>[!CAUTION] Disabling PrivateLink on an existing service will cause all existing connections to be dropped.  The service will be unavailable for a short period of time while the private endpoint is replaced with the new public endpoint.</p> Disable AWS PrivateLink via the SkySQL Portal   1. Visit the\u00a0[SkySQL Portal](https://app.skysql.com/) 2. Find the service that you would like to modify. 3. Click \"MANAGE\" on the far right side of the service listing. 4. In the context menu, select \"Manage PrivateLink\". 5. In the popup window, click \"I want to disconnect my Private Link\". 6. In the popup window, select \"Disconnect\". 7. Since the service's allowlist was cleared when AWS PrivateLink was previously enabled, you will need to\u00a0[update the allowlist](../Security/Configuring%20Firewall.md) to allow clients to connect after disabling PrivateLink.   Disable AWS PrivateLink via the SkySQL DBaaS API   To disable AWS PrivateLink on an existing service, you will need to update the service endpoints with a payload similar to the following:  <pre><code>[\n  {\n    \"mechanism\": \"nlb\"\n  }\n]\n</code></pre>  This payload should then be sent to the API `PATCH` https://api.skysql.com/provisioning/v1/services/{SERVICE_ID}/endpoints where `{SERVICE_ID}` is the ID of the service you are updating. For more information on using the SkySQL DBaaS API, see\u00a0[\"SkySQL DBaaS API\"](https://apidocs.skysql.com/#/Services/patch_provisioning_v1_services__service_id__endpoints)."},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20Azure%20Private%20Link/","title":"Setting up Azure Private Link","text":"<p>Azure Private Link is an Azure service that enables secure and private connectivity between Virtual Networks (VNet) and third-party services. By using Private Link with SkySQL services, traffic does not traverse the public internet, which enhances security and reduces exposure to potential threats.</p> <p>For detailed information about Azure Private Link, see\u00a0\"Azure Private Link\" (Azure documentation).</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20Azure%20Private%20Link/#considerations","title":"Considerations","text":"<ul> <li>Azure Private Link is used for private connections within the same Azure region.  The SkySQL service and the connecting VNet must be in the same region.</li> <li>When using SkySQL with Azure Private Link, all connections occur through private endpoints.  If you need to connect to the service from outside your VNET, you will need to use a VPN or other mechanism to go through the connected VNet.  Alternatively, SkySQL can be configured to provide a second, public endpoint for an additional fee.</li> <li>A list of Azure Subscription IDs that will be allowed to connect to the SkySQL service must be provided when enabling Azure Private Link.  This list can be updated at any time.</li> <li>The SkySQL IP Allowlist is not used with Azure Private Link connections.  Access to the SkySQL service will be controlled by Security Groups in the connecting VNet. For detailed information, see\u00a0\"Manage network policies for private endpoints\"\u00a0(Azure documentation).</li> <li>Connections to SkySQL services by features such as SkySQL backups, and monitoring do not depend on Azure Private Link.</li> <li>The IP address of the SkySQL service will be a private IP address in the range of the VNet that the Private Link endpoint is created in.  Because of this, SSL certificates will not match the IP address of the service.  To avoid this issue, you can either disable SSL on the SkySQL service, or setup Private DNS within your Azure VNet. See \"Enabling DNS for Azure Private Link\" for more information.</li> <li>Query Editor is not supported when Azure Private Link is enabled.</li> </ul>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20Azure%20Private%20Link/#enable-azure-private-link-on-service-launch","title":"Enable Azure Private Link on Service Launch","text":"Enable Private Link via the SkySQL Portal   To enable Azure Private Link when launching a new service via the SkySQL Portal select the 'Enable Private link' option in the 'Security' section. After the service completes provisioning, you will see a new option to \"Set up Private Link\" in the service's context menu. Click this option to add one or more Azure Subscription IDs to the allowlist.   Enable Private Link via the SkySQL DBaaS API   To enable Azure Private Link when launching a new service via the SkySQL DBaaS API, add the\u00a0`endpoint_mechanism`\u00a0and\u00a0`endpoint_allowed_accounts`\u00a0attributes to service creation JSON payload.  <pre><code>{\n  \"name\": \"my-skysql-service\",\n  ...\n  \"endpoint_mechanism\": \"privateconnect\",\n  \"allowed_accounts\": [\n    \"AZURE-SUBSCRIPTION-ID-1\",\n    \"AZURE-SUBSCRIPTION-ID-2\"\n  ]\n}\n</code></pre> - The `endpoint_mechanism` field must be set to `privateconnect` - The `endpoint_allowed_accounts` field must be set to a JSON array of one or more customer subscription IDs in Azure that will be allowed to establish a private connection to the SkySQL service.  These IDs should be in the guid format.  For more information on using the SkySQL DBaaS API, see\u00a0[\"SkySQL DBaaS API\"](https://apidocs.skysql.com/#/Services/post_provisioning_v1_services).  Enable Private Link via the SkySQL Terraform Provider   To enable Azure Private Link when launching a new service via the SkySQL DBaaS API, set the\u00a0`endpoint_mechanism`\u00a0and\u00a0`endpoint_allowed_accounts` attributes on the `skysql_service` resource.  <pre><code>resource \"skysql_service\" \"example\" {\n  name                      = \"my-skysql-service\"\n  ...\n  endpoint_mechanism        = \"privateconnect\"\n  endpoint_allowed_accounts = [\"123456789012\"]\n}\n</code></pre>  - The `endpoint_mechanism` field must be set to `privateconnect` - The `endpoint_allowed_accounts` field must be set to a list of one or more customer subscription IDs in Azure that will be allowed to establish a private connection to the SkySQL service.  These IDs should be in the guid format.  A complete example Terraform template that creates a new SkySQL service with Azure Private Link enabled can be found in the\u00a0[terraform provider examples](https://github.com/skysqlinc/terraform-provider-skysql/tree/main/examples/azure-private-link).   For more information on using the SkySQL Terraform Provider, see\u00a0[\"SkySQL Terraform Provider\"](https://registry.terraform.io/providers/skysqlinc/skysql/latest/docs).   <p>For the next step, see the\u00a0Azure Endpoint Setup\u00a0section on this page.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20Azure%20Private%20Link/#enable-azure-private-link-on-an-existing-skysql-service","title":"Enable Azure Private Link on an Existing SkySQL Service","text":"<p>[!CAUTION] Enabling Private Link on an existing service will cause all existing connections to be dropped.  The service will be unavailable for a short period of time while the public endpoint is replaced with the new Private Link endpoint.</p> Enable Azure Private Link on an existing service via the SkySQL Portal:   1. Log in to the\u00a0SkySQL Portal 2. Click the \"MANAGE\" button (on the right) for the desired service. 3. In the context menu, choose the \"Set up Azure Private Link\" menu item. 4. In the popup window, add one or more Azure account IDs. 5. Click the \"OK\" button to confirm this operation.   Enable Azure Private Link on an existing service via the SkySQL DBaaS API:   To enable Azure Private Link on an existing service, you will need to update the service endpoints with a payload similar to the following:  <pre><code>[\n  {\n    \"mechanism\": \"privateconnect\",\n    \"allowed_accounts\": [\n      \"AZURE-SUBSCRIPTION-ID-1\",\n      \"AZURE-SUBSCRIPTION-ID-2\"\n    ]\n  }\n]\n</code></pre>  This payload should then be sent to the API `PATCH` https://api.skysql.com/provisioning/v1/services/{SERVICE_ID}/endpoints where `{SERVICE_ID}` is the ID of the service you are updating. For more information on using the SkySQL DBaaS API, see\u00a0[\"SkySQL DBaaS API\"](https://apidocs.skysql.com/#/Services/patch_provisioning_v1_services__service_id__endpoints).   <p>For the next step, see the\u00a0Azure Endpoint Setup\u00a0section on this page.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20Azure%20Private%20Link/#azure-endpoint-setup","title":"Azure Endpoint Setup","text":"<p>To connect to a SkySQL service using Azure Private Link, you must create an endpoint in your VNet that connects to the SkySQL service. The endpoint will be used by clients in your VNet to connect to the SkySQL service.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20Azure%20Private%20Link/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>You must have a Virtual Network in the same region as the SkySQL service.</li> <li>You will need to look up the Endpoint Service ID that SkySQL provisioned for you when you created your SkySQL Service.<ul> <li>This ID can be found in the \"Connect\" window of the SkySQL portal.</li> <li>This ID references the \"Alias\" field of the Azure created Private Link service.</li> <li>If using the SkySQL DBaaS API, the ID can be found in the response of the service details API call. <pre><code>curl https://api.skysql.com/provisioning/v1/services/{SERVICE_ID} \\\n     | jq \".endpoints[0].endpoint_service\"\n</code></pre></li> </ul> </li> </ul>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20Azure%20Private%20Link/#private-link-endpoint-creation-steps","title":"Private Link Endpoint Creation Steps","text":"<ol> <li>Log in to the Azure console.</li> <li>Navigate to the \"Private Link\" page, then the \"Private endpoints\" section.</li> <li>The easiest way to get here is to enter \"Private Link\" in the search bar at the top of the Azure console and then select \"Private endpoints\" on the left navigation bar.</li> <li>Click the \"Create\" button on the \"Private Link Center | Private endpoints\" page.</li> <li>In the \"Basics\" tab, update the following:</li> <li>Subscription: Select the subscription that contains the VNet you want to use.</li> <li>Resource group: Select the resource group that will host the Private Link endpoint.</li> <li>Name: Enter a name for the Private Link endpoint.  This can be anything you like.</li> <li>Network Interface Name: Enter a name for the network interface or leave the default value.</li> <li>Region: Select the region where the Virtual Network and the SkySQL service are located.</li> <li>Click the \"Next: Resource\" button.</li> <li>In the \"Resource\" tab, update the following:</li> <li>Connection Method: \"Connect to an Azure resource by resource ID or alias.\"</li> <li>Resource ID or alias: Enter the value of the Endpoint Service ID provided to you by SkySQL.  See Pre-requisites for more information on how to find this ID.</li> <li>You should see a little green check mark in the \"Resource ID or alias\" field if the value is correct.</li> <li>Request message: You can leave this blank as SkySQL will automatically approve connections from your allowlisted Azure Subscription.</li> <li>Click the \"Next: Virtual Network\" button.</li> <li>In the \"Virtual Network\" tab, update the following:</li> <li>Virtual Network: Select the VNet that you want to use to connect to the SkySQL service.</li> <li>Subnet: Select the subnet within the VNet that you want to use to connect to the SkySQL service.  Any service that will connect to the SkySQL service must be able to route to this subnet.</li> <li>Click the \"Next: DNS\" button.</li> <li>Leave this section as the default settings.</li> <li>Click the \"Next: Tags\" button.</li> <li>You can add any tags that you wish to help identify the endpoint.  This is completely optional.</li> <li>Click the \"Review + create\" button.</li> <li>After reviewing the settings, click the \"Create\" button.</li> </ol> <p>After creation, Azure will begin provisioning the new Endpoint.  Once the provisioning is complete, you can inspect the details of your newly created endpoint by clicking the \"Go to Resource\" button, or by navigating again to the \"Private Link Center | Private endpoints\" page. On the details page, you will see a link to the \"Network Interface\" that was created for the endpoint.  This network interface will have a private IP address that you can use to connect to the SkySQL service.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20Azure%20Private%20Link/#connecting-to-your-skysql-service","title":"Connecting to your SkySQL Service","text":"<p>After creating your Private Link endpoint, you will need to find the IP address associated with that endpoint.  This IP address can be found in the properties of the network interface that was created for the endpoint. - The hostname when connecting to your SkySQL service should always be the Private IP address of the Private Endpoint. - The SSL certificate provided by SkySQL will not match the IP address of the service.  To avoid this issue, you can either disable SSL on the SkySQL service, or setup Private DNS within your Azure VNet. See \"Enabling DNS for Azure Private Link\" for more information.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20Azure%20Private%20Link/#enabling-private-dns-for-azure-private-link","title":"Enabling Private DNS for Azure Private Link","text":"<p>Enabling Private DNS for Azure Private Link is optional.  However, if you wish to use a verified SSL connection to the SkySQL service, you will need to create a Private DNS record in your Azure account that maps the service name provided by SkySQL to the private IP address of the Private Link endpoint.</p> <p>The following links will help guide you through the process of setting up Private DNS in Azure: - Creating a Private DNS Zone in Microsoft Azure - Linking a Private DNS Zone to a Virtual Network - Adding DNS Records to a Private DNS Zone</p> <p>[!CAUTION] When linking a DNS zone for your skysql.com domain, you will delegate all DNS resolution for that domain to Azure.  This means that all DNS queries for that domain will be resolved by Azure DNS servers.  If you have other public services that use the same domain, these hostnames will no longer resolve to services inside your linked VNet.</p> <p>Since Private DNS setup is a complex process, we have provided a terraform example that can help with the process.  We highly advise that you explore this example if your organization requires this type of setup. The example can be found in the\u00a0terraform provider examples</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20Azure%20Private%20Link/#disabling-azure-private-link","title":"Disabling Azure Private Link","text":"<p>[!CAUTION] Disabling Private Link on an existing service will cause all existing connections to be dropped.  The service will be unavailable for a short period of time while the private endpoint is replaced with the new public endpoint.</p> Disable Azure Private Link via the SkySQL Portal   1. Visit the\u00a0[SkySQL Portal](https://app.skysql.com/) 2. Find the service that you would like to modify. 3. Click \"MANAGE\" on the far right side of the service listing. 4. In the context menu, select \"Manage Private Link\". 5. In the popup window, click \"I want to disconnect my Private Link\". 6. In the popup window, select \"Disconnect\". 7. Since the service's allowlist was cleared when Azure Private Link was previously enabled, you will need to\u00a0[update the allowlist](../Security/Configuring%20Firewall.md) to allow clients to connect after disabling Private Link.   Disable Azure Private Link via the SkySQL DBaaS API   To disable Azure Private Link on an existing service, you will need to update the service endpoints with a payload similar to the following:  <pre><code>[\n  {\n    \"mechanism\": \"nlb\"\n  }\n]\n</code></pre>  This payload should then be sent to the API `PATCH` https://api.skysql.com/provisioning/v1/services/{SERVICE_ID}/endpoints where `{SERVICE_ID}` is the ID of the service you are updating. For more information on using the SkySQL DBaaS API, see\u00a0[\"SkySQL DBaaS API\"](https://apidocs.skysql.com/#/Services/patch_provisioning_v1_services__service_id__endpoints)."},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20GCP%20Private%20Service%20Connect/","title":"Setting up GCP Private Service Connect","text":"<p>Google Private Service Connect (PSC) is a Google Cloud service that enables secure and private connectivity between Virtual Private Clouds (VPCs) and third-party services. By using PSC with SkySQL services, traffic does not traverse the public internet, which enhances security and reduces exposure to potential threats.</p> <p>For detailed information about Google PSC, see \"Private Service Connect\" (Google documentation).</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20GCP%20Private%20Service%20Connect/#considerations","title":"Considerations","text":"<ul> <li>PSC is used for private connections within the same Google Cloud region.  The SkySQL service and the connection VPC must be in the same region.</li> <li>When using SkySQL with PSC, all connections occur through private endpoints.  If you need to connect to the service from outside your VPC, you will need to use a VPN or other mechanism to go through the connected VPC.  Alternatively, SkySQL can be configured to provide a second, public endpoint for an additional fee.</li> <li>A list of Google Cloud project IDs that will be allowed to connect to the SkySQL service must be provided when enabling PSC.  This list can be updated at any time.</li> <li>The SkySQL IP Allowlist is not used with PSC connections.  Access to the SkySQL service can be controlled by setting up firewall rules inside the connecting VPC.</li> <li>Connections to SkySQL services by features such as SkySQL backups, and monitoring do not depend on PSC.</li> <li>Query Editor is not supported when PSC is enabled.</li> <li>PSC has connection limits which refer to the number of endpoints that can be created to a single PSC service within Google Cloud. Database connection limits are independent from PSC connection limits. The limit for PSC connections is 10.</li> </ul>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20GCP%20Private%20Service%20Connect/#enable-private-service-connect-on-service-launch","title":"Enable Private Service Connect on Service Launch","text":"Enable Google PSC via the SkySQL Portal   To enable PSC when launching a new service via the SkySQL Portal select the 'Google Private Service Connect' option in the 'Security' section. After the service completes provisioning, you will see a new option to \"Manage Google Private Service Connect\" in the service's context menu. Click this option to add one or more Google project IDs to the allowlist.   Enable Google PSC via the SkySQL DBaaS API   To enable Google PSC when launching a new service via the SkySQL DBaaS API, add the\u00a0`endpoint_mechanism`\u00a0and\u00a0`endpoint_allowed_accounts`\u00a0attributes to service creation JSON payload.  <pre><code>{\n  \"name\": \"my-skysql-service\",\n  ...\n  \"endpoint_mechanism\": \"privateconnect\",\n  \"allowed_accounts\": [\n    \"GCP-PROJECT-ID-1\",\n    \"GCP-PROJECT-ID-2\"\n  ]\n}\n</code></pre> - The `endpoint_mechanism` field must be set to `privateconnect` - The `endpoint_allowed_accounts` field must be set to a JSON array of one or more client project IDs in Google Cloud that will be allowed to establish a private connection to the SkySQL service.  For more information on using the SkySQL DBaaS API, see\u00a0[\"SkySQL DBaaS API\"](https://apidocs.skysql.com/#/Services/post_provisioning_v1_services).  Enable Google PSC via the SkySQL Terraform Provider   To enable Google PSC when launching a new service via the SkySQL DBaaS API, set the\u00a0`endpoint_mechanism`\u00a0and\u00a0`endpoint_allowed_accounts` attributes on the `skysql_service` resource.  <pre><code>resource \"skysql_service\" \"example\" {\n  name                      = \"my-skysql-service\"\n  ...\n  endpoint_mechanism        = \"privateconnect\"\n  endpoint_allowed_accounts = [\"GCP-PROJECT-ID-1\", \"GCP-PROJECT-ID-2\"]\n}\n</code></pre>  - The `endpoint_mechanism` field must be set to `privateconnect` - The `endpoint_allowed_accounts` field must be set to a list of one or more customer project IDs in Google Cloud that will be allowed to establish a private connection to the SkySQL service.  A complete example Terraform template that creates a new SkySQL service with Google PSC enabled can be found in the\u00a0[terraform provider examples](https://github.com/skysqlinc/terraform-provider-skysql/tree/main/examples/private-service-connect).   For more information on using the SkySQL Terraform Provider, see\u00a0[\"SkySQL Terraform Provider\"](https://registry.terraform.io/providers/skysqlinc/skysql/latest/docs).   <p>For the next step, see the\u00a0PSC Endpoint Setup\u00a0section on this page.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20GCP%20Private%20Service%20Connect/#enable-google-psc-on-an-existing-skysql-service","title":"Enable Google PSC on an Existing SkySQL Service","text":"<p>[!CAUTION] Enabling PSC on an existing service will cause all existing connections to be dropped.  The service will be unavailable for a short period of time while the public endpoint is replaced with the new PSC endpoint.</p> Enable Google PSC on an existing service via the SkySQL Portal:   1. Log in to the\u00a0SkySQL Portal 2. Click the \"MANAGE\" button (on the right) for the desired service. 3. In the context menu, choose the \"Set up Google Private Service Connect\" menu item. 4. In the popup window, add one or more GCP project IDs. 5. Click the \"OK\" button to confirm this operation.   Enable Google PSC on an existing service via the SkySQL DBaaS API:   To enable Google PSC on an existing service, you will need to update the service endpoints with a payload similar to the following:  <pre><code>[\n  {\n    \"mechanism\": \"privateconnect\",\n    \"allowed_accounts\": [\n      \"GOOGLE-PROJECT-ID-1\",\n      \"GOOGLE-PROJECT-ID-2\"\n    ]\n  }\n]\n</code></pre>  This payload should then be sent to the API `PATCH` https://api.skysql.com/provisioning/v1/services/{SERVICE_ID}/endpoints where `{SERVICE_ID}` is the ID of the service you are updating. For more information on using the SkySQL DBaaS API, see\u00a0[\"SkySQL DBaaS API\"](https://apidocs.skysql.com/#/Services/patch_provisioning_v1_services__service_id__endpoints).   <p>For the next step, see the\u00a0PSC Endpoint Setup\u00a0section on this page.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20GCP%20Private%20Service%20Connect/#private-service-connect-endpoint-setup","title":"Private Service Connect Endpoint Setup","text":"<p>To connect to a SkySQL service using Google PSC, you must create an endpoint in your VPC that connects to the SkySQL service. The endpoint will be used by clients in your VPC to connect to the SkySQL service.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20GCP%20Private%20Service%20Connect/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>You must have a VPC in the same region as the SkySQL service.</li> <li>You will need to lookup the Endpoint Service ID that SkySQL provisioned for you when you created your SkySQL Service.<ul> <li>This ID can be found in the \"Connect\" window of the SkySQL portal.</li> <li>If using the SkySQL DBaaS API, the ID can be found in the response of the service details API call. <pre><code>curl https://api.skysql.com/provisioning/v1/services/{SERVICE_ID} | jq \".endpoints[0].endpoint_service\"\n</code></pre></li> </ul> </li> </ul>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20GCP%20Private%20Service%20Connect/#create-a-subnet-optional","title":"Create a Subnet (optional)","text":"<p>We recommend use of a subnet dedicated to Private Service Connect endpoints in the same VPC where the application is running.</p> <ol> <li>In the GCP console, navigate VPC network \u2192 VPC networks \u2192  \u2192 SUBNETS \u2192 ADD SUBNET.<ul> <li>Replace  with the name of the VPC where the application is running. <li>Configure the subnet:<ul> <li>Name</li> <li>Region: select the same region as the one where the application runs</li> <li>Purpose: None</li> <li>IP address range: Set a CIDR block that doesn't overlap with the CIDR blocks of the existing subnets in the same VPC.</li> <li>Optionally configure Private Google Access</li> <li>Optionally configure Flow logs</li> <li>Click \"ADD\".</li> </ul> </li>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20GCP%20Private%20Service%20Connect/#create-a-static-internal-ip-address","title":"Create a Static Internal IP Address","text":"<ol> <li>In the GCP console, navigate VPC network \u2192 VPC networks \u2192  \u2192 STATIC INTERNAL IP ADDRESSES \u2192 RESERVE STATIC ADDRESS.<ul> <li>Replace  with the name of the VPC where the application is running. <li>Configure the static internal IP address:<ul> <li>Name: set to the Database ID (dbxxxxxxxx) from SkySQL.</li> <li>Subnet: select the subnet where to reserve the static IP address.</li> <li>Static IP address: optionally choose the address.</li> <li>Purpose: Non-shared</li> <li>Click \"RESERVE\".</li> </ul> </li>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20GCP%20Private%20Service%20Connect/#vpc-endpoint-creation-steps","title":"VPC Endpoint Creation Steps","text":"<ol> <li> <p>In the GCP console, navigate Network services \u2192 Private Service Connect \u2192 CONNECTED ENDPOINTS \u2192 CONNECT ENDPOINT.</p> </li> <li> <p>Configure the endpoint connection:</p> <ul> <li>Target: Published service</li> <li>Target service: the value of the\u00a0Endpoint Service ID. See Pre-requisites for more information on how to find this ID.</li> <li>Endpoint name: set to the Database ID from SkySQL (dbxxxxxxxx)</li> <li>Network: select the VPC network where the application is running</li> <li>Subnetwork: select the subnet where the static internal IP address is reserved</li> <li>IP address: select the reserved internal IP address from the prior step</li> <li>Click \"ADD ENDPOINT\".</li> </ul> </li> </ol> <p>After creation, the Endpoint should have a status of <code>Accepted</code>.  If this status is not present, please ensure your Google Project ID is added to the list of allowed accounts in the SkySQL portal for this service.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20GCP%20Private%20Service%20Connect/#connecting-to-your-skysql-service","title":"Connecting to your SkySQL Service","text":"<p>After creating your PSC endpoint, your service should be available within your VPC at the Private IP Address you assigned to the endpoint. - DNS propagation from SkySQL to the Private IP address is not supported when using PSC. - The hostname when connecting to your SkySQL service should always be the Private IP address of the PSC endpoint.</p> <p>[!NOTE] When using PSC with SSL/TLS, there will be a hostname mismatch since the hostname provisioned by SkySQL will not match your internal IP Address.  This can be ignored as the connection is still secure.</p>"},{"location":"Using%20AWS%20Azure%20GCP%20private%20VPC%20connections/Setting%20up%20GCP%20Private%20Service%20Connect/#disabling-google-psc","title":"Disabling Google PSC","text":"<p>[!CAUTION] Disabling PSC on an existing service will cause all existing connections to be dropped.  The service will be unavailable for a short period of time while the private endpoint is replaced with the new public endpoint.</p> Disable Google PSC via the SkySQL Portal   1. Visit the\u00a0[SkySQL Portal](https://app.skysql.com/) 2. Find the service that you would like to modify. 3. Click \"MANAGE\" on the far right side of the service listing. 4. In the context menu, select \"Manage your Private Service Connect\". 5. In the popup window, click \"I want to disconnect my Private Service Connect\". 6. In the popup window, select \"Disconnect\". 7. Since the service's allowlist was cleared when Goolge PSC was previously enabled, you will need to\u00a0[update the allowlist](../Security/Configuring%20Firewall.md) to allow clients to connect after disabling PSC.   Disable Google PSC via the SkySQL DBaaS API   To disable Google PSC on an existing service, you will need to update the service endpoints with a payload similar to the following:  <pre><code>[\n  {\n    \"mechanism\": \"nlb\"\n  }\n]\n</code></pre>  This payload should then be sent to the API `PATCH` https://api.skysql.com/provisioning/v1/services/{SERVICE_ID}/endpoints where `{SERVICE_ID}` is the ID of the service you are updating. For more information on using the SkySQL DBaaS API, see\u00a0[\"SkySQL DBaaS API\"](https://apidocs.skysql.com/#/Services/patch_provisioning_v1_services__service_id__endpoints)."},{"location":"config/","title":"Configure your Database Server(s)","text":"<p>Database server configuration, including system variables, is managed through the Configuration Manager.</p> <p></p>"},{"location":"config/#access-to-configuration-manager","title":"Access to Configuration Manager","text":"<p>To access the Configuration Manager interface:</p> <ol> <li>Log in to the\u00a0Portal.</li> <li>Click the \"Settings\" link in the main menu (left navigation in the Portal).</li> <li>Click the \"Configuration Manager\" button.</li> </ol>"},{"location":"config/#what-is-configurable","title":"What is configurable?","text":"<p>Available configuration parameters differ by cloud database topology.</p> <p>1. Mariadb Server Single Node</p> <p>2. Mariadb Server With Replica(s)</p> <p>3. SkySQL Intelligent Proxy Configuration</p>"},{"location":"config/Mariadb-Server-Single-Node/","title":"Mariadb Server Single Node","text":"<p>For cloud databases with the Mariadb Server Single Node topology, the following Configuration Manager parameters are used to configure MariaDB Server behavior:</p> Name Default Value auto_increment_increment 1 autocommit ON binlog_cache_size 32768 binlog_format ROW connect_timeout 5 cracklib_password_check OFF default_password_lifetime 0 default_time_zone system disconnect_on_expired_password OFF div_precision_increment 4 eq_range_index_dive_limit 200 event_scheduler OFF expire_logs_days 4 explicit_defaults_for_timestamp OFF gtid_strict_mode ON host_cache_size 248 idle_readonly_transaction_timeout 0 idle_transaction_timeout 0 idle_write_transaction_timeout 0 innodb_autoextend_increment 64 innodb_autoinc_lock_mode 2 innodb_buffer_pool_size AUTO_GENERATED innodb_change_buffering none innodb_flush_log_at_trx_commit 1 innodb_log_buffer_size 16777216 innodb_log_file_size 1073741824 innodb_strict_mode ON interactive_timeout 3600 join_buffer_size 262144 local_infile ON log_output FILE log_slow_filter admin, filesort, filesort_on_disk, filesort_priority_queue, full_join, full_scan, query_cache, query_cache_miss, tmp_table, tmp_table_on_disk log_slow_rate_limit 1 log_slow_verbosity log_warnings 2 long_query_time 10.0 lower_case_table_names 0 max_allowed_packet 33554432 max_connections AUTO_GENERATED max_heap_table_size 16777216 max_password_errors 4294967295 net_buffer_length 16384 net_write_timeout 60 open_files_limit 0 optimizer_search_depth 62 optimizer_switch AUTO_GENERATED performance_schema OFF performance_schema_accounts_size -1 performance_schema_digests_size -1 performance_schema_events_stages_history_long_size -1 performance_schema_events_stages_history_size -1 performance_schema_events_statements_history_long_size -1 performance_schema_events_statements_history_size -1 performance_schema_events_waits_history_long_size -1 performance_schema_events_waits_history_size -1 performance_schema_hosts_size -1 performance_schema_max_cond_classes 90 performance_schema_max_cond_instances -1 performance_schema_max_digest_length 1024 performance_schema_max_file_classes 80 performance_schema_max_file_handles 32768 performance_schema_max_file_instances -1 performance_schema_max_mutex_classes 200 performance_schema_max_mutex_instances -1 performance_schema_max_rwlock_classes 50 performance_schema_max_rwlock_instances -1 performance_schema_max_socket_classes 10 performance_schema_max_socket_instances 10 performance_schema_max_stage_classes 160 performance_schema_max_table_handles -1 performance_schema_max_table_instances -1 performance_schema_max_thread_classes 50 performance_schema_max_thread_instances -1 performance_schema_session_connect_attrs_size -1 performance_schema_users_size -1 proxy_protocol_networks read_buffer_size 131072 read_only OFF read_rnd_buffer_size 262144 require_secure_transport AUTO_GENERATED server_audit ON server_audit_file_rotate_size 1000000 server_audit_logging OFF session_track_system_variables autocommit, character_set_client, character_set_connection, character_set_results, time_zone simple_password_check_digits 1 simple_password_check_letters_same_case 1 simple_password_check_minimal_length 8 simple_password_check_other_characters 1 slow_query_log OFF sort_buffer_size 2097152 sql_mode ERROR_FOR_DIVISION_BY_ZERO, NO_AUTO_CREATE_USER, NO_ENGINE_SUBSTITUTION, STRICT_TRANS_TABLES strict_password_validation ON sync_binlog 1 system_versioning_alter_history ERROR table_open_cache AUTO_GENERATED thread_cache_size 256 thread_handling one-thread-per-connection thread_pool_idle_timeout 60 thread_pool_max_threads 65536 thread_pool_priority auto thread_stack 299008 tmp_table_size AUTO_GENERATED transaction_isolation REPEATABLE-READ wait_timeout 600"},{"location":"config/Mariadb-Server-with-Replica%28s%29/","title":"Mariadb Server with Replica(s)","text":"<p>For cloud databases with the Mariadb Server With Replica(s) topology, Configuration Manager can be used to configure MariaDB Server behavior and MariaDB MaxScale behavior.</p> <p>The following Configuration Manager parameters are used to configure MariaDB Server behavior:</p> Name Default Value auto_increment_increment 1 autocommit ON binlog_cache_size 32768 binlog_commit_wait_count 0 binlog_commit_wait_usec 100000 connect_timeout 5 cracklib_password_check OFF default_password_lifetime 0 default_time_zone system disconnect_on_expired_password OFF div_precision_increment 4 eq_range_index_dive_limit 200 event_scheduler OFF expire_logs_days 4 explicit_defaults_for_timestamp OFF gtid_strict_mode ON host_cache_size 248 idle_readonly_transaction_timeout 0 idle_transaction_timeout 0 idle_write_transaction_timeout 0 innodb_autoextend_increment 64 innodb_autoinc_lock_mode 2 innodb_buffer_pool_size AUTO_GENERATED innodb_change_buffering none innodb_flush_log_at_trx_commit 1 innodb_log_buffer_size 16777216 innodb_log_file_size 1073741824 innodb_strict_mode ON interactive_timeout 3600 join_buffer_size 262144 local_infile ON log_output FILE log_slow_filter admin, filesort, filesort_on_disk, filesort_priority_queue, full_join, full_scan, query_cache, query_cache_miss, tmp_table, tmp_table_on_disk log_slow_rate_limit 1 log_slow_verbosity log_warnings 2 long_query_time 10.0 lower_case_table_names 0 max_allowed_packet 33554432 max_connections AUTO_GENERATED max_heap_table_size 16777216 max_password_errors 4294967295 net_buffer_length 16384 net_write_timeout 60 open_files_limit 0 optimizer_search_depth 62 optimizer_switch AUTO_GENERATED performance_schema OFF performance_schema_accounts_size -1 performance_schema_digests_size -1 performance_schema_events_stages_history_long_size -1 performance_schema_events_stages_history_size -1 performance_schema_events_statements_history_long_size -1 performance_schema_events_statements_history_size -1 performance_schema_events_waits_history_long_size -1 performance_schema_events_waits_history_size -1 performance_schema_hosts_size -1 performance_schema_max_cond_classes 90 performance_schema_max_cond_instances -1 performance_schema_max_digest_length 1024 performance_schema_max_file_classes 80 performance_schema_max_file_handles 32768 performance_schema_max_file_instances -1 performance_schema_max_mutex_classes 200 performance_schema_max_mutex_instances -1 performance_schema_max_rwlock_classes 50 performance_schema_max_rwlock_instances -1 performance_schema_max_socket_classes 10 performance_schema_max_socket_instances 10 performance_schema_max_stage_classes 160 performance_schema_max_table_handles -1 performance_schema_max_table_instances -1 performance_schema_max_thread_classes 50 performance_schema_max_thread_instances -1 performance_schema_session_connect_attrs_size -1 performance_schema_users_size -1 proxy_protocol_networks 10.0.0.0/8 read_buffer_size 131072 read_only OFF read_rnd_buffer_size 262144 rpl_semi_sync_master_enabled ON rpl_semi_sync_master_timeout 10000 rpl_semi_sync_master_wait_no_slave ON rpl_semi_sync_master_wait_point AFTER_COMMIT rpl_semi_sync_slave_delay_master OFF rpl_semi_sync_slave_enabled ON rpl_semi_sync_slave_kill_conn_timeout 5 server_audit ON server_audit_file_rotate_size 1000000 server_audit_logging OFF session_track_system_variables autocommit, character_set_client, character_set_connection, character_set_results, time_zone simple_password_check_digits 1 simple_password_check_letters_same_case 1 simple_password_check_minimal_length 8 simple_password_check_other_characters 1 slave_compressed_protocol OFF slave_parallel_mode optimistic slave_parallel_threads AUTO_GENERATED slave_parallel_workers 0 slow_query_log OFF sort_buffer_size 2097152 sql_mode ERROR_FOR_DIVISION_BY_ZERO, NO_AUTO_CREATE_USER, NO_ENGINE_SUBSTITUTION, STRICT_TRANS_TABLES strict_password_validation ON sync_binlog 1 sync_master_info 1 sync_relay_log 0 sync_relay_log_info 0 system_versioning_alter_history ERROR table_open_cache AUTO_GENERATED thread_cache_size 256 thread_handling one-thread-per-connection thread_pool_idle_timeout 60 thread_pool_max_threads 65536 thread_pool_priority auto thread_stack 299008 tmp_table_size AUTO_GENERATED transaction_isolation REPEATABLE-READ wait_timeout 600"},{"location":"config/Mariadb-Serverless-Single-Node/","title":"Mariadb Serverless Single Node","text":"<p>For cloud databases using the MariaDB Serverless Single Node topology, the following Configuration Manager parameters are available to configure the behavior of the MariaDB Server:</p> Name Default Value auto_increment_increment 1 autocommit ON cracklib_password_check OFF default_password_lifetime 0 default_time_zone system disconnect_on_expired_password OFF div_precision_increment 4 eq_range_index_dive_limit 200 event_scheduler OFF expire_logs_days 4 explicit_defaults_for_timestamp OFF innodb_autoextend_increment 64 innodb_autoinc_lock_mode 2 log_slow_filter admin, filesort, filesort_on_disk, filesort_priority_queue, full_join, full_scan, query_cache, query_cache_miss, tmp_table, tmp_table_on_disk log_slow_rate_limit 1 log_slow_verbosity long_query_time 10.0 lower_case_table_names 0 max_allowed_packet 33554432 max_password_errors 4294967295 optimizer_search_depth 62 optimizer_switch AUTO_GENERATED read_only OFF session_track_system_variables autocommit, character_set_client, character_set_connection, character_set_results, time_zone simple_password_check_digits 1 simple_password_check_letters_same_case 1 simple_password_check_minimal_length 8 simple_password_check_other_characters 1 slow_query_log OFF sql_mode ERROR_FOR_DIVISION_BY_ZERO, NO_AUTO_CREATE_USER, NO_ENGINE_SUBSTITUTION, STRICT_TRANS_TABLES strict_password_validation ON transaction_isolation REPEATABLE-READ"},{"location":"config/SkySQL-Intelligent-Proxy/","title":"SkySQL Intelligent Proxy","text":"<p>SkySQL Intelligent Proxy represents an optimized iteration of MariaDB MaxScale. The subsequent Configuration Manager parameters are leveraged to tailor the behavior of MariaDB MaxScale:\"</p> Name Default Value causal_reads none causal_reads_timeout 10s delayed_retry true delayed_retry_timeout 10s failcount 7 master_accept_reads true master_reconnection true max_slave_connections 255 max_slave_replication_lag 0ms monitor_interval 2000ms slave_selection_criteria LEAST_CURRENT_OPERATIONS strict_multi_stmt false strict_sp_calls false transaction_replay true transaction_replay_attempts 10 transaction_replay_max_size 10Mi transaction_replay_retry_on_deadlock true use_sql_variables_in all"}]}